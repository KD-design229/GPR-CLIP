{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01042d0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T02:33:09.878112Z",
     "iopub.status.busy": "2025-10-29T02:33:09.877760Z",
     "iopub.status.idle": "2025-10-29T02:35:08.390949Z",
     "shell.execute_reply": "2025-10-29T02:35:08.390162Z"
    },
    "papermill": {
     "duration": 118.522654,
     "end_time": "2025-10-29T02:35:08.392662",
     "exception": false,
     "start_time": "2025-10-29T02:33:09.870008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.6 which is incompatible.\r\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.3 which is incompatible.\r\n",
      "mkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\r\n",
      "mkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\r\n",
      "mkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\r\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\r\n",
      "datasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\r\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires numpy<2.2,>=1.16.0, but you have numpy 2.2.6 which is incompatible.\r\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\r\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\r\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\r\n",
      "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "transformers 4.53.3 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.0.0rc2 which is incompatible.\r\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\r\n",
      "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mæ­£åœ¨æ¸…ç†è¡çªçš„åŒ…...\n",
      "Found existing installation: numpy 2.2.6\r\n",
      "Uninstalling numpy-2.2.6:\r\n",
      "  Successfully uninstalled numpy-2.2.6\r\n",
      "Found existing installation: scipy 1.15.3\r\n",
      "Uninstalling scipy-1.15.3:\r\n",
      "  Successfully uninstalled scipy-1.15.3\r\n",
      "Found existing installation: opencv-python 4.12.0.88\r\n",
      "Uninstalling opencv-python-4.12.0.88:\r\n",
      "  Successfully uninstalled opencv-python-4.12.0.88\r\n",
      "Found existing installation: opencv-contrib-python 4.12.0.88\r\n",
      "Uninstalling opencv-contrib-python-4.12.0.88:\r\n",
      "  Successfully uninstalled opencv-contrib-python-4.12.0.88\r\n",
      "Found existing installation: opencv-python-headless 4.12.0.88\r\n",
      "Uninstalling opencv-python-headless-4.12.0.88:\r\n",
      "  Successfully uninstalled opencv-python-headless-4.12.0.88\r\n",
      "\n",
      "å®‰è£å…¼å®¹ç‰ˆæœ¬çš„æ ¸å¿ƒåº«...\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.7/61.7 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "datasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\r\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\r\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\r\n",
      "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.11.4 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\r\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\r\n",
      "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "transformers 4.53.3 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.0.0rc2 which is incompatible.\r\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\r\n",
      "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# ä¿®å¤ä¾èµ–å†²çª\n",
    "# å®‰è£…å¹¶å¯¼å…¥ - é”å®šå…¼å®¹ç‰ˆæœ¬é¿å… Kaggle ç¯å¢ƒä¾èµ–å†²çª\n",
    "!pip install -q tensorboardX albumentations thop\n",
    "# ===== ä¿®å¤ Kaggle 2025 ç¯å¢ƒå…¼å®¹æ€§é—®é¢˜ =====\n",
    "# é—®é¢˜ï¼šKaggle å‡çº§åˆ° NumPy 2.x å¯¼è‡´ SciPy/Seaborn/OpenCV å´©æºƒ\n",
    "# è§£å†³ï¼šé”å®šåˆ° 2024 å¹´ç¨³å®šçš„ç‰ˆæœ¬ç»„åˆ\n",
    "\n",
    "# é¦–å…ˆï¼ŒæŒ‰ç…§åŸæ„åœ–è§£é™¤å®‰è£è¡çªçš„å¥—ä»¶\n",
    "print(\"æ­£åœ¨æ¸…ç†è¡çªçš„åŒ…...\")\n",
    "!pip uninstall -y numpy scipy opencv-python opencv-contrib-python opencv-python-headless 2>/dev/null || true\n",
    "\n",
    "# æ¥è‘—ï¼Œåœ¨å–®ä¸€æŒ‡ä»¤ä¸­å®‰è£æ‰€æœ‰å¿…è¦çš„å‡½å¼åº«\n",
    "# é€™èƒ½è®“ pip ä¸€æ¬¡æ€§è§£æ±ºæ‰€æœ‰ä¾è³´é—œä¿‚ï¼Œä¸¦éµå¾ªç‰ˆæœ¬é–å®š\n",
    "print(\"\\nå®‰è£å…¼å®¹ç‰ˆæœ¬çš„æ ¸å¿ƒåº«...\")\n",
    "!pip install --quiet \\\n",
    "    numpy==1.26.4 \\\n",
    "    scipy==1.11.4 \\\n",
    "    matplotlib==3.7.5 \\\n",
    "    opencv-python==4.8.1.78 \\\n",
    "    albumentations \\\n",
    "    tensorboardX \\\n",
    "    thop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c786013",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-29T02:35:08.458002Z",
     "iopub.status.busy": "2025-10-29T02:35:08.457443Z",
     "iopub.status.idle": "2025-10-29T02:35:43.172266Z",
     "shell.execute_reply": "2025-10-29T02:35:43.171438Z"
    },
    "papermill": {
     "duration": 34.749107,
     "end_time": "2025-10-29T02:35:43.173876",
     "exception": false,
     "start_time": "2025-10-29T02:35:08.424769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "import timm\n",
    "import torch\n",
    "import random\n",
    "import logging\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from io import BytesIO\n",
    "from thop import profile\n",
    "from copy import deepcopy\n",
    "from torch.optim import Adam\n",
    "from torch.optim import AdamW\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import v2\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import default_collate \n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.utils import compute_class_weight\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, classification_report\n",
    "# ...\n",
    "# è®¾ç½®æ—¥å¿—è®°å½•\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c08e88c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T02:35:43.241132Z",
     "iopub.status.busy": "2025-10-29T02:35:43.240582Z",
     "iopub.status.idle": "2025-10-29T02:35:43.247420Z",
     "shell.execute_reply": "2025-10-29T02:35:43.246705Z"
    },
    "papermill": {
     "duration": 0.041782,
     "end_time": "2025-10-29T02:35:43.248630",
     "exception": false,
     "start_time": "2025-10-29T02:35:43.206848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class KaggleConfig:\n",
    "    def __init__(self):\n",
    "        # --- è·¯å¾„è®¾ç½® (è¯·æ ¹æ®æ‚¨çš„Kaggleæ•°æ®é›†åç§°ä¿®æ”¹) ---\n",
    "        # å‡è®¾æ‚¨çš„Kaggleæ•°æ®é›†åœ°å€æ˜¯ /kaggle/input/your-dataset-name\n",
    "        # æ‚¨éœ€è¦å°†ä¸‹é¢çš„ 'your-dataset-slug' æ›¿æ¢ä¸ºæ‚¨çš„æ•°æ®é›†çš„å®é™…åç§°\n",
    "        \n",
    "        \n",
    "        self.train_path = '/kaggle/input/d1-data/Dataset_V5_split_new/train'\n",
    "        self.val_path = '/kaggle/input/d1-data/Dataset_V5_split_new/val'\n",
    "        self.test_path = '/kaggle/input/d1-data/Dataset_V5_split_new/test'\n",
    "        self.save_path = '/kaggle/working/' # æ¨¡å‹å’Œè¾“å‡ºæ–‡ä»¶å°†ä¿å­˜åœ¨è¿™é‡Œ\n",
    "\n",
    "        # --- è®­ç»ƒå‚æ•° ---\n",
    "        self.train_batch_size = 64\n",
    "        self.val_batch_size = 64\n",
    "        self.test_batch_size = 128\n",
    "        self.num_epochs = 200\n",
    "        self.cuda_no = 0\n",
    "        \n",
    "        # --- KæŠ˜äº¤å‰éªŒè¯å‚æ•° ---\n",
    "        self.n_folds = 5  # KæŠ˜äº¤å‰éªŒè¯çš„æŠ˜æ•°\n",
    "        self.current_fold = 0  # å½“å‰æŠ˜ç´¢å¼•\n",
    "        \n",
    "        # --- æ¨¡å‹å’Œä¼˜åŒ–å™¨å‚æ•° ---\n",
    "        self.encoder = 'mobilenetv3_large_100'  # ğŸ”¥ ä¿®æ­£ä¸º resnet50ï¼ˆä¸æ‚¨çš„éœ€æ±‚ä¸€è‡´ï¼‰\n",
    "        self.classnum = 8        # æ‚¨çš„æ€»ç±»åˆ«æ•°\n",
    "        self.LR_clf = 1e-5       # ğŸ”¥ ä¿®æ”¹ä¸º 5e-5\n",
    "        self.LR_head = 1e-3     # <-- æ–°å¢ï¼šç”¨äºé˜¶æ®µä¸€çš„å­¦ä¹ ç‡ï¼Œè¦å¤§å¾—å¤š\n",
    "        self.WE_dec = 0.05\n",
    "        self.min_lr = 1e-6\n",
    "\n",
    "        #å­¦ä¹ ç‡ç­–ç•¥\n",
    "        # ReduceLROnPlateau å‚æ•°ï¼ˆä»…åœ¨ lr_scheduler == \"plateau\" æ—¶ç”Ÿæ•ˆï¼‰\n",
    "        self.lr_scheduler = \"plateau\"  # æƒ³ç”¨ä½™å¼¦é€€ç«å°±æ”¹ä¸º \"cosine\"\n",
    "        self.plateau_factor = 0.5   # æ¯æ¬¡é™ LR çš„å€æ•°\n",
    "        self.plateau_patience = 5   # è¿ç»­å¤šå°‘ä¸ª epoch éªŒè¯æŸå¤±ä¸ä¸‹é™æ‰é™ LR\n",
    "        # ä½™å¼¦çš„ T_max è®¾ç½®ï¼ˆå¯æŒ‰é˜¶æ®µåˆ†åˆ«è®¾ç½®ï¼‰\n",
    "        self.stage1_tmax = 15\n",
    "        \n",
    "        # --- æ–°å¢å‚æ•° ---\n",
    "        self.use_hybrid_mix = 0 \n",
    "        self.aug_methon = 1\n",
    "        self.label_smoothing = 0.00 # æ ‡ç­¾å¹³æ»‘çš„å¼ºåº¦ï¼Œ0.1æ˜¯ä¸€ä¸ªå¸¸ç”¨å€¼\n",
    "        self.focal_loss_gamma = 2.0  # æ·»åŠ  gamma å‚æ•°ï¼Œ2.0 æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„èµ·å§‹å€¼\n",
    "        self.fold = 0\n",
    "        self.dropout_rate = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b4bf3cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T02:35:43.327245Z",
     "iopub.status.busy": "2025-10-29T02:35:43.326895Z",
     "iopub.status.idle": "2025-10-29T02:35:43.335124Z",
     "shell.execute_reply": "2025-10-29T02:35:43.334488Z"
    },
    "papermill": {
     "duration": 0.048673,
     "end_time": "2025-10-29T02:35:43.336351",
     "exception": false,
     "start_time": "2025-10-29T02:35:43.287678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Focal Loss çš„ PyTorch å®ç°ã€‚\n",
    "    è¿™ä¸ªæŸå¤±å‡½æ•°è¢«è®¾è®¡ç”¨æ¥è§£å†³ç±»åˆ«ä¸å¹³è¡¡å’Œéš¾æ˜“æ ·æœ¬ä¸å¹³è¡¡çš„é—®é¢˜ã€‚\n",
    "    å®ƒé€šè¿‡ä¸€ä¸ªåŠ¨æ€ç¼©æ”¾å› å­æ¥é™ä½â€œç®€å•â€æ ·æœ¬å¯¹æŸå¤±çš„è´¡çŒ®ï¼Œ\n",
    "    ä»è€Œè®©æ¨¡å‹æ›´åŠ ä¸“æ³¨äºå­¦ä¹ é‚£äº›â€œå›°éš¾â€çš„æ ·æœ¬ã€‚\n",
    "\n",
    "    å…¬å¼: FL(p_t) = -Î±_t * (1 - p_t)^Î³ * log(p_t)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
    "        \"\"\"\n",
    "        åˆå§‹åŒ– Focal Loss.\n",
    "        Args:\n",
    "            alpha (Tensor, optional): ä¸€ä¸ªä¸ç±»åˆ«æ•°é‡ç›¸åŒé•¿åº¦çš„å¼ é‡ï¼Œç”¨äºä¸ºæ¯ä¸ªç±»åˆ«åˆ†é…æƒé‡ã€‚\n",
    "                                      è¿™ä¸åŠ æƒäº¤å‰ç†µä¸­çš„ 'weight' å‚æ•°ä½œç”¨ç›¸åŒã€‚\n",
    "                                      é»˜è®¤å€¼: None (æ‰€æœ‰ç±»åˆ«æƒé‡ä¸º1)ã€‚\n",
    "            gamma (float, optional): èšç„¦å‚æ•° (Focusing Parameter)ã€‚\n",
    "                                     è¯¥å€¼è¶Šå¤§ï¼Œæ¨¡å‹å°±è¶Šä¼šä¸“æ³¨äºå›°éš¾æ ·æœ¬ã€‚\n",
    "                                     è®ºæ–‡ä¸­æ¨èçš„é»˜è®¤å€¼ä¸º 2.0ã€‚\n",
    "            reduction (str, optional): æŒ‡å®šå¦‚ä½•å¯¹æ‰¹æ¬¡çš„æŸå¤±è¿›è¡Œèšåˆã€‚\n",
    "                                       å¯é€‰å€¼: 'mean', 'sum', 'none'ã€‚\n",
    "                                       é»˜è®¤å€¼: 'mean'ã€‚\n",
    "        \"\"\"\n",
    "        super(FocalLoss, self).__init__()\n",
    "        # alpha å‚æ•°ç”¨äºå¹³è¡¡ç±»åˆ«é‡è¦æ€§ï¼Œå¯ä»¥æ˜¯ None æˆ–è€…ä¸€ä¸ª Tensor\n",
    "        # å¦‚æœæ˜¯ Tensorï¼Œæˆ‘ä»¬ä¼šç¡®ä¿å®ƒåœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š\n",
    "        if alpha is not None:\n",
    "            if not isinstance(alpha, torch.Tensor):\n",
    "                alpha = torch.tensor(alpha)\n",
    "        self.alpha = alpha\n",
    "\n",
    "        # gamma æ˜¯èšç„¦å‚æ•°ï¼Œç”¨äºè°ƒèŠ‚éš¾æ˜“æ ·æœ¬çš„æƒé‡\n",
    "        self.gamma = gamma\n",
    "\n",
    "        # reduction æŒ‡å®šæœ€ç»ˆæŸå¤±çš„è®¡ç®—æ–¹å¼\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        \"\"\"\n",
    "        è®¡ç®— Focal Loss çš„å‰å‘ä¼ æ’­ã€‚\n",
    "        Args:\n",
    "            inputs (Tensor): æ¨¡å‹çš„åŸå§‹è¾“å‡º (logits)ï¼Œå½¢çŠ¶ä¸º [N, C]ï¼Œ\n",
    "                             å…¶ä¸­ N æ˜¯æ‰¹æ¬¡å¤§å°, C æ˜¯ç±»åˆ«æ•°ã€‚\n",
    "            targets (Tensor): çœŸå®çš„ç±»åˆ«æ ‡ç­¾ï¼Œå½¢çŠ¶ä¸º [N]ã€‚\n",
    "        Returns:\n",
    "            Tensor: è®¡ç®—å‡ºçš„ Focal Lossã€‚\n",
    "        \"\"\"\n",
    "        # ç¡®ä¿ alpha æƒé‡å¼ é‡å’Œè¾“å…¥åœ¨åŒä¸€ä¸ªè®¾å¤‡ä¸Š (CPU æˆ– GPU)\n",
    "        if self.alpha is not None and self.alpha.device != inputs.device:\n",
    "            self.alpha = self.alpha.to(inputs.device)\n",
    "\n",
    "        # æ­¥éª¤ 1: è®¡ç®—æ ‡å‡†çš„äº¤å‰ç†µæŸå¤±ï¼Œä½†ä¸è¿›è¡Œä»»ä½•èšåˆ (reduction='none')\n",
    "        #         è¿™æ ·æˆ‘ä»¬å¯ä»¥å¾—åˆ°æ‰¹æ¬¡ä¸­æ¯ä¸ªæ ·æœ¬çš„ç‹¬ç«‹æŸå¤±å€¼ã€‚\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "\n",
    "        # æ­¥éª¤ 2: ä»äº¤å‰ç†µæŸå¤±ä¸­è®¡ç®—å‡ºæ¨¡å‹å¯¹æ­£ç¡®ç±»åˆ«çš„é¢„æµ‹æ¦‚ç‡ p_t\n",
    "        #         å…¬å¼: p_t = exp(-ce_loss)\n",
    "        #         è¿™ä¸ªæŠ€å·§å¯ä»¥é¿å…ç›´æ¥æ“ä½œ softmax çš„è¾“å‡ºï¼Œæ•°å€¼ä¸Šæ›´ç¨³å®šã€‚\n",
    "        pt = torch.exp(-ce_loss)\n",
    "\n",
    "        # æ­¥éª¤ 3: è®¡ç®— Focal Loss çš„æ ¸å¿ƒéƒ¨åˆ†â€”â€”åŠ¨æ€ç¼©æ”¾å› å­\n",
    "        #         å…¬å¼: (1 - p_t)^Î³\n",
    "        #         è¿™ä¸ªå› å­ä¼šæ ¹æ®é¢„æµ‹æ¦‚ç‡ pt çš„å¤§å°æ¥åŠ¨æ€è°ƒæ•´æŸå¤±çš„æƒé‡ã€‚\n",
    "        #         å¦‚æœ pt å¾ˆå¤§ (æ¥è¿‘1ï¼Œç®€å•æ ·æœ¬)ï¼Œè¿™ä¸ªå› å­å°±æ¥è¿‘0ï¼ŒæŸå¤±è¢«å¤§å¹…å‰Šå¼±ã€‚\n",
    "        #         å¦‚æœ pt å¾ˆå° (æ¥è¿‘0ï¼Œå›°éš¾æ ·æœ¬)ï¼Œè¿™ä¸ªå› å­å°±æ¥è¿‘1ï¼ŒæŸå¤±åŸºæœ¬ä¿æŒä¸å˜ã€‚\n",
    "        focal_term = (1 - pt) ** self.gamma\n",
    "\n",
    "        # æ­¥éª¤ 4: è®¡ç®—æœ€ç»ˆçš„ Focal Loss\n",
    "        #         é¦–å…ˆå°†åŠ¨æ€ç¼©æ”¾å› å­ä¸åŸå§‹çš„äº¤å‰ç†µæŸå¤±ç›¸ä¹˜ã€‚\n",
    "        loss = focal_term * ce_loss\n",
    "\n",
    "        # æ­¥éª¤ 5: (å¯é€‰) å¦‚æœæä¾›äº† alpha æƒé‡ï¼Œåˆ™å†ä¹˜ä¸Šå¯¹åº”ç±»åˆ«çš„æƒé‡\n",
    "        if self.alpha is not None:\n",
    "            # self.alpha[targets] ä¼šæ ¹æ® targets ä¸­çš„æ ‡ç­¾ç´¢å¼•ï¼Œ\n",
    "            # ä» alpha æƒé‡å¼ é‡ä¸­å–å‡ºæ¯ä¸ªæ ·æœ¬å¯¹åº”çš„æƒé‡ã€‚\n",
    "            alpha_t = self.alpha[targets]\n",
    "            loss = alpha_t * loss\n",
    "\n",
    "        # æ­¥éª¤ 6: æ ¹æ®æŒ‡å®šçš„ reduction å‚æ•°å¯¹æœ€ç»ˆçš„æŸå¤±è¿›è¡Œèšåˆ\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c222bf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T02:35:43.405083Z",
     "iopub.status.busy": "2025-10-29T02:35:43.404773Z",
     "iopub.status.idle": "2025-10-29T02:35:43.423991Z",
     "shell.execute_reply": "2025-10-29T02:35:43.423364Z"
    },
    "papermill": {
     "duration": 0.056089,
     "end_time": "2025-10-29T02:35:43.425423",
     "exception": false,
     "start_time": "2025-10-29T02:35:43.369334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "def count_parameters(model):\n",
    "    \"\"\"Counts the number of trainable parameters in a model.\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "def mean_and_std(paths):\n",
    "    print('Calculating mean and std of training set for data normalization.')\n",
    "    bgr_means, bgr_stds = [], []\n",
    "\n",
    "    for img_path in tqdm(paths):\n",
    "        img = cv2.imread(img_path)\n",
    "        channel_means, channel_stds = cv2.meanStdDev(img)[:2]\n",
    "        bgr_means.append(channel_means.reshape(3))\n",
    "        bgr_stds.append(channel_stds.reshape(3))\n",
    "\n",
    "    global_mean = np.mean(bgr_means, axis=0)[::-1] / 255.0\n",
    "    global_std = np.mean(bgr_stds, axis=0)[::-1] / 255.0\n",
    "\n",
    "    print(f\"Mean (RGB): {global_mean.tolist()}\")\n",
    "    print(f\"Std  (RGB): {global_std.tolist()}\")\n",
    "    return global_mean, global_std\n",
    "\n",
    "def save_metrics_to_excel(file_name, epoch, encoder_lr=None, loss=None, accuracy=None,\n",
    "                         precision=None, recall=None, f1=None, f1_macro=None, auc_macro=None,\n",
    "                         auc_weighted=None, confusion_matrix=None, **kwargs):\n",
    "    # ğŸ†• encoder_lr ä½œä¸ºç¬¬ä¸€åˆ—ï¼Œç”¨äºè¿½è¸ªå®éªŒé…ç½®\n",
    "    data = {\n",
    "        'encoder_lr': [encoder_lr],  # ğŸ†• æ–°å¢: è®°å½• run_id (ä¾‹å¦‚ \"convnext_tiny_lr_3e-5\")\n",
    "        'Epoch': [epoch], \n",
    "        'Loss': [loss], \n",
    "        'Accuracy': [accuracy], \n",
    "        'Precision': [precision],\n",
    "        'Recall': [recall], \n",
    "        'F1_weighted': [f1], \n",
    "        'F1_macro': [f1_macro], \n",
    "        'AUC_macro': [auc_macro], \n",
    "        'AUC_weighted': [auc_weighted]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # åœ¨Kaggleç¯å¢ƒä¸­ï¼Œç›´æ¥ä½¿ç”¨save_path\n",
    "    args = KaggleConfig()\n",
    "    file_path = os.path.join(args.save_path, file_name)\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        df.to_excel(file_path, index=False, sheet_name='Sheet1')\n",
    "    else:\n",
    "        with pd.ExcelWriter(file_path, mode='a', engine='openpyxl', if_sheet_exists='overlay') as writer:\n",
    "            if 'Sheet1' in writer.sheets:\n",
    "                 start_row = writer.sheets['Sheet1'].max_row\n",
    "                 df.to_excel(writer, sheet_name='Sheet1', index=False, header=False, startrow=start_row)\n",
    "            else:\n",
    "                 df.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "\n",
    "class AverageMeter(object):\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "    def reset(self):\n",
    "        self.val, self.avg, self.sum, self.count = 0, 0, 0, 0\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "def cm_to_figure(cm):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted'); plt.ylabel('True'); plt.title('Confusion Matrix')\n",
    "    buf = BytesIO()\n",
    "    fig.savefig(buf, format='png', bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    buf.seek(0)\n",
    "    image = np.frombuffer(buf.getvalue(), dtype=np.uint8)\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    return image.transpose(2, 0, 1)\n",
    "\n",
    "def plot_history_curves(history, save_dir):\n",
    "    \"\"\"ç»˜åˆ¶å¹¶ä¿å­˜è®­ç»ƒå’ŒéªŒè¯çš„æŸå¤±ä¸å‡†ç¡®ç‡æ›²çº¿å›¾ã€‚\"\"\"\n",
    "    # æ£€æŸ¥historyå­—å…¸ä¸­æ˜¯å¦åŒ…å«æ‰€éœ€çš„æ‰€æœ‰é”®\n",
    "    required_keys = ['train_loss', 'val_loss', 'train_acc', 'val_acc']\n",
    "    if not all(key in history for key in required_keys):\n",
    "        print(\"Warning: History dictionary is missing one or more required keys for plotting. Skipping plot.\")\n",
    "        return\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "    fig.suptitle('Training & Validation History', fontsize=16)\n",
    "\n",
    "    # ç¡®ä¿æ‰€æœ‰åˆ—è¡¨é•¿åº¦ä¸€è‡´ï¼Œä»¥æœ€çŸ­çš„ä¸ºå‡†\n",
    "    min_epochs = len(history['train_loss'])\n",
    "    epochs_range = range(min_epochs)\n",
    "\n",
    "    # ç»˜åˆ¶æŸå¤±æ›²çº¿\n",
    "    ax1.plot(epochs_range, history['train_loss'][:min_epochs], 'o-', label='Train Loss')\n",
    "    ax1.plot(epochs_range, history['val_loss'][:min_epochs], 'o-', label='Validation Loss')\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.set_title('Loss vs. Epochs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # ç»˜åˆ¶å‡†ç¡®ç‡æ›²çº¿\n",
    "    ax2.plot(epochs_range, history['train_acc'][:min_epochs], 'o-', label='Train Accuracy')\n",
    "    ax2.plot(epochs_range, history['val_acc'][:min_epochs], 'o-', label='Validation Accuracy')\n",
    "    ax2.legend(loc='lower right')\n",
    "    ax2.set_title('Accuracy vs. Epochs')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.grid(True)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.96])\n",
    "\n",
    "    # ä¿å­˜å›¾ç‰‡\n",
    "    save_path = os.path.join(save_dir, 'history_curves.png')\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.close(fig)\n",
    "    print(f\"âœ… Training history curves plot saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a64fe0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T02:35:43.495105Z",
     "iopub.status.busy": "2025-10-29T02:35:43.494750Z",
     "iopub.status.idle": "2025-10-29T02:35:43.521750Z",
     "shell.execute_reply": "2025-10-29T02:35:43.520876Z"
    },
    "papermill": {
     "duration": 0.06359,
     "end_time": "2025-10-29T02:35:43.523377",
     "exception": false,
     "start_time": "2025-10-29T02:35:43.459787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. ä¸ºè®­ç»ƒé›†å®šä¹‰çš„æœ€ç»ˆå¢å¼ºæµæ°´çº¿ (ç²¾ç¡®å¤ç°ä½ çš„ç­‰æ¯”ä¾‹æ”¾å¤§ç­–ç•¥)\n",
    "# --- Hybrid Mix å®šä¹‰ ---\n",
    "args_for_mix = KaggleConfig() # è·å–ç±»åˆ«æ•°\n",
    "cutmix = v2.CutMix(num_classes=args_for_mix.classnum,alpha=0.8)\n",
    "mixup = v2.MixUp(num_classes=args_for_mix.classnum,alpha=0.8)\n",
    "cutmix_or_mixup = v2.RandomChoice([cutmix, mixup], p =[0.7,0.3])\n",
    "\n",
    "# --- Collate Function å®šä¹‰ ---\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    ä¸€ä¸ªæ›´å¥å£®çš„collate_fnï¼Œç”¨äºå¤„ç†åŒ…å«é¢å¤–ä¿¡æ¯ï¼ˆå¦‚æ–‡ä»¶åï¼‰çš„æ•°æ®ã€‚\n",
    "    \"\"\"\n",
    "    # 1. å…ˆç”¨PyTorché»˜è®¤çš„æ–¹å¼å°†ä¸€æ‰¹æ•°æ®æ‰“åŒ…ã€‚\n",
    "    # å¯¹äºæˆ‘ä»¬è¿”å› (æ–‡ä»¶å, å›¾åƒ, æ ‡ç­¾) çš„æ•°æ®é›†ï¼Œè¿™é‡Œä¼šå¾—åˆ°ä¸‰ä¸ªç‹¬ç«‹çš„æ‰¹æ¬¡ã€‚\n",
    "    filenames, images, targets = default_collate(batch)\n",
    "    \n",
    "    # 2. åªæŠŠå›¾åƒå’Œæ ‡ç­¾ä¼ å…¥CutMix/MixUpè¿›è¡Œå¤„ç†\n",
    "    images, targets = cutmix_or_mixup(images, targets)\n",
    "    \n",
    "    # 3. å°†åŸå§‹çš„æ–‡ä»¶ååˆ—è¡¨å’Œç»è¿‡å¢å¼ºå¤„ç†çš„å›¾åƒã€æ ‡ç­¾é‡æ–°ç»„åˆå¹¶è¿”å›\n",
    "    return filenames, images, targets\n",
    "    \n",
    "def image_transform(mean,std):\n",
    "    args = KaggleConfig()\n",
    "    if args.aug_methon == 0:\n",
    "        train_transform = A.Compose([\n",
    "            # --- æ ¸å¿ƒç­–ç•¥ï¼šç­‰æ¯”ä¾‹æ”¾å¤§ + ä¸­å¿ƒè£å‰ª ---\n",
    "            # è¿™ä¸€æ­¥å®Œå…¨ç­‰æ•ˆäº torchvision çš„ transforms.Resize(int(224 * 1.14))\n",
    "            # å®ƒå°†å›¾åƒçš„æœ€çŸ­è¾¹ç¼©æ”¾åˆ° 255 (å³ 224 * 1.14)ï¼ŒåŒæ—¶ä¿æŒé•¿å®½æ¯”ã€‚\n",
    "            A.SmallestMaxSize(max_size=int(224 * 1.14)), \n",
    "    \n",
    "            # è¿™ä¸€æ­¥ç­‰æ•ˆäº transforms.CenterCrop(224)\n",
    "            A.CenterCrop(height=224, width=224),\n",
    "    \n",
    "             # --- å…¶ä»–æœ‰æ•ˆçš„å¢å¼ºæŠ€æœ¯ ---\n",
    "            # æ°´å¹³ç¿»è½¬\n",
    "            A.HorizontalFlip(p=0.5), \n",
    "        \n",
    "            # è½»å¾®çš„å‡ ä½•å˜æ¢ (ä½ç§»ã€ç¼©æ”¾ã€æ—‹è½¬)ï¼Œå¯¹GPRå›¾åƒçš„ç»†å¾®å˜åŒ–å¾ˆæœ‰æ•ˆ\n",
    "            A.ShiftScaleRotate(shift_limit=0.06, scale_limit=0.1, rotate_limit=5, p=0.7),\n",
    "\n",
    "            # æ¨¡æ‹Ÿä¿¡å·å¼ºåº¦çš„å˜åŒ–\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.7),\n",
    "    \n",
    "            # å¢å¼ºå¯¹å™ªå£°çš„æŠµæŠ—åŠ›\n",
    "            A.GaussNoise(var_limit=(10.0, 50.0), p=0.5),\n",
    "\n",
    "            # éšæœºé®æŒ¡ï¼Œå¼ºè¿«æ¨¡å‹å…³æ³¨å…¨å±€ç‰¹å¾\n",
    "            #A.CoarseDropout(max_holes=8, max_height=20, max_width=20, p=0.5),\n",
    "    \n",
    "            # æ ‡å‡†åŒ–å’Œç±»å‹è½¬æ¢\n",
    "            A.Normalize(mean, std),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "             # 2. éªŒè¯å’Œæµ‹è¯•é›†çš„é¢„å¤„ç† (åŒæ ·ä¿æŒæœ€çŸ­è¾¹ç¼©æ”¾ï¼Œä¿è¯å¤„ç†é€»è¾‘ä¸€è‡´æ€§)\n",
    "        val_test_transform = A.Compose([\n",
    "            A.SmallestMaxSize(max_size=int(224 * 1.14)),\n",
    "            A.CenterCrop(height=224, width=224),\n",
    "            A.Normalize(mean,std),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    elif args.aug_methon == 1:\n",
    "        train_transform = A.Compose([\n",
    "        # --- å°ºå¯¸ä¸å‡ ä½•å˜æ¢ ---\n",
    "        # æ­¥éª¤ 1: ä½¿ç”¨ RandomResizedCrop æ›¿ä»£åŸæ¥çš„å›ºå®šç¼©æ”¾å’Œä¸­å¿ƒè£å‰ªã€‚\n",
    "        # è¿™æ˜¯æ›´ç°ä»£ã€æ›´å¼ºå¤§çš„è®­ç»ƒæŠ€å·§ï¼Œå®ƒéšæœºåœ°åœ¨å›¾åƒä¸­è£å‰ªä¸åŒå¤§å°å’Œé•¿å®½æ¯”çš„åŒºåŸŸï¼Œç„¶åç¼©æ”¾åˆ°224x224ã€‚\n",
    "        # è¿™èƒ½è®©æ¨¡å‹å¯¹ç›®æ ‡çš„ä½ç½®å’Œå¤§å°å˜åŒ–æ›´åŠ é²æ£’ã€‚\n",
    "        A.LongestMaxSize(max_size=224, p=1.0),\n",
    "        A.PadIfNeeded(min_height=224, min_width=224, border_mode=0, value=134, p=1.0),\n",
    "\n",
    "        # æ­¥éª¤ 2: æ°´å¹³ç¿»è½¬ï¼Œå¯¹äºGPRæ•°æ®æ˜¯å®‰å…¨ä¸”æœ‰æ•ˆçš„å¢å¼ºã€‚\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "\n",
    "        # æ­¥éª¤ 3: å¼¹æ€§å˜æ¢ï¼Œæ¨¡æ‹Ÿåœ°ä¸‹ä»‹è´¨ä¸å‡åŒ€å¯¼è‡´çš„æ³¢å½¢è½»å¾®æ‰­æ›²ï¼Œå¯¹GPRæ•°æ®éå¸¸æœ‰æ•ˆã€‚\n",
    "        A.ElasticTransform(p=0.5, alpha=20, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n",
    "        A.ShiftScaleRotate(\n",
    "            shift_limit=0.05,      # è½»å¾®å¹³ç§» (Â±5%)\n",
    "            scale_limit=0.1,       # è½»å¾®ç¼©æ”¾ (Â±10%)\n",
    "            rotate_limit=0,        # âŒ GPRæ•°æ®ä¸åº”æ—‹è½¬!\n",
    "            border_mode=0,         # é»‘è‰²å¡«å……\n",
    "            p=0.3                  # é™ä½æ¦‚ç‡,é¿å…è¿‡åº¦å˜æ¢\n",
    "        ),\n",
    "        # --- å™ªå£°ä¸é®æŒ¡ç»„åˆ ---\n",
    "        # æ­¥éª¤ 4: ä½¿ç”¨ SomeOf ç»„åˆå™¨ï¼Œæ¯æ¬¡ä»¥80%çš„æ¦‚ç‡ä»ä»¥ä¸‹ä¸‰ç§å™ªå£°/é®æŒ¡ä¸­éšæœºé€‰æ‹©ä¸¤ç§æ¥åº”ç”¨ã€‚\n",
    "        # è¿™æå¤§åœ°å¢åŠ äº†æ•°æ®çš„å¤šæ ·æ€§ï¼Œé¿å…æ¨¡å‹å¯¹æŸç§ç‰¹å®šå™ªå£°äº§ç”Ÿè¿‡æ‹Ÿåˆã€‚\n",
    "        A.OneOf([\n",
    "            # é€‰é¡¹1: é«˜æ–¯å™ªå£° - æ¨¡æ‹Ÿä¼ æ„Ÿå™¨çš„éšæœºå™ªå£°\n",
    "            A.GaussNoise(var_limit=(5.0, 30.0), p=1.0),  # âœ… é™ä½å™ªå£°å¼ºåº¦: 10~50 -> 5~30\n",
    "            \n",
    "            # é€‰é¡¹2: å°èŒƒå›´éšæœºé®æŒ¡ - æ¨¡æ‹Ÿæ•°æ®ç¼ºå¤±\n",
    "            A.CoarseDropout(\n",
    "                max_holes=4,           # âœ… å‡å°‘é®æŒ¡å—æ•°é‡: 8 -> 4\n",
    "                max_height=15,         # âœ… å‡å°é®æŒ¡å°ºå¯¸: 25 -> 15\n",
    "                max_width=15, \n",
    "                min_holes=2,           # âœ… å‡å°‘æœ€å°é®æŒ¡æ•°: 4 -> 2\n",
    "                fill_value=0, \n",
    "                p=1.0\n",
    "            ),\n",
    "            \n",
    "            # é€‰é¡¹3: ä¹˜æ€§å™ªå£° - æ¨¡æ‹Ÿä¿¡å·å¢ç›Šå˜åŒ–\n",
    "            A.MultiplicativeNoise(multiplier=[0.9, 1.1], p=1.0),  # âœ… æ”¶çª„èŒƒå›´: 0.8~1.2 -> 0.9~1.1\n",
    "        ], p=0.4),  # âœ… æé«˜åº”ç”¨æ¦‚ç‡: 0.3 -> 0.4 (å› ä¸ºç°åœ¨åªé€‰ä¸€ç§,ä¸ä¼šå åŠ \n",
    "\n",
    "        # --- ä¿¡å·å¼ºåº¦ä¸é¢œè‰²å˜æ¢ ---\n",
    "        # æ­¥éª¤ 5: éšæœºè°ƒæ•´äº®åº¦å’Œå¯¹æ¯”åº¦ï¼Œæ¨¡æ‹Ÿä¿¡å·å¼ºåº¦çš„å˜åŒ–ã€‚\n",
    "        A.RandomBrightnessContrast(\n",
    "            brightness_limit=0.15,  # âœ… é™ä½å¼ºåº¦: 0.2 -> 0.15\n",
    "            contrast_limit=0.15, \n",
    "            p=0.5                   # âœ… é™ä½æ¦‚ç‡: 0.7 -> 0.5\n",
    "        ),\n",
    "\n",
    "        # --- æ ‡å‡†åŒ–ä¸æ ¼å¼è½¬æ¢ ---\n",
    "        # æ­¥éª¤ 6: æ ‡å‡†åŒ–å’Œè½¬æ¢ä¸ºTensorï¼Œè¿™æ˜¯ä»»ä½•æ¨¡å‹éƒ½å¿…éœ€çš„æ­¥éª¤ã€‚\n",
    "        A.Normalize(mean=mean, std=std),\n",
    "        ToTensorV2(),\n",
    "        ])\n",
    "         # 2. éªŒè¯å’Œæµ‹è¯•é›†çš„é¢„å¤„ç† (åŒæ ·ä¿æŒæœ€çŸ­è¾¹ç¼©æ”¾ï¼Œä¿è¯å¤„ç†é€»è¾‘ä¸€è‡´æ€§)\n",
    "        val_test_transform = A.Compose([\n",
    "            A.LongestMaxSize(max_size=224, p=1.0),\n",
    "            A.PadIfNeeded(min_height=224, min_width=224, border_mode=0, value=134, p=1.0),\n",
    "            A.Normalize(mean,std),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    return(train_transform ,val_test_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8221366",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T02:35:43.593106Z",
     "iopub.status.busy": "2025-10-29T02:35:43.592314Z",
     "iopub.status.idle": "2025-10-29T02:35:43.601083Z",
     "shell.execute_reply": "2025-10-29T02:35:43.600188Z"
    },
    "papermill": {
     "duration": 0.044969,
     "end_time": "2025-10-29T02:35:43.602483",
     "exception": false,
     "start_time": "2025-10-29T02:35:43.557514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# å®šä¹‰å…¨å±€ç±»åˆ«æ˜ å°„å’Œåç§°åˆ—è¡¨ï¼Œæ–¹ä¾¿åç»­ä½¿ç”¨\n",
    "CLASS_MAP = {\n",
    "    'Crack': 0, 'Loose': 1,\n",
    "    'Mud Pumping': 2, 'Pipeline': 3, 'Redar': 4, 'Void': 5,\n",
    "     'Water Abnormality': 6, 'stell_rib': 7 \n",
    "\n",
    "}\n",
    "CLASS_NAMES = [name for name, idx in sorted(CLASS_MAP.items(), key=lambda item: item[1])]\n",
    "\n",
    "# æ–°çš„ DatasetImage ç±»ï¼Œä½¿ç”¨ albumentations\n",
    "class DatasetImage(Dataset):\n",
    "    def __init__(self, file_names, transform=None):\n",
    "        self.file_names = file_names\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_file_name = self.file_names[idx]\n",
    "        # è¯»å–å›¾åƒ (Albumentations éœ€è¦ RGB æ ¼å¼)\n",
    "        image = cv2.imread(img_file_name)\n",
    "        if image is None: raise ValueError(f\"æ— æ³•è¯»å–å›¾åƒ: {img_file_name}\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # åº”ç”¨å¢å¼º\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        \n",
    "        # è·å–æ ‡ç­¾\n",
    "        class_name = os.path.basename(os.path.dirname(img_file_name))\n",
    "        cls = torch.tensor(CLASS_MAP[class_name], dtype=torch.long)\n",
    "        \n",
    "        return img_file_name, image, cls\n",
    "\n",
    "# KaggleTestDataset ä¿æŒä¸å˜...\n",
    "class KaggleTestDataset(Dataset):\n",
    "    def __init__(self, file_paths, transform=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.file_paths[idx]\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return os.path.basename(img_path), img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e55d9b5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T02:35:43.671898Z",
     "iopub.status.busy": "2025-10-29T02:35:43.671354Z",
     "iopub.status.idle": "2025-10-29T02:35:43.676611Z",
     "shell.execute_reply": "2025-10-29T02:35:43.675964Z"
    },
    "papermill": {
     "duration": 0.040845,
     "end_time": "2025-10-29T02:35:43.677879",
     "exception": false,
     "start_time": "2025-10-29T02:35:43.637034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def my_get_encoder(name, num_classes=1, pretrained=True, drop_rate=0.0): # 1. æ–°å¢ drop_rate å‚æ•°\n",
    "    # 2. åœ¨åˆ›å»ºæ¨¡å‹æ—¶ï¼Œå°† drop_rate ä¼ é€’ç»™ timm\n",
    "    #    timm ä¼šè‡ªåŠ¨å°†å…¶åº”ç”¨åˆ°æ¨¡å‹çš„åˆ†ç±»å¤´\n",
    "    encoder = timm.create_model(name, pretrained=pretrained, num_classes=num_classes, drop_rate=drop_rate)\n",
    "    return encoder\n",
    "\n",
    "class ClassificationModel(nn.Module):\n",
    "    # 3. åœ¨åˆå§‹åŒ–æ—¶æ¥æ”¶ drop_rate\n",
    "    def __init__(self, encoder, classnum, pretrained=True, drop_rate=0.0): \n",
    "        super().__init__()\n",
    "        # 4. å°† drop_rate ä¼ é€’ä¸‹å»\n",
    "        self.clf_model = my_get_encoder(encoder, num_classes=classnum, pretrained=pretrained, drop_rate=drop_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.clf_model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a93bca3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T02:35:43.744944Z",
     "iopub.status.busy": "2025-10-29T02:35:43.744569Z",
     "iopub.status.idle": "2025-10-29T02:35:43.765783Z",
     "shell.execute_reply": "2025-10-29T02:35:43.764987Z"
    },
    "papermill": {
     "duration": 0.05609,
     "end_time": "2025-10-29T02:35:43.767065",
     "exception": false,
     "start_time": "2025-10-29T02:35:43.710975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _calculate_metrics(metrics, mode, compute_cm):\n",
    "    # --- è®¡ç®—æ•´ä½“æŒ‡æ ‡ ---\n",
    "    precision = precision_score(metrics['all_targets'], metrics['all_preds'], average='weighted', zero_division=0)\n",
    "    recall = recall_score(metrics['all_targets'], metrics['all_preds'], average='weighted', zero_division=0)\n",
    "    f1 = f1_score(metrics['all_targets'], metrics['all_preds'], average='weighted', zero_division=0)\n",
    "    f1_weighted = f1_score(metrics['all_targets'], metrics['all_preds'], average='weighted', zero_division=0)\n",
    "    f1_macro = f1_score(metrics['all_targets'], metrics['all_preds'], average='macro', zero_division=0) # <--- æ·»åŠ è¿™ä¸€è¡Œ\n",
    "    # auc_macro, auc_weighted = 0.0, 0.0\n",
    "    auc_macro, auc_weighted = 0.0, 0.0\n",
    "    try:\n",
    "        auc_macro = roc_auc_score(metrics['all_targets'], metrics['all_probs'], multi_class='ovr', average='macro')\n",
    "        auc_weighted = roc_auc_score(metrics['all_targets'], metrics['all_probs'], multi_class='ovr', average='weighted')\n",
    "    except Exception as e:\n",
    "        logging.error(f\"AUCè®¡ç®—å¤±è´¥: {e}\")\n",
    "\n",
    "    # --- è®¡ç®—æ··æ·†çŸ©é˜µå’Œå„ç±»åˆ«æŒ‡æ ‡ ---\n",
    "    cm = confusion_matrix(metrics['all_targets'], metrics['all_preds']) if compute_cm and (mode in ['test', 'val']) else None\n",
    "    per_class_recall = None\n",
    "    per_class_precision = None\n",
    "    if cm is not None:\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            # å„ç±»åˆ«å¬å›ç‡(Recall) = å¯¹è§’çº¿å…ƒç´  / å¯¹åº”è¡Œçš„æ€»å’Œ\n",
    "            # è¿™ä¹Ÿç­‰åŒäºè¯¥ç±»åˆ«çš„å‡†ç¡®ç‡ (True Positive Rate)\n",
    "            per_class_recall = cm.diagonal() / cm.sum(axis=1)\n",
    "            per_class_recall[np.isnan(per_class_recall)] = 0\n",
    "\n",
    "            # å„ç±»åˆ«ç²¾ç¡®ç‡(Precision) = å¯¹è§’çº¿å…ƒç´  / å¯¹åº”åˆ—çš„æ€»å’Œ\n",
    "            per_class_precision = cm.diagonal() / cm.sum(axis=0)\n",
    "            per_class_precision[np.isnan(per_class_precision)] = 0\n",
    "\n",
    "    return {\n",
    "        'loss': metrics['loss'].avg, 'accuracy': metrics['accuracy'].avg,\n",
    "        'precision': precision, 'recall': recall, 'f1': f1_weighted, 'f1_macro': f1_macro, # <--- ä¿®æ”¹è¿™ä¸€è¡Œ\n",
    "        'auc_macro': auc_macro, 'auc_weighted': auc_weighted,\n",
    "        'confusion_matrix': cm,\n",
    "        'per_class_recall': per_class_recall,\n",
    "        'per_class_precision': per_class_precision\n",
    "    }\n",
    "\n",
    "\n",
    "def run_epoch(mode, model, data_loader, criterion, device, epoch, optimizer=None, writer=None, compute_cm=False, args=None):\n",
    "    is_training = (mode == 'train')\n",
    "    model.train() if is_training else model.eval()\n",
    "    torch.set_grad_enabled(is_training)\n",
    "    metrics = {'loss': AverageMeter(\"Loss\", \".16f\"), 'accuracy': AverageMeter(\"Acc\", \".8f\"), 'all_preds': [], 'all_targets': [], 'all_probs': []}\n",
    "    pbar = tqdm(data_loader, desc=f\"{mode.capitalize()} Epoch {epoch}\")\n",
    "    inference_start_time = time.time()   #è®°å½•æ—¶é—´\n",
    "    \n",
    "    # ğŸ”¥ ä¿®å¤: å¦‚æœæ²¡æœ‰ä¼ å…¥ args,å°±åˆ›å»ºä¸€ä¸ªé»˜è®¤çš„\n",
    "    if args is None:\n",
    "        args = KaggleConfig()\n",
    "    \n",
    "    for _, (file_name, images, target) in enumerate(pbar):\n",
    "        images, target = images.to(device), target.to(device)\n",
    "        output = model(images)\n",
    "        loss = criterion(output, target)\n",
    "        if is_training:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        probs = torch.softmax(output, dim=1).detach().cpu().numpy()\n",
    "        preds = output.argmax(dim=1).cpu().numpy()\n",
    "        # -- æ ¸å¿ƒä¿®æ­£ï¼šç»Ÿä¸€å¤„ç†ç¡¬æ ‡ç­¾å’Œè½¯æ ‡ç­¾ --\n",
    "        if args.use_hybrid_mix and target.ndim == 2:\n",
    "            # å¯¹äºè½¯æ ‡ç­¾ï¼Œå– argmax å¾—åˆ°æ•´æ•°æ ‡ç­¾ç”¨äºè®¡ç®—æŒ‡æ ‡\n",
    "            true_labels_for_metrics = target.argmax(dim=1)\n",
    "        else:\n",
    "            # å¯¹äºç¡¬æ ‡ç­¾ï¼Œç›´æ¥ä½¿ç”¨\n",
    "            true_labels_for_metrics = target\n",
    "\n",
    "        # ä½¿ç”¨ä¿®æ­£åçš„ true_labels_for_metrics æ¥ä¿å­˜å’Œè®¡ç®—\n",
    "        metrics['all_probs'].extend(probs);\n",
    "        metrics['all_preds'].extend(preds); \n",
    "        #metrics['all_targets'].extend(target.cpu().numpy())\n",
    "        metrics['loss'].update(loss.item(), images.size(0))\n",
    "        metrics['all_targets'].extend(true_labels_for_metrics.cpu().numpy())\n",
    "        #metrics['accuracy'].update((preds == target.cpu().numpy()).mean(), images.size(0))\n",
    "        # å°†è¿™ä¸€è¡Œ:\n",
    "        # metrics['accuracy'].update((preds == target.cpu().numpy()).mean(), images.size(0))\n",
    "        # æ›¿æ¢ä¸ºä¸‹é¢è¿™ä¸ªä»£ç å—:\n",
    "        if args.use_hybrid_mix and target.ndim == 2:\n",
    "            # å¯¹äºCutMix/MixUpç”Ÿæˆçš„è½¯æ ‡ç­¾(2D)ï¼Œæ¯”è¾ƒå®ƒä»¬çš„argmax\n",
    "            true_labels = target.argmax(dim=1)\n",
    "        else:\n",
    "            # å¯¹äºæ™®é€šçš„ç¡¬æ ‡ç­¾(1D)\n",
    "            true_labels = target\n",
    "        metrics['accuracy'].update((preds == true_labels.cpu().numpy()).mean(), images.size(0))\n",
    "        pbar.set_description(f\"{mode:5} | Loss:{metrics['loss'].avg:.3f} Acc:{metrics['accuracy'].avg:.2%}\")\n",
    "    \n",
    "    inference_end_time = time.time()\n",
    "    final_metrics = _calculate_metrics(metrics, mode, compute_cm)\n",
    "\n",
    "    # --- å†™å…¥TensorBoardæ—¥å¿— ---\n",
    "    if writer:\n",
    "        prefix = f\"{mode}/\"\n",
    "        writer.add_scalar(f'{prefix}loss', final_metrics['loss'], epoch)\n",
    "        writer.add_scalar(f'{prefix}accuracy', final_metrics['accuracy'], epoch)\n",
    "        writer.add_scalar(f'{prefix}precision_weighted', final_metrics['precision'], epoch)\n",
    "        writer.add_scalar(f'{prefix}recall_weighted', final_metrics['recall'], epoch)\n",
    "        writer.add_scalar(f'{prefix}f1_weighted', final_metrics['f1'], epoch)\n",
    "        writer.add_scalar(f'{prefix}f1_macro', final_metrics['f1_macro'], epoch) # <--- æ·»åŠ è¿™ä¸€è¡Œ\n",
    "        #writer.add_scalar(f'{prefix}auc_macro', final_metrics['auc_macro'], epoch)\n",
    "        writer.add_scalar(f'{prefix}auc_macro', final_metrics['auc_macro'], epoch)\n",
    "        writer.add_scalar(f'{prefix}auc_weighted', final_metrics['auc_weighted'], epoch)\n",
    "\n",
    "        # å†™å…¥æ··æ·†çŸ©é˜µå›¾\n",
    "        if final_metrics.get('confusion_matrix') is not None and mode in ['val', 'test']:\n",
    "            writer.add_image(f'{prefix}confusion_matrix', cm_to_figure(final_metrics['confusion_matrix']), epoch)\n",
    "\n",
    "        # (æ–°å¢) å†™å…¥å„ç±»åˆ«æŒ‡æ ‡\n",
    "        if mode == 'test':\n",
    "            \n",
    "            report = classification_report(metrics['all_targets'], metrics['all_preds'], target_names=CLASS_NAMES, output_dict=True, zero_division=0)\n",
    "            \n",
    "            for class_name, class_metrics in report.items():\n",
    "                if isinstance(class_metrics, dict): # ç¡®ä¿åªå¤„ç†ç±»åˆ«è¡Œ\n",
    "                    writer.add_scalar(f'{prefix}{class_name}/precision', class_metrics['precision'], epoch)\n",
    "                    writer.add_scalar(f'{prefix}{class_name}/recall', class_metrics['recall'], epoch)\n",
    "                    writer.add_scalar(f'{prefix}{class_name}/f1-score', class_metrics['f1-score'], epoch)\n",
    "                    writer.add_scalar(f'{prefix}{class_name}/support', class_metrics['support'], epoch)\n",
    "            logging.info(\"å·²å°†æ¯ä¸ªç±»åˆ«çš„è¯¦ç»†æµ‹è¯•æŒ‡æ ‡å†™å…¥TensorBoardã€‚\")\n",
    "\n",
    "    \n",
    "    # ä¿®æ­£äº†è¿™é‡Œçš„å˜é‡åï¼šfinal_files -> final_metrics\n",
    "    log_message = (f\"{mode.capitalize()} Results - Loss: {final_metrics['loss']:.4f} | \"\n",
    "               f\"Accuracy: {final_metrics['accuracy']:.4%} | \"\n",
    "               f\"F1_weighted: {final_metrics['f1']:.4%} | \"\n",
    "               f\"F1_macro: {final_metrics['f1_macro']:.4%}\")\n",
    "    if mode == 'test':\n",
    "        total_inference_time = inference_end_time - inference_start_time\n",
    "        num_samples = len(data_loader.dataset)\n",
    "        fps = num_samples / total_inference_time\n",
    "        log_message += f\" | Inference Speed: {fps:.2f} FPS\"\n",
    "        logging.info(f\"æ€»æ¨ç†æ—¶é—´ (Total Inference Time): {total_inference_time:.2f} seconds for {num_samples} images.\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"âœ… æ€»æ¨ç†æ—¶é—´ (Total Inference Time): {total_inference_time:.2f} seconds for {num_samples} images.\")\n",
    "        print(f\"âœ… æ¨ç†é€Ÿåº¦ (Inference Speed): {fps:.2f} FPS\")\n",
    "        print(log_message) # ä¹Ÿç”¨ print è¾“å‡ºæœ€ç»ˆæŒ‡æ ‡\n",
    "        print(\"-\" * 50)\n",
    "    logging.info(log_message)\n",
    "    \n",
    "    # ğŸ”¥ ä¿®å¤: ä»ä¼ å…¥çš„ args è·å– run_id\n",
    "    encoder_lr = getattr(args, 'run_id', None)\n",
    "    save_metrics_to_excel(f\"{mode}_metrics.xlsx\", epoch, encoder_lr=encoder_lr, **final_metrics)\n",
    "    return final_metrics\n",
    "\n",
    "\n",
    "def predict_on_test(model, data_loader, device):\n",
    "    model.eval()\n",
    "    all_filenames, all_predictions = [], []\n",
    "    with torch.no_grad():\n",
    "        for filenames, images in tqdm(data_loader, desc=\"Predicting\"):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "            all_filenames.extend(filenames)\n",
    "            all_predictions.extend(preds)\n",
    "    return all_filenames, all_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97052413",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T02:35:43.834411Z",
     "iopub.status.busy": "2025-10-29T02:35:43.833632Z",
     "iopub.status.idle": "2025-10-29T02:35:43.839264Z",
     "shell.execute_reply": "2025-10-29T02:35:43.838569Z"
    },
    "papermill": {
     "duration": 0.040631,
     "end_time": "2025-10-29T02:35:43.840498",
     "exception": false,
     "start_time": "2025-10-29T02:35:43.799867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_scheduler(optimizer, phase, args, num_epochs_stage1=None):\n",
    "    \"\"\"\n",
    "    phase: \"stage1\" æˆ– \"stage2\"\n",
    "    num_epochs_stage1: é˜¶æ®µä¸€çš„è®­ç»ƒè½®æ•°ï¼ˆä»…ç”¨äºè®¡ç®— stage2 çš„ T_maxï¼‰\n",
    "    \"\"\"\n",
    "    if args.lr_scheduler == \"cosine\":\n",
    "        if phase == \"stage1\":\n",
    "            return torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "                optimizer, T_max=args.stage1_tmax, eta_min=args.min_lr\n",
    "            )\n",
    "        else:  # stage2\n",
    "            # æ ¹æ®æ€» epoch è‡ªåŠ¨è®¡ç®—é˜¶æ®µäºŒçš„ T_max\n",
    "            tmax_stage2 = args.num_epochs - (num_epochs_stage1 or 0)\n",
    "            return torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "                optimizer, T_max=tmax_stage2, eta_min=args.min_lr\n",
    "            )\n",
    "    else:  # \"plateau\"\n",
    "        # æ³¨æ„ï¼šPlateau çš„ step éœ€è¦ä¼ å…¥éªŒè¯æŸå¤±ï¼Œæˆ‘ä»¬åœ¨è®­ç»ƒå¾ªç¯é‡Œå¤„ç†\n",
    "        return torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode=\"min\",\n",
    "            factor=args.plateau_factor,\n",
    "            patience=args.plateau_patience,\n",
    "            min_lr=args.min_lr,\n",
    "            verbose=True\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76f1a12d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T02:35:43.909293Z",
     "iopub.status.busy": "2025-10-29T02:35:43.909016Z",
     "iopub.status.idle": "2025-10-29T05:36:26.591133Z",
     "shell.execute_reply": "2025-10-29T05:36:26.590062Z"
    },
    "papermill": {
     "duration": 10842.718526,
     "end_time": "2025-10-29T05:36:26.592642",
     "exception": false,
     "start_time": "2025-10-29T02:35:43.874116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "\n",
      "======================================================================\n",
      "ğŸ”¥ å¼€å§‹ 5 æŠ˜äº¤å‰éªŒè¯è®­ç»ƒ\n",
      "æ¨¡å‹: mobilenetv3_large_100 | å­¦ä¹ ç‡: 1e-05\n",
      "======================================================================\n",
      "\n",
      "æ€»è®­ç»ƒ+éªŒè¯æ–‡ä»¶æ•°: 2754\n",
      "æµ‹è¯•æ–‡ä»¶æ•°: 683\n",
      "\n",
      "======================================================================\n",
      "ğŸ”¥ å¼€å§‹è®­ç»ƒ Fold 1/5\n",
      "======================================================================\n",
      "\n",
      "æ‰¾åˆ° 2203 ä¸ªè®­ç»ƒæ–‡ä»¶, 551 ä¸ªéªŒè¯æ–‡ä»¶, 683 ä¸ªæµ‹è¯•æ–‡ä»¶\n",
      "Calculating mean and std of training set for data normalization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2203/2203 [00:28<00:00, 78.55it/s]\n",
      "/tmp/ipykernel_19/1154223942.py:69: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=224, min_width=224, border_mode=0, value=134, p=1.0),\n",
      "/tmp/ipykernel_19/1154223942.py:75: UserWarning: Argument(s) 'alpha_affine' are not valid for transform ElasticTransform\n",
      "  A.ElasticTransform(p=0.5, alpha=20, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n",
      "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "/tmp/ipykernel_19/1154223942.py:88: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(5.0, 30.0), p=1.0),  # âœ… é™ä½å™ªå£°å¼ºåº¦: 10~50 -> 5~30\n",
      "/tmp/ipykernel_19/1154223942.py:91: UserWarning: Argument(s) 'max_holes, max_height, max_width, min_holes, fill_value' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(\n",
      "/tmp/ipykernel_19/1154223942.py:120: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=224, min_width=224, border_mode=0, value=134, p=1.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean (RGB): [0.49715162577510535, 0.49943902106757904, 0.5020123172567167]\n",
      "Std  (RGB): [0.15914664258290495, 0.15962691844790716, 0.15891394991650823]\n",
      "æ­£åœ¨è®¡ç®—ç±»åˆ«æƒé‡ä»¥å¤„ç†æ•°æ®ä¸å¹³è¡¡é—®é¢˜...\n",
      "è®¡ç®—å‡ºçš„ç±»åˆ«æƒé‡: [0.61330736 1.330314   1.039151   1.0510496  1.5735714  0.7607044\n",
      " 1.9392606  0.8075513 ]\n",
      "\n",
      "æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹: mobilenetv3_large_100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adac39c2443c4f5088c086f921c0a2bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/22.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "âœ… æ¨¡å‹å‚æ•°é‡ (Parameters): 4.21 M\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… FLOPs: 0.22 G\n",
      "============================================================\n",
      "æ­£åœ¨ä½¿ç”¨ FocalLoss\n",
      "\n",
      "==================================================\n",
      "ğŸ”¥ é˜¶æ®µä¸€: å†»ç»“ä¸»å¹²ç½‘ç»œï¼Œåªè®­ç»ƒåˆ†ç±»å¤´\n",
      "==================================================\n",
      "æ¨¡å‹ä¸»å¹²å·²å†»ç»“ï¼Œåªè®­ç»ƒæœ€åçš„ 'classifier' å±‚ã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train | Loss:3.244 Acc:18.24%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.69it/s]\n",
      "val   | Loss:2.361 Acc:28.13%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:04<00:00,  2.00it/s]\n",
      "train | Loss:2.030 Acc:30.56%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.68it/s]\n",
      "val   | Loss:1.581 Acc:42.29%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.88it/s]\n",
      "train | Loss:1.575 Acc:41.54%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.66it/s]\n",
      "val   | Loss:1.238 Acc:49.91%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.75it/s]\n",
      "train | Loss:1.235 Acc:48.81%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.56it/s]\n",
      "val   | Loss:1.044 Acc:55.35%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.87it/s]\n",
      "train | Loss:1.081 Acc:52.71%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.67it/s]\n",
      "val   | Loss:0.891 Acc:58.80%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.90it/s]\n",
      "train | Loss:0.889 Acc:56.48%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.60it/s]\n",
      "val   | Loss:0.770 Acc:61.71%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.84it/s]\n",
      "train | Loss:0.797 Acc:59.51%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.73it/s]\n",
      "val   | Loss:0.682 Acc:64.61%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.87it/s]\n",
      "train | Loss:0.712 Acc:61.63%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.54it/s]\n",
      "val   | Loss:0.609 Acc:67.70%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.66it/s]\n",
      "train | Loss:0.652 Acc:64.38%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.68it/s]\n",
      "val   | Loss:0.555 Acc:70.05%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.86it/s]\n",
      "train | Loss:0.597 Acc:65.49%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.60it/s]\n",
      "val   | Loss:0.513 Acc:72.23%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.90it/s]\n",
      "train | Loss:0.583 Acc:66.87%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.66it/s]\n",
      "val   | Loss:0.486 Acc:73.32%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.96it/s]\n",
      "train | Loss:0.550 Acc:67.65%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.65it/s]\n",
      "val   | Loss:0.458 Acc:75.32%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.87it/s]\n",
      "train | Loss:0.515 Acc:69.67%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.73it/s]\n",
      "val   | Loss:0.440 Acc:77.13%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.96it/s]\n",
      "train | Loss:0.462 Acc:72.43%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.67it/s]\n",
      "val   | Loss:0.428 Acc:76.59%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.87it/s]\n",
      "train | Loss:0.469 Acc:73.12%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.61it/s]\n",
      "val   | Loss:0.406 Acc:77.68%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.97it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”¥ é˜¶æ®µäºŒ: è§£å†»æ‰€æœ‰å±‚ï¼Œè¿›è¡Œå…¨å±€å¾®è°ƒ\n",
      "==================================================\n",
      "åŠ è½½é˜¶æ®µä¸€çš„æœ€ä½³æ¨¡å‹æƒé‡...\n",
      "æ‰€æœ‰å±‚å·²è§£å†»ã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train | Loss:0.434 Acc:73.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.53it/s]\n",
      "val   | Loss:0.398 Acc:78.58%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.73it/s]\n",
      "train | Loss:0.428 Acc:75.28%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.54it/s]\n",
      "val   | Loss:0.392 Acc:79.13%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.83it/s]\n",
      "train | Loss:0.430 Acc:74.26%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.60it/s]\n",
      "val   | Loss:0.383 Acc:78.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.97it/s]\n",
      "train | Loss:0.410 Acc:74.91%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.52it/s]\n",
      "val   | Loss:0.383 Acc:79.67%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.85it/s]\n",
      "train | Loss:0.396 Acc:75.23%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.56it/s]\n",
      "val   | Loss:0.376 Acc:78.77%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.03it/s]\n",
      "train | Loss:0.383 Acc:76.19%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.52it/s]\n",
      "val   | Loss:0.370 Acc:78.77%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.89it/s]\n",
      "train | Loss:0.384 Acc:76.98%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.60it/s]\n",
      "val   | Loss:0.369 Acc:79.31%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.88it/s]\n",
      "train | Loss:0.393 Acc:75.74%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.54it/s]\n",
      "val   | Loss:0.363 Acc:78.58%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.89it/s]\n",
      "train | Loss:0.372 Acc:76.33%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.52it/s]\n",
      "val   | Loss:0.355 Acc:79.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.79it/s]\n",
      "train | Loss:0.391 Acc:75.55%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.62it/s]\n",
      "val   | Loss:0.351 Acc:79.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.96it/s]\n",
      "train | Loss:0.365 Acc:77.39%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.64it/s]\n",
      "val   | Loss:0.353 Acc:79.49%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.00it/s]\n",
      "train | Loss:0.367 Acc:75.83%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.61it/s]\n",
      "val   | Loss:0.349 Acc:80.22%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.96it/s]\n",
      "train | Loss:0.371 Acc:77.11%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.67it/s]\n",
      "val   | Loss:0.342 Acc:79.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.04it/s]\n",
      "train | Loss:0.369 Acc:76.93%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.62it/s]\n",
      "val   | Loss:0.345 Acc:80.22%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.83it/s]\n",
      "train | Loss:0.360 Acc:77.71%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.338 Acc:80.04%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.77it/s]\n",
      "train | Loss:0.360 Acc:76.98%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.56it/s]\n",
      "val   | Loss:0.337 Acc:80.22%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.64it/s]\n",
      "train | Loss:0.374 Acc:77.44%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.50it/s]\n",
      "val   | Loss:0.335 Acc:81.13%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.68it/s]\n",
      "train | Loss:0.360 Acc:77.07%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.43it/s]\n",
      "val   | Loss:0.331 Acc:80.76%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.89it/s]\n",
      "train | Loss:0.356 Acc:78.81%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.51it/s]\n",
      "val   | Loss:0.328 Acc:80.94%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.79it/s]\n",
      "train | Loss:0.350 Acc:77.62%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.52it/s]\n",
      "val   | Loss:0.325 Acc:80.58%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.70it/s]\n",
      "train | Loss:0.337 Acc:78.08%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.55it/s]\n",
      "val   | Loss:0.321 Acc:79.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.83it/s]\n",
      "train | Loss:0.338 Acc:79.09%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.56it/s]\n",
      "val   | Loss:0.318 Acc:80.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.90it/s]\n",
      "train | Loss:0.339 Acc:78.91%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.54it/s]\n",
      "val   | Loss:0.318 Acc:80.76%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.83it/s]\n",
      "train | Loss:0.326 Acc:79.00%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.54it/s]\n",
      "val   | Loss:0.317 Acc:80.94%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.93it/s]\n",
      "train | Loss:0.321 Acc:79.00%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.63it/s]\n",
      "val   | Loss:0.317 Acc:80.94%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.88it/s]\n",
      "train | Loss:0.313 Acc:80.84%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.58it/s]\n",
      "val   | Loss:0.312 Acc:81.31%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.89it/s]\n",
      "train | Loss:0.317 Acc:79.69%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.65it/s]\n",
      "val   | Loss:0.311 Acc:80.58%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.95it/s]\n",
      "train | Loss:0.310 Acc:79.92%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.67it/s]\n",
      "val   | Loss:0.309 Acc:81.67%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.98it/s]\n",
      "train | Loss:0.329 Acc:79.32%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.64it/s]\n",
      "val   | Loss:0.305 Acc:81.67%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.11it/s]\n",
      "train | Loss:0.313 Acc:79.60%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.67it/s]\n",
      "val   | Loss:0.306 Acc:81.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.04it/s]\n",
      "train | Loss:0.310 Acc:79.64%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.66it/s]\n",
      "val   | Loss:0.303 Acc:81.67%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.99it/s]\n",
      "train | Loss:0.315 Acc:79.83%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.63it/s]\n",
      "val   | Loss:0.303 Acc:81.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.03it/s]\n",
      "train | Loss:0.315 Acc:79.55%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.67it/s]\n",
      "val   | Loss:0.300 Acc:81.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.97it/s]\n",
      "train | Loss:0.310 Acc:79.92%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.60it/s]\n",
      "val   | Loss:0.301 Acc:81.67%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.83it/s]\n",
      "train | Loss:0.308 Acc:80.79%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.64it/s]\n",
      "val   | Loss:0.298 Acc:81.31%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.84it/s]\n",
      "train | Loss:0.304 Acc:80.28%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.67it/s]\n",
      "val   | Loss:0.295 Acc:82.76%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.93it/s]\n",
      "train | Loss:0.306 Acc:79.92%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.69it/s]\n",
      "val   | Loss:0.296 Acc:82.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.01it/s]\n",
      "train | Loss:0.297 Acc:80.24%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.69it/s]\n",
      "val   | Loss:0.292 Acc:82.21%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.03it/s]\n",
      "train | Loss:0.292 Acc:80.24%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.70it/s]\n",
      "val   | Loss:0.290 Acc:82.21%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.88it/s]\n",
      "train | Loss:0.302 Acc:80.33%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.57it/s]\n",
      "val   | Loss:0.292 Acc:82.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.03it/s]\n",
      "train | Loss:0.299 Acc:80.42%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.64it/s]\n",
      "val   | Loss:0.291 Acc:82.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.07it/s]\n",
      "train | Loss:0.287 Acc:80.01%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.60it/s]\n",
      "val   | Loss:0.286 Acc:82.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.96it/s]\n",
      "train | Loss:0.288 Acc:80.70%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.65it/s]\n",
      "val   | Loss:0.288 Acc:82.58%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.85it/s]\n",
      "train | Loss:0.298 Acc:79.92%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.61it/s]\n",
      "val   | Loss:0.287 Acc:82.21%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.02it/s]\n",
      "train | Loss:0.283 Acc:80.88%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.67it/s]\n",
      "val   | Loss:0.283 Acc:82.58%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.98it/s]\n",
      "train | Loss:0.278 Acc:81.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.60it/s]\n",
      "val   | Loss:0.285 Acc:82.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.00it/s]\n",
      "train | Loss:0.284 Acc:82.08%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.66it/s]\n",
      "val   | Loss:0.283 Acc:82.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.01it/s]\n",
      "train | Loss:0.284 Acc:80.79%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.64it/s]\n",
      "val   | Loss:0.282 Acc:82.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.85it/s]\n",
      "train | Loss:0.277 Acc:81.48%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.64it/s]\n",
      "val   | Loss:0.282 Acc:82.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.74it/s]\n",
      "train | Loss:0.291 Acc:81.16%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.64it/s]\n",
      "val   | Loss:0.282 Acc:82.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.80it/s]\n",
      "train | Loss:0.282 Acc:81.34%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.66it/s]\n",
      "val   | Loss:0.279 Acc:82.58%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.85it/s]\n",
      "train | Loss:0.276 Acc:83.23%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.72it/s]\n",
      "val   | Loss:0.280 Acc:82.58%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.02it/s]\n",
      "train | Loss:0.284 Acc:81.34%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.68it/s]\n",
      "val   | Loss:0.280 Acc:82.58%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.95it/s]\n",
      "train | Loss:0.266 Acc:81.76%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.69it/s]\n",
      "val   | Loss:0.279 Acc:82.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.84it/s]\n",
      "train | Loss:0.283 Acc:81.80%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.66it/s]\n",
      "val   | Loss:0.280 Acc:82.94%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.93it/s]\n",
      "train | Loss:0.282 Acc:81.62%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.69it/s]\n",
      "val   | Loss:0.276 Acc:82.76%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.90it/s]\n",
      "train | Loss:0.266 Acc:81.99%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.68it/s]\n",
      "val   | Loss:0.275 Acc:83.48%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.01it/s]\n",
      "train | Loss:0.262 Acc:82.63%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.66it/s]\n",
      "val   | Loss:0.273 Acc:82.76%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.59it/s]\n",
      "train | Loss:0.266 Acc:82.49%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.47it/s]\n",
      "val   | Loss:0.274 Acc:82.76%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.78it/s]\n",
      "train | Loss:0.267 Acc:82.49%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.51it/s]\n",
      "val   | Loss:0.273 Acc:83.12%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.84it/s]\n",
      "train | Loss:0.266 Acc:82.49%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.60it/s]\n",
      "val   | Loss:0.274 Acc:82.76%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.79it/s]\n",
      "train | Loss:0.258 Acc:82.95%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.49it/s]\n",
      "val   | Loss:0.276 Acc:82.94%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.73it/s]\n",
      "train | Loss:0.258 Acc:83.46%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.52it/s]\n",
      "val   | Loss:0.274 Acc:83.48%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.85it/s]\n",
      "train | Loss:0.258 Acc:82.58%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.55it/s]\n",
      "val   | Loss:0.273 Acc:82.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.80it/s]\n",
      "train | Loss:0.268 Acc:81.66%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.60it/s]\n",
      "val   | Loss:0.271 Acc:83.30%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.79it/s]\n",
      "train | Loss:0.264 Acc:81.34%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.56it/s]\n",
      "val   | Loss:0.269 Acc:82.76%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.77it/s]\n",
      "train | Loss:0.251 Acc:82.22%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.49it/s]\n",
      "val   | Loss:0.270 Acc:83.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.78it/s]\n",
      "train | Loss:0.252 Acc:82.63%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.53it/s]\n",
      "val   | Loss:0.267 Acc:82.94%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.93it/s]\n",
      "train | Loss:0.252 Acc:83.09%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.54it/s]\n",
      "val   | Loss:0.269 Acc:83.30%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.85it/s]\n",
      "train | Loss:0.239 Acc:84.05%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.52it/s]\n",
      "val   | Loss:0.268 Acc:82.58%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.71it/s]\n",
      "train | Loss:0.257 Acc:82.49%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.58it/s]\n",
      "val   | Loss:0.268 Acc:83.12%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.89it/s]\n",
      "train | Loss:0.252 Acc:83.64%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.56it/s]\n",
      "val   | Loss:0.266 Acc:83.12%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.92it/s]\n",
      "train | Loss:0.249 Acc:82.72%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.54it/s]\n",
      "val   | Loss:0.267 Acc:82.58%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.87it/s]\n",
      "train | Loss:0.261 Acc:83.00%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.53it/s]\n",
      "val   | Loss:0.265 Acc:83.30%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.90it/s]\n",
      "train | Loss:0.249 Acc:83.13%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.263 Acc:83.30%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.82it/s]\n",
      "train | Loss:0.254 Acc:82.77%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.68it/s]\n",
      "val   | Loss:0.264 Acc:83.30%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.18it/s]\n",
      "train | Loss:0.255 Acc:83.59%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.72it/s]\n",
      "val   | Loss:0.265 Acc:84.21%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.12it/s]\n",
      "train | Loss:0.236 Acc:84.28%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.70it/s]\n",
      "val   | Loss:0.264 Acc:83.48%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.10it/s]\n",
      "train | Loss:0.232 Acc:84.38%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.73it/s]\n",
      "val   | Loss:0.267 Acc:83.48%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.95it/s]\n",
      "train | Loss:0.252 Acc:82.90%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.68it/s]\n",
      "val   | Loss:0.264 Acc:83.12%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.08it/s]\n",
      "train | Loss:0.235 Acc:84.47%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.71it/s]\n",
      "val   | Loss:0.264 Acc:84.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.98it/s]\n",
      "train | Loss:0.241 Acc:84.47%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.64it/s]\n",
      "val   | Loss:0.262 Acc:84.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.86it/s]\n",
      "train | Loss:0.239 Acc:83.96%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.63it/s]\n",
      "val   | Loss:0.262 Acc:84.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.31it/s]\n",
      "train | Loss:0.241 Acc:83.92%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.46it/s]\n",
      "val   | Loss:0.263 Acc:83.48%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.88it/s]\n",
      "train | Loss:0.236 Acc:84.97%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.261 Acc:84.21%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.64it/s]\n",
      "train | Loss:0.235 Acc:84.83%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.46it/s]\n",
      "val   | Loss:0.260 Acc:83.67%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.74it/s]\n",
      "train | Loss:0.247 Acc:83.82%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.58it/s]\n",
      "val   | Loss:0.261 Acc:83.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.84it/s]\n",
      "train | Loss:0.240 Acc:83.64%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.56it/s]\n",
      "val   | Loss:0.259 Acc:83.67%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.84it/s]\n",
      "train | Loss:0.226 Acc:84.10%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.49it/s]\n",
      "val   | Loss:0.261 Acc:83.67%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.69it/s]\n",
      "train | Loss:0.236 Acc:84.42%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:14<00:00,  2.40it/s]\n",
      "val   | Loss:0.260 Acc:84.21%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.70it/s]\n",
      "train | Loss:0.234 Acc:85.20%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.44it/s]\n",
      "val   | Loss:0.261 Acc:83.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.62it/s]\n",
      "train | Loss:0.241 Acc:83.96%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:14<00:00,  2.37it/s]\n",
      "val   | Loss:0.260 Acc:84.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.81it/s]\n",
      "train | Loss:0.236 Acc:83.96%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.46it/s]\n",
      "val   | Loss:0.260 Acc:84.21%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.71it/s]\n",
      "train | Loss:0.227 Acc:84.47%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:14<00:00,  2.33it/s]\n",
      "val   | Loss:0.258 Acc:83.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.36it/s]\n",
      "train | Loss:0.227 Acc:84.79%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:15<00:00,  2.25it/s]\n",
      "val   | Loss:0.258 Acc:84.39%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.52it/s]\n",
      "train | Loss:0.228 Acc:84.42%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.45it/s]\n",
      "val   | Loss:0.260 Acc:83.67%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.70it/s]\n",
      "train | Loss:0.237 Acc:84.05%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.49it/s]\n",
      "val   | Loss:0.259 Acc:84.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.67it/s]\n",
      "train | Loss:0.223 Acc:85.25%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.51it/s]\n",
      "val   | Loss:0.263 Acc:84.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.87it/s]\n",
      "train | Loss:0.232 Acc:84.10%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:14<00:00,  2.41it/s]\n",
      "val   | Loss:0.261 Acc:84.21%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.87it/s]\n",
      "train | Loss:0.238 Acc:84.01%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.53it/s]\n",
      "val   | Loss:0.260 Acc:84.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.71it/s]\n",
      "train | Loss:0.223 Acc:85.43%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.46it/s]\n",
      "val   | Loss:0.260 Acc:84.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.73it/s]\n",
      "train | Loss:0.225 Acc:84.42%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.47it/s]\n",
      "val   | Loss:0.261 Acc:84.21%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.68it/s]\n",
      "train | Loss:0.229 Acc:84.70%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.48it/s]\n",
      "val   | Loss:0.261 Acc:83.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.72it/s]\n",
      "train | Loss:0.241 Acc:82.81%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.48it/s]\n",
      "val   | Loss:0.259 Acc:83.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.68it/s]\n",
      "train | Loss:0.225 Acc:85.06%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.50it/s]\n",
      "val   | Loss:0.257 Acc:84.21%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.79it/s]\n",
      "train | Loss:0.214 Acc:85.57%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.52it/s]\n",
      "val   | Loss:0.260 Acc:84.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.68it/s]\n",
      "train | Loss:0.224 Acc:84.93%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.45it/s]\n",
      "val   | Loss:0.258 Acc:84.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.81it/s]\n",
      "train | Loss:0.237 Acc:83.59%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.51it/s]\n",
      "val   | Loss:0.260 Acc:83.67%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.74it/s]\n",
      "train | Loss:0.228 Acc:84.65%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.47it/s]\n",
      "val   | Loss:0.261 Acc:83.67%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.87it/s]\n",
      "train | Loss:0.226 Acc:84.42%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.54it/s]\n",
      "val   | Loss:0.258 Acc:83.30%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.73it/s]\n",
      "train | Loss:0.221 Acc:84.51%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.46it/s]\n",
      "val   | Loss:0.260 Acc:84.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.68it/s]\n",
      "train | Loss:0.227 Acc:84.70%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.48it/s]\n",
      "val   | Loss:0.260 Acc:83.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.83it/s]\n",
      "train | Loss:0.223 Acc:84.70%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.49it/s]\n",
      "val   | Loss:0.258 Acc:83.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.74it/s]\n",
      "train | Loss:0.216 Acc:85.39%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.57it/s]\n",
      "val   | Loss:0.257 Acc:84.21%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.85it/s]\n",
      "train | Loss:0.242 Acc:83.69%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.48it/s]\n",
      "val   | Loss:0.256 Acc:84.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.84it/s]\n",
      "train | Loss:0.220 Acc:84.56%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.53it/s]\n",
      "val   | Loss:0.258 Acc:84.39%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.79it/s]\n",
      "train | Loss:0.238 Acc:84.65%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.51it/s]\n",
      "val   | Loss:0.258 Acc:84.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.83it/s]\n",
      "train | Loss:0.228 Acc:85.16%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.50it/s]\n",
      "val   | Loss:0.258 Acc:84.39%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.71it/s]\n",
      "train | Loss:0.223 Acc:84.24%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.52it/s]\n",
      "val   | Loss:0.258 Acc:84.39%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.89it/s]\n",
      "train | Loss:0.217 Acc:85.48%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.257 Acc:84.39%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.61it/s]\n",
      "train | Loss:0.228 Acc:84.15%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.58it/s]\n",
      "val   | Loss:0.258 Acc:83.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.95it/s]\n",
      "train | Loss:0.236 Acc:84.88%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.259 Acc:83.67%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.54it/s]\n",
      "train | Loss:0.223 Acc:85.02%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.46it/s]\n",
      "val   | Loss:0.257 Acc:84.57%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.77it/s]\n",
      "train | Loss:0.230 Acc:84.47%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.56it/s]\n",
      "val   | Loss:0.260 Acc:84.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.65it/s]\n",
      "train | Loss:0.221 Acc:85.48%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.58it/s]\n",
      "val   | Loss:0.258 Acc:84.39%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.83it/s]\n",
      "train | Loss:0.228 Acc:84.88%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.51it/s]\n",
      "val   | Loss:0.259 Acc:84.21%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.76it/s]\n",
      "train | Loss:0.221 Acc:85.98%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.58it/s]\n",
      "val   | Loss:0.259 Acc:84.39%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.97it/s]\n",
      "train | Loss:0.221 Acc:86.31%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.54it/s]\n",
      "val   | Loss:0.259 Acc:84.21%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.86it/s]\n",
      "train | Loss:0.228 Acc:85.25%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.58it/s]\n",
      "val   | Loss:0.258 Acc:83.48%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.80it/s]\n",
      "train | Loss:0.222 Acc:84.93%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.49it/s]\n",
      "val   | Loss:0.259 Acc:84.39%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.78it/s]\n",
      "train | Loss:0.231 Acc:84.74%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.53it/s]\n",
      "val   | Loss:0.260 Acc:83.67%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.85it/s]\n",
      "train | Loss:0.219 Acc:85.25%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.47it/s]\n",
      "val   | Loss:0.258 Acc:84.21%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.80it/s]\n",
      "train | Loss:0.236 Acc:83.82%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.52it/s]\n",
      "val   | Loss:0.258 Acc:84.21%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.75it/s]\n",
      "train | Loss:0.228 Acc:84.47%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:14<00:00,  2.41it/s]\n",
      "val   | Loss:0.257 Acc:84.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.68it/s]\n",
      "train | Loss:0.230 Acc:85.34%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.53it/s]\n",
      "val   | Loss:0.257 Acc:84.21%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.79it/s]\n",
      "train | Loss:0.215 Acc:84.38%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.53it/s]\n",
      "val   | Loss:0.259 Acc:83.30%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.83it/s]\n",
      "train | Loss:0.225 Acc:83.96%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.56it/s]\n",
      "val   | Loss:0.261 Acc:83.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.00it/s]\n",
      "train | Loss:0.217 Acc:85.02%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.53it/s]\n",
      "val   | Loss:0.258 Acc:84.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.86it/s]\n",
      "train | Loss:0.224 Acc:84.15%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.53it/s]\n",
      "val   | Loss:0.259 Acc:83.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.93it/s]\n",
      "train | Loss:0.221 Acc:85.43%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.53it/s]\n",
      "val   | Loss:0.259 Acc:83.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.88it/s]\n",
      "train | Loss:0.218 Acc:85.48%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.62it/s]\n",
      "val   | Loss:0.257 Acc:84.21%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.87it/s]\n",
      "train | Loss:0.223 Acc:85.25%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.57it/s]\n",
      "val   | Loss:0.262 Acc:83.12%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.86it/s]\n",
      "train | Loss:0.217 Acc:85.29%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.258 Acc:83.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.66it/s]\n",
      "train | Loss:0.217 Acc:84.93%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.54it/s]\n",
      "val   | Loss:0.257 Acc:84.39%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.74it/s]\n",
      "train | Loss:0.233 Acc:84.19%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.61it/s]\n",
      "val   | Loss:0.260 Acc:83.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.84it/s]\n",
      "train | Loss:0.223 Acc:85.02%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.54it/s]\n",
      "val   | Loss:0.258 Acc:84.39%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.92it/s]\n",
      "train | Loss:0.217 Acc:84.93%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.61it/s]\n",
      "val   | Loss:0.258 Acc:83.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.06it/s]\n",
      "train | Loss:0.224 Acc:84.47%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.55it/s]\n",
      "val   | Loss:0.259 Acc:83.67%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.89it/s]\n",
      "train | Loss:0.218 Acc:84.65%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.63it/s]\n",
      "val   | Loss:0.256 Acc:84.21%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.99it/s]\n",
      "train | Loss:0.231 Acc:84.51%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.61it/s]\n",
      "val   | Loss:0.257 Acc:83.12%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.90it/s]\n",
      "train | Loss:0.225 Acc:84.47%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.67it/s]\n",
      "val   | Loss:0.257 Acc:84.21%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.13it/s]\n",
      "train | Loss:0.227 Acc:85.34%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.60it/s]\n",
      "val   | Loss:0.258 Acc:84.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.87it/s]\n",
      "train | Loss:0.215 Acc:84.56%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.63it/s]\n",
      "val   | Loss:0.258 Acc:83.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.89it/s]\n",
      "train | Loss:0.220 Acc:85.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.65it/s]\n",
      "val   | Loss:0.255 Acc:83.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.94it/s]\n",
      "train | Loss:0.231 Acc:84.33%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.63it/s]\n",
      "val   | Loss:0.257 Acc:84.21%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.01it/s]\n",
      "train | Loss:0.223 Acc:85.11%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.257 Acc:83.67%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.90it/s]\n",
      "train | Loss:0.217 Acc:85.98%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.56it/s]\n",
      "val   | Loss:0.258 Acc:84.39%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.95it/s]\n",
      "train | Loss:0.231 Acc:83.13%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.58it/s]\n",
      "val   | Loss:0.256 Acc:84.21%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "ğŸ”¥ è¯„ä¼°å…¨å±€æœ€ä½³æ¨¡å‹ (æ¥è‡ª epoch 138ï¼ŒéªŒè¯é›†å‡†ç¡®ç‡ 84.5735%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test  | Loss:0.253 Acc:83.60%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:05<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "âœ… æ€»æ¨ç†æ—¶é—´ (Total Inference Time): 5.64 seconds for 683 images.\n",
      "âœ… æ¨ç†é€Ÿåº¦ (Inference Speed): 121.18 FPS\n",
      "Test Results - Loss: 0.2526 | Accuracy: 83.6018% | F1_weighted: 83.4611% | F1_macro: 83.4383% | Inference Speed: 121.18 FPS\n",
      "--------------------------------------------------\n",
      "\n",
      "Final Test Confusion Matrix:\n",
      "Class 0  |  118 |    0 |    0 |    7 |    2 |   11 |    1 |    1\n",
      "Class 1  |    0 |   63 |    0 |    0 |    0 |    1 |    0 |    0\n",
      "Class 2  |    0 |    0 |   80 |    0 |    0 |    0 |    2 |    0\n",
      "Class 3  |    1 |    0 |    0 |   62 |    3 |   11 |    3 |    1\n",
      "Class 4  |    0 |    1 |    2 |    5 |   43 |    3 |    0 |    0\n",
      "Class 5  |   17 |    3 |    0 |   19 |    6 |   67 |    1 |    0\n",
      "Class 6  |    0 |    0 |    2 |    4 |    2 |    2 |   33 |    0\n",
      "Class 7  |    0 |    0 |    0 |    0 |    0 |    0 |    1 |  105\n",
      "==================================================\n",
      "\n",
      "\n",
      "æ­£åœ¨ç”Ÿæˆè®­ç»ƒå†å²æ›²çº¿å›¾...\n",
      "Warning: æœªæ‰¾åˆ° train_metrics.xlsx æˆ– val_metrics.xlsxã€‚è·³è¿‡ç»˜å›¾ã€‚\n",
      "\n",
      "âœ… Fold 1 è®­ç»ƒå®Œæˆ!\n",
      "   æœ€ä½³epoch: 138\n",
      "   æœ€ä½³éªŒè¯å‡†ç¡®ç‡: 84.5735%\n",
      "   æµ‹è¯•å‡†ç¡®ç‡: 83.6018%\n",
      "   æµ‹è¯•F1 (macro): 83.4383%\n",
      "\n",
      "======================================================================\n",
      "ğŸ”¥ å¼€å§‹è®­ç»ƒ Fold 2/5\n",
      "======================================================================\n",
      "\n",
      "æ‰¾åˆ° 2203 ä¸ªè®­ç»ƒæ–‡ä»¶, 551 ä¸ªéªŒè¯æ–‡ä»¶, 683 ä¸ªæµ‹è¯•æ–‡ä»¶\n",
      "Calculating mean and std of training set for data normalization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2203/2203 [00:08<00:00, 266.78it/s]\n",
      "/tmp/ipykernel_19/1154223942.py:69: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=224, min_width=224, border_mode=0, value=134, p=1.0),\n",
      "/tmp/ipykernel_19/1154223942.py:75: UserWarning: Argument(s) 'alpha_affine' are not valid for transform ElasticTransform\n",
      "  A.ElasticTransform(p=0.5, alpha=20, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n",
      "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "/tmp/ipykernel_19/1154223942.py:88: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(5.0, 30.0), p=1.0),  # âœ… é™ä½å™ªå£°å¼ºåº¦: 10~50 -> 5~30\n",
      "/tmp/ipykernel_19/1154223942.py:91: UserWarning: Argument(s) 'max_holes, max_height, max_width, min_holes, fill_value' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(\n",
      "/tmp/ipykernel_19/1154223942.py:120: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=224, min_width=224, border_mode=0, value=134, p=1.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean (RGB): [0.4973583989550892, 0.49997000487806276, 0.502768622308975]\n",
      "Std  (RGB): [0.15939570777237208, 0.1599187567059571, 0.15914790214422056]\n",
      "æ­£åœ¨è®¡ç®—ç±»åˆ«æƒé‡ä»¥å¤„ç†æ•°æ®ä¸å¹³è¡¡é—®é¢˜...\n",
      "è®¡ç®—å‡ºçš„ç±»åˆ«æƒé‡: [0.61330736 1.330314   1.039151   1.0510496  1.5735714  0.7607044\n",
      " 1.9392606  0.8075513 ]\n",
      "\n",
      "æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹: mobilenetv3_large_100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "âœ… æ¨¡å‹å‚æ•°é‡ (Parameters): 4.21 M\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "âœ… FLOPs: 0.22 G\n",
      "============================================================\n",
      "æ­£åœ¨ä½¿ç”¨ FocalLoss\n",
      "\n",
      "==================================================\n",
      "ğŸ”¥ é˜¶æ®µä¸€: å†»ç»“ä¸»å¹²ç½‘ç»œï¼Œåªè®­ç»ƒåˆ†ç±»å¤´\n",
      "==================================================\n",
      "æ¨¡å‹ä¸»å¹²å·²å†»ç»“ï¼Œåªè®­ç»ƒæœ€åçš„ 'classifier' å±‚ã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train | Loss:3.247 Acc:19.35%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.71it/s]\n",
      "val   | Loss:2.474 Acc:32.49%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.69it/s]\n",
      "train | Loss:1.980 Acc:34.83%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.73it/s]\n",
      "val   | Loss:1.808 Acc:43.01%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.09it/s]\n",
      "train | Loss:1.599 Acc:42.69%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.77it/s]\n",
      "val   | Loss:1.410 Acc:50.82%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.10it/s]\n",
      "train | Loss:1.193 Acc:49.31%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.68it/s]\n",
      "val   | Loss:1.206 Acc:53.36%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.13it/s]\n",
      "train | Loss:1.089 Acc:51.84%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.73it/s]\n",
      "val   | Loss:1.044 Acc:55.54%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.00it/s]\n",
      "train | Loss:0.911 Acc:55.97%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.57it/s]\n",
      "val   | Loss:0.893 Acc:58.98%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.11it/s]\n",
      "train | Loss:0.814 Acc:58.04%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.69it/s]\n",
      "val   | Loss:0.814 Acc:60.07%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.13it/s]\n",
      "train | Loss:0.737 Acc:61.21%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.75it/s]\n",
      "val   | Loss:0.706 Acc:62.98%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.06it/s]\n",
      "train | Loss:0.643 Acc:65.26%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.77it/s]\n",
      "val   | Loss:0.646 Acc:63.88%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.20it/s]\n",
      "train | Loss:0.616 Acc:65.76%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.65it/s]\n",
      "val   | Loss:0.585 Acc:66.61%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.13it/s]\n",
      "train | Loss:0.574 Acc:67.23%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.75it/s]\n",
      "val   | Loss:0.543 Acc:66.97%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.07it/s]\n",
      "train | Loss:0.538 Acc:68.34%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.72it/s]\n",
      "val   | Loss:0.500 Acc:69.33%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.10it/s]\n",
      "train | Loss:0.512 Acc:70.82%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.72it/s]\n",
      "val   | Loss:0.482 Acc:69.33%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.15it/s]\n",
      "train | Loss:0.487 Acc:70.82%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.66it/s]\n",
      "val   | Loss:0.457 Acc:70.60%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.05it/s]\n",
      "train | Loss:0.467 Acc:73.21%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.76it/s]\n",
      "val   | Loss:0.435 Acc:73.50%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.24it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”¥ é˜¶æ®µäºŒ: è§£å†»æ‰€æœ‰å±‚ï¼Œè¿›è¡Œå…¨å±€å¾®è°ƒ\n",
      "==================================================\n",
      "åŠ è½½é˜¶æ®µä¸€çš„æœ€ä½³æ¨¡å‹æƒé‡...\n",
      "æ‰€æœ‰å±‚å·²è§£å†»ã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train | Loss:0.453 Acc:73.53%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.56it/s]\n",
      "val   | Loss:0.427 Acc:74.77%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.11it/s]\n",
      "train | Loss:0.448 Acc:74.17%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.66it/s]\n",
      "val   | Loss:0.419 Acc:74.41%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.18it/s]\n",
      "train | Loss:0.437 Acc:74.49%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.62it/s]\n",
      "val   | Loss:0.414 Acc:74.77%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.26it/s]\n",
      "train | Loss:0.429 Acc:74.68%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.68it/s]\n",
      "val   | Loss:0.408 Acc:74.23%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.29it/s]\n",
      "train | Loss:0.430 Acc:74.91%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.73it/s]\n",
      "val   | Loss:0.404 Acc:76.23%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.66it/s]\n",
      "train | Loss:0.415 Acc:75.05%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.67it/s]\n",
      "val   | Loss:0.398 Acc:75.86%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.16it/s]\n",
      "train | Loss:0.403 Acc:75.64%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.67it/s]\n",
      "val   | Loss:0.393 Acc:75.50%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.52it/s]\n",
      "train | Loss:0.406 Acc:75.92%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.388 Acc:75.86%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.16it/s]\n",
      "train | Loss:0.398 Acc:76.01%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.57it/s]\n",
      "val   | Loss:0.386 Acc:76.23%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.82it/s]\n",
      "train | Loss:0.397 Acc:76.84%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.62it/s]\n",
      "val   | Loss:0.382 Acc:75.86%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.94it/s]\n",
      "train | Loss:0.393 Acc:75.97%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.381 Acc:76.04%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.12it/s]\n",
      "train | Loss:0.376 Acc:77.39%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.63it/s]\n",
      "val   | Loss:0.375 Acc:76.59%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.18it/s]\n",
      "train | Loss:0.378 Acc:76.19%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.70it/s]\n",
      "val   | Loss:0.371 Acc:77.13%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.24it/s]\n",
      "train | Loss:0.371 Acc:77.48%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.57it/s]\n",
      "val   | Loss:0.369 Acc:76.59%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.13it/s]\n",
      "train | Loss:0.370 Acc:76.75%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.61it/s]\n",
      "val   | Loss:0.366 Acc:76.41%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.11it/s]\n",
      "train | Loss:0.376 Acc:76.70%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.363 Acc:76.23%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.09it/s]\n",
      "train | Loss:0.356 Acc:78.68%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.364 Acc:76.95%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.22it/s]\n",
      "train | Loss:0.352 Acc:77.99%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.358 Acc:77.86%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.11it/s]\n",
      "train | Loss:0.358 Acc:77.90%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.58it/s]\n",
      "val   | Loss:0.355 Acc:78.58%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.19it/s]\n",
      "train | Loss:0.356 Acc:78.45%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.57it/s]\n",
      "val   | Loss:0.356 Acc:77.86%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.27it/s]\n",
      "train | Loss:0.340 Acc:78.95%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.63it/s]\n",
      "val   | Loss:0.353 Acc:78.22%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.32it/s]\n",
      "train | Loss:0.350 Acc:78.86%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.58it/s]\n",
      "val   | Loss:0.347 Acc:77.86%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.01it/s]\n",
      "train | Loss:0.361 Acc:78.31%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.57it/s]\n",
      "val   | Loss:0.351 Acc:78.22%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.78it/s]\n",
      "train | Loss:0.339 Acc:79.41%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.51it/s]\n",
      "val   | Loss:0.345 Acc:78.22%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.98it/s]\n",
      "train | Loss:0.334 Acc:78.91%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.63it/s]\n",
      "val   | Loss:0.343 Acc:79.67%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.17it/s]\n",
      "train | Loss:0.347 Acc:79.27%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.58it/s]\n",
      "val   | Loss:0.340 Acc:79.31%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.11it/s]\n",
      "train | Loss:0.337 Acc:79.55%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.64it/s]\n",
      "val   | Loss:0.340 Acc:78.95%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.21it/s]\n",
      "train | Loss:0.331 Acc:79.46%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.54it/s]\n",
      "val   | Loss:0.341 Acc:79.67%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.16it/s]\n",
      "train | Loss:0.321 Acc:80.88%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.64it/s]\n",
      "val   | Loss:0.336 Acc:80.22%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.24it/s]\n",
      "train | Loss:0.327 Acc:79.78%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.65it/s]\n",
      "val   | Loss:0.333 Acc:79.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.18it/s]\n",
      "train | Loss:0.318 Acc:79.73%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.66it/s]\n",
      "val   | Loss:0.334 Acc:80.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.24it/s]\n",
      "train | Loss:0.327 Acc:79.37%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.330 Acc:79.31%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.03it/s]\n",
      "train | Loss:0.322 Acc:80.15%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.68it/s]\n",
      "val   | Loss:0.332 Acc:79.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.11it/s]\n",
      "train | Loss:0.328 Acc:79.55%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.57it/s]\n",
      "val   | Loss:0.327 Acc:79.67%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.00it/s]\n",
      "train | Loss:0.325 Acc:79.69%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.57it/s]\n",
      "val   | Loss:0.330 Acc:80.04%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.06it/s]\n",
      "train | Loss:0.312 Acc:80.84%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.54it/s]\n",
      "val   | Loss:0.326 Acc:79.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.94it/s]\n",
      "train | Loss:0.303 Acc:81.11%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.65it/s]\n",
      "val   | Loss:0.324 Acc:79.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.03it/s]\n",
      "train | Loss:0.306 Acc:80.88%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.60it/s]\n",
      "val   | Loss:0.323 Acc:79.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.17it/s]\n",
      "train | Loss:0.301 Acc:81.34%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.62it/s]\n",
      "val   | Loss:0.324 Acc:79.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.21it/s]\n",
      "train | Loss:0.305 Acc:81.16%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.58it/s]\n",
      "val   | Loss:0.321 Acc:79.49%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.96it/s]\n",
      "train | Loss:0.298 Acc:79.92%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.63it/s]\n",
      "val   | Loss:0.319 Acc:80.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.08it/s]\n",
      "train | Loss:0.294 Acc:80.93%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.63it/s]\n",
      "val   | Loss:0.319 Acc:80.04%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.69it/s]\n",
      "train | Loss:0.286 Acc:82.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.69it/s]\n",
      "val   | Loss:0.316 Acc:80.58%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.24it/s]\n",
      "train | Loss:0.299 Acc:81.07%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.63it/s]\n",
      "val   | Loss:0.319 Acc:79.67%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.78it/s]\n",
      "train | Loss:0.292 Acc:81.30%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.62it/s]\n",
      "val   | Loss:0.317 Acc:80.04%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.04it/s]\n",
      "train | Loss:0.298 Acc:81.66%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.318 Acc:81.13%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.06it/s]\n",
      "train | Loss:0.284 Acc:81.66%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.61it/s]\n",
      "val   | Loss:0.316 Acc:80.22%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.96it/s]\n",
      "train | Loss:0.286 Acc:82.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.61it/s]\n",
      "val   | Loss:0.314 Acc:80.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.98it/s]\n",
      "train | Loss:0.281 Acc:82.26%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.51it/s]\n",
      "val   | Loss:0.315 Acc:79.67%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.21it/s]\n",
      "train | Loss:0.287 Acc:81.76%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.68it/s]\n",
      "val   | Loss:0.313 Acc:79.67%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.19it/s]\n",
      "train | Loss:0.283 Acc:82.81%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.63it/s]\n",
      "val   | Loss:0.310 Acc:79.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.32it/s]\n",
      "train | Loss:0.288 Acc:81.76%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.71it/s]\n",
      "val   | Loss:0.311 Acc:80.22%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.15it/s]\n",
      "train | Loss:0.288 Acc:82.35%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.65it/s]\n",
      "val   | Loss:0.305 Acc:80.22%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.29it/s]\n",
      "train | Loss:0.270 Acc:83.04%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.67it/s]\n",
      "val   | Loss:0.309 Acc:80.58%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.30it/s]\n",
      "train | Loss:0.282 Acc:81.53%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.66it/s]\n",
      "val   | Loss:0.306 Acc:80.58%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.28it/s]\n",
      "train | Loss:0.284 Acc:82.72%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.69it/s]\n",
      "val   | Loss:0.306 Acc:80.76%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.34it/s]\n",
      "train | Loss:0.279 Acc:82.81%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.61it/s]\n",
      "val   | Loss:0.307 Acc:80.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.14it/s]\n",
      "train | Loss:0.285 Acc:82.44%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.71it/s]\n",
      "val   | Loss:0.307 Acc:80.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.33it/s]\n",
      "train | Loss:0.281 Acc:81.89%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.69it/s]\n",
      "val   | Loss:0.303 Acc:80.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.23it/s]\n",
      "train | Loss:0.283 Acc:82.54%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.69it/s]\n",
      "val   | Loss:0.305 Acc:80.04%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.28it/s]\n",
      "train | Loss:0.274 Acc:82.12%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.67it/s]\n",
      "val   | Loss:0.304 Acc:80.22%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.18it/s]\n",
      "train | Loss:0.283 Acc:82.31%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.72it/s]\n",
      "val   | Loss:0.303 Acc:79.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.22it/s]\n",
      "train | Loss:0.270 Acc:82.95%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.56it/s]\n",
      "val   | Loss:0.301 Acc:80.58%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.71it/s]\n",
      "train | Loss:0.265 Acc:83.78%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.65it/s]\n",
      "val   | Loss:0.299 Acc:80.22%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.13it/s]\n",
      "train | Loss:0.270 Acc:83.55%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.56it/s]\n",
      "val   | Loss:0.296 Acc:80.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.59it/s]\n",
      "train | Loss:0.270 Acc:83.27%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.65it/s]\n",
      "val   | Loss:0.295 Acc:80.22%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.11it/s]\n",
      "train | Loss:0.256 Acc:83.18%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.63it/s]\n",
      "val   | Loss:0.299 Acc:79.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.89it/s]\n",
      "train | Loss:0.258 Acc:83.41%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.55it/s]\n",
      "val   | Loss:0.298 Acc:80.04%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.15it/s]\n",
      "train | Loss:0.262 Acc:84.42%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.294 Acc:80.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.28it/s]\n",
      "train | Loss:0.267 Acc:83.04%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.296 Acc:80.76%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.32it/s]\n",
      "train | Loss:0.260 Acc:82.77%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.58it/s]\n",
      "val   | Loss:0.296 Acc:80.58%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.34it/s]\n",
      "train | Loss:0.282 Acc:82.58%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:14<00:00,  2.40it/s]\n",
      "val   | Loss:0.296 Acc:80.76%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.17it/s]\n",
      "train | Loss:0.245 Acc:84.33%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.68it/s]\n",
      "val   | Loss:0.293 Acc:80.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.22it/s]\n",
      "train | Loss:0.261 Acc:82.44%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.57it/s]\n",
      "val   | Loss:0.295 Acc:80.76%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.12it/s]\n",
      "train | Loss:0.246 Acc:84.01%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.291 Acc:80.22%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.18it/s]\n",
      "train | Loss:0.254 Acc:83.46%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.52it/s]\n",
      "val   | Loss:0.293 Acc:80.58%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.16it/s]\n",
      "train | Loss:0.254 Acc:84.33%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.61it/s]\n",
      "val   | Loss:0.291 Acc:80.58%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.19it/s]\n",
      "train | Loss:0.250 Acc:83.82%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.56it/s]\n",
      "val   | Loss:0.292 Acc:80.76%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.13it/s]\n",
      "train | Loss:0.251 Acc:84.56%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.64it/s]\n",
      "val   | Loss:0.290 Acc:80.58%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.32it/s]\n",
      "train | Loss:0.256 Acc:84.65%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.65it/s]\n",
      "val   | Loss:0.291 Acc:80.94%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.27it/s]\n",
      "train | Loss:0.247 Acc:84.24%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.74it/s]\n",
      "val   | Loss:0.289 Acc:79.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "ğŸ”¥ è¯„ä¼°å…¨å±€æœ€ä½³æ¨¡å‹ (æ¥è‡ª epoch 61ï¼ŒéªŒè¯é›†å‡†ç¡®ç‡ 81.1252%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test  | Loss:0.313 Acc:80.67%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:03<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "âœ… æ€»æ¨ç†æ—¶é—´ (Total Inference Time): 3.01 seconds for 683 images.\n",
      "âœ… æ¨ç†é€Ÿåº¦ (Inference Speed): 226.88 FPS\n",
      "Test Results - Loss: 0.3133 | Accuracy: 80.6735% | F1_weighted: 80.8741% | F1_macro: 79.8800% | Inference Speed: 226.88 FPS\n",
      "--------------------------------------------------\n",
      "\n",
      "Final Test Confusion Matrix:\n",
      "Class 0  |  111 |    0 |    0 |    6 |    1 |   19 |    2 |    1\n",
      "Class 1  |    0 |   61 |    0 |    1 |    1 |    1 |    0 |    0\n",
      "Class 2  |    0 |    0 |   70 |    0 |    0 |    0 |   12 |    0\n",
      "Class 3  |    0 |    0 |    2 |   62 |    2 |   13 |    2 |    0\n",
      "Class 4  |    0 |    0 |    3 |    5 |   42 |    3 |    0 |    1\n",
      "Class 5  |   13 |    3 |    1 |   15 |    5 |   71 |    5 |    0\n",
      "Class 6  |    0 |    0 |    4 |    6 |    2 |    2 |   29 |    0\n",
      "Class 7  |    0 |    0 |    0 |    0 |    0 |    0 |    1 |  105\n",
      "==================================================\n",
      "\n",
      "\n",
      "æ­£åœ¨ç”Ÿæˆè®­ç»ƒå†å²æ›²çº¿å›¾...\n",
      "Warning: æœªæ‰¾åˆ° train_metrics.xlsx æˆ– val_metrics.xlsxã€‚è·³è¿‡ç»˜å›¾ã€‚\n",
      "\n",
      "âœ… Fold 2 è®­ç»ƒå®Œæˆ!\n",
      "   æœ€ä½³epoch: 61\n",
      "   æœ€ä½³éªŒè¯å‡†ç¡®ç‡: 81.1252%\n",
      "   æµ‹è¯•å‡†ç¡®ç‡: 80.6735%\n",
      "   æµ‹è¯•F1 (macro): 79.8800%\n",
      "\n",
      "======================================================================\n",
      "ğŸ”¥ å¼€å§‹è®­ç»ƒ Fold 3/5\n",
      "======================================================================\n",
      "\n",
      "æ‰¾åˆ° 2203 ä¸ªè®­ç»ƒæ–‡ä»¶, 551 ä¸ªéªŒè¯æ–‡ä»¶, 683 ä¸ªæµ‹è¯•æ–‡ä»¶\n",
      "Calculating mean and std of training set for data normalization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2203/2203 [00:07<00:00, 282.67it/s]\n",
      "/tmp/ipykernel_19/1154223942.py:69: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=224, min_width=224, border_mode=0, value=134, p=1.0),\n",
      "/tmp/ipykernel_19/1154223942.py:75: UserWarning: Argument(s) 'alpha_affine' are not valid for transform ElasticTransform\n",
      "  A.ElasticTransform(p=0.5, alpha=20, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n",
      "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "/tmp/ipykernel_19/1154223942.py:88: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(5.0, 30.0), p=1.0),  # âœ… é™ä½å™ªå£°å¼ºåº¦: 10~50 -> 5~30\n",
      "/tmp/ipykernel_19/1154223942.py:91: UserWarning: Argument(s) 'max_holes, max_height, max_width, min_holes, fill_value' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(\n",
      "/tmp/ipykernel_19/1154223942.py:120: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=224, min_width=224, border_mode=0, value=134, p=1.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean (RGB): [0.4972926695123134, 0.49978454529565086, 0.5024542531838558]\n",
      "Std  (RGB): [0.1597400119810871, 0.16026780646061364, 0.15956911667049095]\n",
      "æ­£åœ¨è®¡ç®—ç±»åˆ«æƒé‡ä»¥å¤„ç†æ•°æ®ä¸å¹³è¡¡é—®é¢˜...\n",
      "è®¡ç®—å‡ºçš„ç±»åˆ«æƒé‡: [0.61330736 1.330314   1.0352443  1.0510496  1.5735714  0.7586088\n",
      " 1.9530141  0.80992645]\n",
      "\n",
      "æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹: mobilenetv3_large_100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "âœ… æ¨¡å‹å‚æ•°é‡ (Parameters): 4.21 M\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "âœ… FLOPs: 0.22 G\n",
      "============================================================\n",
      "æ­£åœ¨ä½¿ç”¨ FocalLoss\n",
      "\n",
      "==================================================\n",
      "ğŸ”¥ é˜¶æ®µä¸€: å†»ç»“ä¸»å¹²ç½‘ç»œï¼Œåªè®­ç»ƒåˆ†ç±»å¤´\n",
      "==================================================\n",
      "æ¨¡å‹ä¸»å¹²å·²å†»ç»“ï¼Œåªè®­ç»ƒæœ€åçš„ 'classifier' å±‚ã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train | Loss:3.204 Acc:16.04%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:11<00:00,  2.86it/s]\n",
      "val   | Loss:2.308 Acc:26.50%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.93it/s]\n",
      "train | Loss:2.032 Acc:31.43%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.81it/s]\n",
      "val   | Loss:1.557 Acc:44.46%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.32it/s]\n",
      "train | Loss:1.491 Acc:42.14%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:11<00:00,  2.86it/s]\n",
      "val   | Loss:1.221 Acc:49.55%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.85it/s]\n",
      "train | Loss:1.250 Acc:47.98%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:11<00:00,  2.91it/s]\n",
      "val   | Loss:0.994 Acc:55.54%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.90it/s]\n",
      "train | Loss:1.056 Acc:53.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.74it/s]\n",
      "val   | Loss:0.876 Acc:57.71%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.22it/s]\n",
      "train | Loss:0.924 Acc:55.56%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:11<00:00,  2.85it/s]\n",
      "val   | Loss:0.746 Acc:61.16%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.81it/s]\n",
      "train | Loss:0.786 Acc:59.01%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.69it/s]\n",
      "val   | Loss:0.661 Acc:62.98%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.63it/s]\n",
      "train | Loss:0.702 Acc:60.34%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.78it/s]\n",
      "val   | Loss:0.598 Acc:66.06%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.83it/s]\n",
      "train | Loss:0.669 Acc:63.14%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.69it/s]\n",
      "val   | Loss:0.543 Acc:68.06%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.63it/s]\n",
      "train | Loss:0.610 Acc:64.61%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.49it/s]\n",
      "val   | Loss:0.498 Acc:71.32%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.58it/s]\n",
      "train | Loss:0.566 Acc:65.07%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.65it/s]\n",
      "val   | Loss:0.466 Acc:72.78%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.66it/s]\n",
      "train | Loss:0.535 Acc:69.12%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.72it/s]\n",
      "val   | Loss:0.448 Acc:73.50%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.61it/s]\n",
      "train | Loss:0.506 Acc:70.08%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.58it/s]\n",
      "val   | Loss:0.420 Acc:75.50%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.68it/s]\n",
      "train | Loss:0.471 Acc:71.92%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.67it/s]\n",
      "val   | Loss:0.404 Acc:76.41%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.52it/s]\n",
      "train | Loss:0.479 Acc:72.24%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.60it/s]\n",
      "val   | Loss:0.398 Acc:77.13%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.71it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”¥ é˜¶æ®µäºŒ: è§£å†»æ‰€æœ‰å±‚ï¼Œè¿›è¡Œå…¨å±€å¾®è°ƒ\n",
      "==================================================\n",
      "åŠ è½½é˜¶æ®µä¸€çš„æœ€ä½³æ¨¡å‹æƒé‡...\n",
      "æ‰€æœ‰å±‚å·²è§£å†»ã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train | Loss:0.442 Acc:74.17%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.55it/s]\n",
      "val   | Loss:0.384 Acc:78.95%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.75it/s]\n",
      "train | Loss:0.442 Acc:73.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.47it/s]\n",
      "val   | Loss:0.383 Acc:78.95%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.64it/s]\n",
      "train | Loss:0.434 Acc:74.17%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.52it/s]\n",
      "val   | Loss:0.372 Acc:78.58%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.58it/s]\n",
      "train | Loss:0.418 Acc:74.45%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.51it/s]\n",
      "val   | Loss:0.369 Acc:79.31%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.63it/s]\n",
      "train | Loss:0.414 Acc:75.14%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.54it/s]\n",
      "val   | Loss:0.368 Acc:77.86%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.58it/s]\n",
      "train | Loss:0.413 Acc:75.00%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.46it/s]\n",
      "val   | Loss:0.358 Acc:79.67%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.53it/s]\n",
      "train | Loss:0.413 Acc:74.49%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.56it/s]\n",
      "val   | Loss:0.349 Acc:80.22%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.58it/s]\n",
      "train | Loss:0.393 Acc:76.93%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.49it/s]\n",
      "val   | Loss:0.346 Acc:80.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.69it/s]\n",
      "train | Loss:0.403 Acc:76.10%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.56it/s]\n",
      "val   | Loss:0.340 Acc:81.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.47it/s]\n",
      "train | Loss:0.394 Acc:76.29%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.46it/s]\n",
      "val   | Loss:0.345 Acc:79.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.53it/s]\n",
      "train | Loss:0.389 Acc:76.15%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.56it/s]\n",
      "val   | Loss:0.338 Acc:80.94%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.60it/s]\n",
      "train | Loss:0.361 Acc:76.75%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:14<00:00,  2.43it/s]\n",
      "val   | Loss:0.334 Acc:81.49%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.57it/s]\n",
      "train | Loss:0.367 Acc:77.48%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.54it/s]\n",
      "val   | Loss:0.334 Acc:80.94%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.69it/s]\n",
      "train | Loss:0.373 Acc:76.65%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.48it/s]\n",
      "val   | Loss:0.336 Acc:80.94%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.65it/s]\n",
      "train | Loss:0.369 Acc:77.48%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.61it/s]\n",
      "val   | Loss:0.329 Acc:81.31%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.65it/s]\n",
      "train | Loss:0.371 Acc:77.80%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.49it/s]\n",
      "val   | Loss:0.327 Acc:80.94%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.61it/s]\n",
      "train | Loss:0.366 Acc:77.53%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.58it/s]\n",
      "val   | Loss:0.324 Acc:81.49%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.60it/s]\n",
      "train | Loss:0.362 Acc:77.71%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.55it/s]\n",
      "val   | Loss:0.321 Acc:82.58%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.63it/s]\n",
      "train | Loss:0.340 Acc:77.71%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.319 Acc:80.94%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.59it/s]\n",
      "train | Loss:0.332 Acc:79.04%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.50it/s]\n",
      "val   | Loss:0.316 Acc:81.49%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.63it/s]\n",
      "train | Loss:0.332 Acc:79.41%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.55it/s]\n",
      "val   | Loss:0.313 Acc:81.49%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.63it/s]\n",
      "train | Loss:0.348 Acc:78.12%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:14<00:00,  2.38it/s]\n",
      "val   | Loss:0.312 Acc:82.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.60it/s]\n",
      "train | Loss:0.342 Acc:78.77%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.54it/s]\n",
      "val   | Loss:0.308 Acc:82.76%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.50it/s]\n",
      "train | Loss:0.342 Acc:78.45%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.48it/s]\n",
      "val   | Loss:0.311 Acc:81.49%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.65it/s]\n",
      "train | Loss:0.339 Acc:78.31%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.58it/s]\n",
      "val   | Loss:0.308 Acc:81.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.66it/s]\n",
      "train | Loss:0.328 Acc:78.58%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.51it/s]\n",
      "val   | Loss:0.309 Acc:82.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.63it/s]\n",
      "train | Loss:0.332 Acc:79.64%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.304 Acc:82.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.84it/s]\n",
      "train | Loss:0.323 Acc:78.86%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.57it/s]\n",
      "val   | Loss:0.300 Acc:82.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.79it/s]\n",
      "train | Loss:0.334 Acc:78.45%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.296 Acc:82.76%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.80it/s]\n",
      "train | Loss:0.313 Acc:79.78%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.66it/s]\n",
      "val   | Loss:0.300 Acc:82.76%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.59it/s]\n",
      "train | Loss:0.321 Acc:80.01%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.65it/s]\n",
      "val   | Loss:0.295 Acc:82.94%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.72it/s]\n",
      "train | Loss:0.317 Acc:79.55%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.65it/s]\n",
      "val   | Loss:0.293 Acc:82.94%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.29it/s]\n",
      "train | Loss:0.314 Acc:81.30%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.70it/s]\n",
      "val   | Loss:0.290 Acc:83.12%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.80it/s]\n",
      "train | Loss:0.311 Acc:80.47%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.64it/s]\n",
      "val   | Loss:0.288 Acc:83.12%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.27it/s]\n",
      "train | Loss:0.297 Acc:81.16%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.64it/s]\n",
      "val   | Loss:0.289 Acc:82.58%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.76it/s]\n",
      "train | Loss:0.308 Acc:81.07%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.67it/s]\n",
      "val   | Loss:0.287 Acc:83.48%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.66it/s]\n",
      "train | Loss:0.313 Acc:79.69%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.52it/s]\n",
      "val   | Loss:0.284 Acc:83.48%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.64it/s]\n",
      "train | Loss:0.303 Acc:80.19%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.64it/s]\n",
      "val   | Loss:0.288 Acc:82.94%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.56it/s]\n",
      "train | Loss:0.309 Acc:80.47%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.56it/s]\n",
      "val   | Loss:0.285 Acc:82.21%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.70it/s]\n",
      "train | Loss:0.293 Acc:80.24%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.55it/s]\n",
      "val   | Loss:0.283 Acc:83.12%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.49it/s]\n",
      "train | Loss:0.315 Acc:80.01%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.49it/s]\n",
      "val   | Loss:0.280 Acc:83.12%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.70it/s]\n",
      "train | Loss:0.300 Acc:80.24%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.60it/s]\n",
      "val   | Loss:0.280 Acc:82.94%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.66it/s]\n",
      "train | Loss:0.292 Acc:80.38%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.54it/s]\n",
      "val   | Loss:0.277 Acc:83.67%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.52it/s]\n",
      "train | Loss:0.293 Acc:80.84%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.53it/s]\n",
      "val   | Loss:0.277 Acc:82.76%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.55it/s]\n",
      "train | Loss:0.295 Acc:79.60%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.51it/s]\n",
      "val   | Loss:0.274 Acc:83.12%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.65it/s]\n",
      "train | Loss:0.289 Acc:82.12%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.275 Acc:83.67%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.76it/s]\n",
      "train | Loss:0.298 Acc:81.30%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.54it/s]\n",
      "val   | Loss:0.271 Acc:82.94%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.67it/s]\n",
      "train | Loss:0.288 Acc:82.08%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.64it/s]\n",
      "val   | Loss:0.271 Acc:83.48%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.74it/s]\n",
      "train | Loss:0.274 Acc:82.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.57it/s]\n",
      "val   | Loss:0.269 Acc:83.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.72it/s]\n",
      "train | Loss:0.293 Acc:81.16%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.69it/s]\n",
      "val   | Loss:0.270 Acc:83.12%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.63it/s]\n",
      "train | Loss:0.288 Acc:81.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.57it/s]\n",
      "val   | Loss:0.267 Acc:83.30%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.70it/s]\n",
      "train | Loss:0.277 Acc:82.22%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.65it/s]\n",
      "val   | Loss:0.271 Acc:83.48%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.83it/s]\n",
      "train | Loss:0.281 Acc:81.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.50it/s]\n",
      "val   | Loss:0.268 Acc:82.94%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.66it/s]\n",
      "train | Loss:0.279 Acc:81.94%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.55it/s]\n",
      "val   | Loss:0.265 Acc:83.30%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.44it/s]\n",
      "train | Loss:0.276 Acc:82.22%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.45it/s]\n",
      "val   | Loss:0.264 Acc:83.12%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.53it/s]\n",
      "train | Loss:0.275 Acc:82.17%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.54it/s]\n",
      "val   | Loss:0.268 Acc:83.12%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.59it/s]\n",
      "train | Loss:0.269 Acc:82.17%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.46it/s]\n",
      "val   | Loss:0.263 Acc:83.67%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.51it/s]\n",
      "train | Loss:0.264 Acc:82.17%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.58it/s]\n",
      "val   | Loss:0.263 Acc:84.75%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.51it/s]\n",
      "train | Loss:0.272 Acc:82.67%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.43it/s]\n",
      "val   | Loss:0.262 Acc:83.30%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.70it/s]\n",
      "train | Loss:0.259 Acc:82.81%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.58it/s]\n",
      "val   | Loss:0.263 Acc:83.48%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.55it/s]\n",
      "train | Loss:0.269 Acc:81.89%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.51it/s]\n",
      "val   | Loss:0.261 Acc:83.67%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.61it/s]\n",
      "train | Loss:0.275 Acc:81.62%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.62it/s]\n",
      "val   | Loss:0.264 Acc:82.94%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.62it/s]\n",
      "train | Loss:0.269 Acc:82.35%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.48it/s]\n",
      "val   | Loss:0.263 Acc:83.48%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.60it/s]\n",
      "train | Loss:0.265 Acc:82.54%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.58it/s]\n",
      "val   | Loss:0.262 Acc:83.48%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.59it/s]\n",
      "train | Loss:0.250 Acc:83.09%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.44it/s]\n",
      "val   | Loss:0.258 Acc:83.48%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.68it/s]\n",
      "train | Loss:0.262 Acc:83.13%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.58it/s]\n",
      "val   | Loss:0.262 Acc:82.94%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.58it/s]\n",
      "train | Loss:0.269 Acc:83.92%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.47it/s]\n",
      "val   | Loss:0.257 Acc:84.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.72it/s]\n",
      "train | Loss:0.261 Acc:83.73%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.54it/s]\n",
      "val   | Loss:0.255 Acc:83.48%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.76it/s]\n",
      "train | Loss:0.258 Acc:83.41%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.51it/s]\n",
      "val   | Loss:0.254 Acc:83.48%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.70it/s]\n",
      "train | Loss:0.265 Acc:82.90%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.61it/s]\n",
      "val   | Loss:0.257 Acc:83.48%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.57it/s]\n",
      "train | Loss:0.254 Acc:83.55%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.53it/s]\n",
      "val   | Loss:0.255 Acc:82.94%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.58it/s]\n",
      "train | Loss:0.253 Acc:83.69%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.63it/s]\n",
      "val   | Loss:0.254 Acc:83.30%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.66it/s]\n",
      "train | Loss:0.255 Acc:83.04%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.55it/s]\n",
      "val   | Loss:0.256 Acc:83.30%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.23it/s]\n",
      "train | Loss:0.256 Acc:83.41%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.57it/s]\n",
      "val   | Loss:0.255 Acc:83.12%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.58it/s]\n",
      "train | Loss:0.247 Acc:83.73%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.56it/s]\n",
      "val   | Loss:0.253 Acc:83.48%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.34it/s]\n",
      "train | Loss:0.250 Acc:82.95%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.65it/s]\n",
      "val   | Loss:0.254 Acc:84.21%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.79it/s]\n",
      "train | Loss:0.247 Acc:83.32%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.253 Acc:83.30%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.24it/s]\n",
      "train | Loss:0.263 Acc:83.69%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.58it/s]\n",
      "val   | Loss:0.251 Acc:83.30%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.65it/s]\n",
      "train | Loss:0.243 Acc:84.79%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.55it/s]\n",
      "val   | Loss:0.252 Acc:83.48%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.28it/s]\n",
      "train | Loss:0.248 Acc:82.63%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.57it/s]\n",
      "val   | Loss:0.252 Acc:83.48%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.67it/s]\n",
      "train | Loss:0.249 Acc:83.23%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.54it/s]\n",
      "val   | Loss:0.250 Acc:83.48%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.59it/s]\n",
      "train | Loss:0.232 Acc:83.59%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.56it/s]\n",
      "val   | Loss:0.250 Acc:83.67%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.69it/s]\n",
      "train | Loss:0.251 Acc:83.64%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.61it/s]\n",
      "val   | Loss:0.250 Acc:84.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.70it/s]\n",
      "train | Loss:0.251 Acc:83.04%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.49it/s]\n",
      "val   | Loss:0.251 Acc:83.67%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.70it/s]\n",
      "train | Loss:0.241 Acc:84.47%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.54it/s]\n",
      "val   | Loss:0.249 Acc:84.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.73it/s]\n",
      "train | Loss:0.235 Acc:84.56%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.50it/s]\n",
      "val   | Loss:0.248 Acc:83.48%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.76it/s]\n",
      "train | Loss:0.236 Acc:84.47%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.60it/s]\n",
      "val   | Loss:0.252 Acc:84.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.65it/s]\n",
      "train | Loss:0.238 Acc:84.65%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.55it/s]\n",
      "val   | Loss:0.248 Acc:83.67%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.70it/s]\n",
      "train | Loss:0.239 Acc:84.51%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.60it/s]\n",
      "val   | Loss:0.251 Acc:84.21%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.79it/s]\n",
      "train | Loss:0.237 Acc:84.10%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.54it/s]\n",
      "val   | Loss:0.250 Acc:83.48%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.72it/s]\n",
      "train | Loss:0.232 Acc:84.83%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.65it/s]\n",
      "val   | Loss:0.248 Acc:84.57%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.74it/s]\n",
      "train | Loss:0.225 Acc:85.75%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.60it/s]\n",
      "val   | Loss:0.243 Acc:84.21%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.65it/s]\n",
      "train | Loss:0.230 Acc:85.16%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.65it/s]\n",
      "val   | Loss:0.248 Acc:84.21%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "ğŸ”¥ è¯„ä¼°å…¨å±€æœ€ä½³æ¨¡å‹ (æ¥è‡ª epoch 73ï¼ŒéªŒè¯é›†å‡†ç¡®ç‡ 84.7550%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test  | Loss:0.271 Acc:83.16%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:02<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "âœ… æ€»æ¨ç†æ—¶é—´ (Total Inference Time): 2.97 seconds for 683 images.\n",
      "âœ… æ¨ç†é€Ÿåº¦ (Inference Speed): 230.05 FPS\n",
      "Test Results - Loss: 0.2706 | Accuracy: 83.1625% | F1_weighted: 83.1254% | F1_macro: 82.4172% | Inference Speed: 230.05 FPS\n",
      "--------------------------------------------------\n",
      "\n",
      "Final Test Confusion Matrix:\n",
      "Class 0  |  119 |    0 |    0 |    5 |    2 |   13 |    0 |    1\n",
      "Class 1  |    0 |   63 |    0 |    1 |    0 |    0 |    0 |    0\n",
      "Class 2  |    0 |    0 |   76 |    0 |    0 |    0 |    6 |    0\n",
      "Class 3  |    1 |    0 |    1 |   56 |    5 |   15 |    2 |    1\n",
      "Class 4  |    0 |    1 |    4 |    6 |   41 |    2 |    0 |    0\n",
      "Class 5  |   16 |    2 |    0 |   11 |    4 |   77 |    3 |    0\n",
      "Class 6  |    0 |    0 |    3 |    5 |    2 |    1 |   32 |    0\n",
      "Class 7  |    0 |    0 |    1 |    0 |    0 |    0 |    1 |  104\n",
      "==================================================\n",
      "\n",
      "\n",
      "æ­£åœ¨ç”Ÿæˆè®­ç»ƒå†å²æ›²çº¿å›¾...\n",
      "Warning: æœªæ‰¾åˆ° train_metrics.xlsx æˆ– val_metrics.xlsxã€‚è·³è¿‡ç»˜å›¾ã€‚\n",
      "\n",
      "âœ… Fold 3 è®­ç»ƒå®Œæˆ!\n",
      "   æœ€ä½³epoch: 73\n",
      "   æœ€ä½³éªŒè¯å‡†ç¡®ç‡: 84.7550%\n",
      "   æµ‹è¯•å‡†ç¡®ç‡: 83.1625%\n",
      "   æµ‹è¯•F1 (macro): 82.4172%\n",
      "\n",
      "======================================================================\n",
      "ğŸ”¥ å¼€å§‹è®­ç»ƒ Fold 4/5\n",
      "======================================================================\n",
      "\n",
      "æ‰¾åˆ° 2203 ä¸ªè®­ç»ƒæ–‡ä»¶, 551 ä¸ªéªŒè¯æ–‡ä»¶, 683 ä¸ªæµ‹è¯•æ–‡ä»¶\n",
      "Calculating mean and std of training set for data normalization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2203/2203 [00:08<00:00, 250.86it/s]\n",
      "/tmp/ipykernel_19/1154223942.py:69: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=224, min_width=224, border_mode=0, value=134, p=1.0),\n",
      "/tmp/ipykernel_19/1154223942.py:75: UserWarning: Argument(s) 'alpha_affine' are not valid for transform ElasticTransform\n",
      "  A.ElasticTransform(p=0.5, alpha=20, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n",
      "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "/tmp/ipykernel_19/1154223942.py:88: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(5.0, 30.0), p=1.0),  # âœ… é™ä½å™ªå£°å¼ºåº¦: 10~50 -> 5~30\n",
      "/tmp/ipykernel_19/1154223942.py:91: UserWarning: Argument(s) 'max_holes, max_height, max_width, min_holes, fill_value' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(\n",
      "/tmp/ipykernel_19/1154223942.py:120: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=224, min_width=224, border_mode=0, value=134, p=1.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean (RGB): [0.49773439137112413, 0.500304728516519, 0.5030029279399457]\n",
      "Std  (RGB): [0.16000424125855256, 0.16053049431184996, 0.15982206705389304]\n",
      "æ­£åœ¨è®¡ç®—ç±»åˆ«æƒé‡ä»¥å¤„ç†æ•°æ®ä¸å¹³è¡¡é—®é¢˜...\n",
      "è®¡ç®—å‡ºçš„ç±»åˆ«æƒé‡: [0.61467636 1.3239182  1.0352443  1.0550766  1.5735714  0.7586088\n",
      " 1.9530141  0.8075513 ]\n",
      "\n",
      "æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹: mobilenetv3_large_100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "âœ… æ¨¡å‹å‚æ•°é‡ (Parameters): 4.21 M\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "âœ… FLOPs: 0.22 G\n",
      "============================================================\n",
      "æ­£åœ¨ä½¿ç”¨ FocalLoss\n",
      "\n",
      "==================================================\n",
      "ğŸ”¥ é˜¶æ®µä¸€: å†»ç»“ä¸»å¹²ç½‘ç»œï¼Œåªè®­ç»ƒåˆ†ç±»å¤´\n",
      "==================================================\n",
      "æ¨¡å‹ä¸»å¹²å·²å†»ç»“ï¼Œåªè®­ç»ƒæœ€åçš„ 'classifier' å±‚ã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train | Loss:3.243 Acc:17.51%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.68it/s]\n",
      "val   | Loss:2.719 Acc:23.23%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.77it/s]\n",
      "train | Loss:2.203 Acc:30.15%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.69it/s]\n",
      "val   | Loss:1.788 Acc:43.38%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.38it/s]\n",
      "train | Loss:1.658 Acc:41.50%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.79it/s]\n",
      "val   | Loss:1.365 Acc:50.45%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.91it/s]\n",
      "train | Loss:1.350 Acc:46.46%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.74it/s]\n",
      "val   | Loss:1.087 Acc:54.45%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.25it/s]\n",
      "train | Loss:1.135 Acc:50.69%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.78it/s]\n",
      "val   | Loss:0.909 Acc:59.71%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.92it/s]\n",
      "train | Loss:0.988 Acc:55.10%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.79it/s]\n",
      "val   | Loss:0.780 Acc:62.98%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.94it/s]\n",
      "train | Loss:0.849 Acc:57.35%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.72it/s]\n",
      "val   | Loss:0.669 Acc:64.07%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.89it/s]\n",
      "train | Loss:0.761 Acc:61.08%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.82it/s]\n",
      "val   | Loss:0.577 Acc:64.97%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.97it/s]\n",
      "train | Loss:0.677 Acc:63.79%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.66it/s]\n",
      "val   | Loss:0.533 Acc:66.97%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.75it/s]\n",
      "train | Loss:0.632 Acc:63.92%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.80it/s]\n",
      "val   | Loss:0.502 Acc:69.51%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.73it/s]\n",
      "train | Loss:0.576 Acc:66.82%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.72it/s]\n",
      "val   | Loss:0.457 Acc:71.51%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.88it/s]\n",
      "train | Loss:0.552 Acc:68.75%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:11<00:00,  2.88it/s]\n",
      "val   | Loss:0.427 Acc:73.14%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.89it/s]\n",
      "train | Loss:0.507 Acc:70.22%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.76it/s]\n",
      "val   | Loss:0.405 Acc:74.05%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.45it/s]\n",
      "train | Loss:0.499 Acc:72.15%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.79it/s]\n",
      "val   | Loss:0.390 Acc:72.78%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.75it/s]\n",
      "train | Loss:0.474 Acc:72.52%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:11<00:00,  2.86it/s]\n",
      "val   | Loss:0.377 Acc:73.68%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.83it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”¥ é˜¶æ®µäºŒ: è§£å†»æ‰€æœ‰å±‚ï¼Œè¿›è¡Œå…¨å±€å¾®è°ƒ\n",
      "==================================================\n",
      "åŠ è½½é˜¶æ®µä¸€çš„æœ€ä½³æ¨¡å‹æƒé‡...\n",
      "æ‰€æœ‰å±‚å·²è§£å†»ã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train | Loss:0.478 Acc:71.88%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.56it/s]\n",
      "val   | Loss:0.393 Acc:73.32%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.83it/s]\n",
      "train | Loss:0.476 Acc:71.51%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.67it/s]\n",
      "val   | Loss:0.383 Acc:74.05%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.90it/s]\n",
      "train | Loss:0.469 Acc:72.20%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.49it/s]\n",
      "val   | Loss:0.384 Acc:73.32%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.45it/s]\n",
      "train | Loss:0.446 Acc:74.22%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.61it/s]\n",
      "val   | Loss:0.374 Acc:74.41%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.85it/s]\n",
      "train | Loss:0.464 Acc:72.06%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.51it/s]\n",
      "val   | Loss:0.366 Acc:74.23%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.57it/s]\n",
      "train | Loss:0.424 Acc:74.59%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.363 Acc:75.50%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.79it/s]\n",
      "train | Loss:0.438 Acc:73.44%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.55it/s]\n",
      "val   | Loss:0.355 Acc:74.59%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.73it/s]\n",
      "train | Loss:0.430 Acc:75.00%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.65it/s]\n",
      "val   | Loss:0.345 Acc:76.04%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.88it/s]\n",
      "train | Loss:0.415 Acc:73.30%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.340 Acc:75.32%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.85it/s]\n",
      "train | Loss:0.415 Acc:74.22%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.66it/s]\n",
      "val   | Loss:0.333 Acc:76.41%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.84it/s]\n",
      "train | Loss:0.406 Acc:75.41%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.56it/s]\n",
      "val   | Loss:0.328 Acc:76.77%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.80it/s]\n",
      "train | Loss:0.407 Acc:75.05%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.68it/s]\n",
      "val   | Loss:0.328 Acc:76.59%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.01it/s]\n",
      "train | Loss:0.399 Acc:75.55%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.326 Acc:76.77%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.97it/s]\n",
      "train | Loss:0.401 Acc:75.05%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.69it/s]\n",
      "val   | Loss:0.321 Acc:77.50%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.80it/s]\n",
      "train | Loss:0.394 Acc:76.65%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.64it/s]\n",
      "val   | Loss:0.319 Acc:77.86%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.69it/s]\n",
      "train | Loss:0.388 Acc:76.29%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.70it/s]\n",
      "val   | Loss:0.314 Acc:77.31%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.81it/s]\n",
      "train | Loss:0.390 Acc:76.33%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.71it/s]\n",
      "val   | Loss:0.310 Acc:78.04%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.50it/s]\n",
      "train | Loss:0.360 Acc:77.25%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.69it/s]\n",
      "val   | Loss:0.305 Acc:79.67%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.85it/s]\n",
      "train | Loss:0.368 Acc:76.38%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.64it/s]\n",
      "val   | Loss:0.310 Acc:78.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.00it/s]\n",
      "train | Loss:0.358 Acc:77.30%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.300 Acc:78.95%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.93it/s]\n",
      "train | Loss:0.365 Acc:78.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.65it/s]\n",
      "val   | Loss:0.295 Acc:79.67%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.87it/s]\n",
      "train | Loss:0.357 Acc:77.76%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.51it/s]\n",
      "val   | Loss:0.299 Acc:79.49%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.82it/s]\n",
      "train | Loss:0.364 Acc:77.02%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.67it/s]\n",
      "val   | Loss:0.289 Acc:79.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.83it/s]\n",
      "train | Loss:0.347 Acc:76.93%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.47it/s]\n",
      "val   | Loss:0.293 Acc:79.13%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.93it/s]\n",
      "train | Loss:0.345 Acc:78.49%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.67it/s]\n",
      "val   | Loss:0.288 Acc:79.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.92it/s]\n",
      "train | Loss:0.338 Acc:78.31%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.51it/s]\n",
      "val   | Loss:0.288 Acc:79.31%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.85it/s]\n",
      "train | Loss:0.342 Acc:79.00%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.63it/s]\n",
      "val   | Loss:0.288 Acc:79.67%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.92it/s]\n",
      "train | Loss:0.340 Acc:79.50%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.52it/s]\n",
      "val   | Loss:0.285 Acc:79.49%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.90it/s]\n",
      "train | Loss:0.317 Acc:80.19%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.60it/s]\n",
      "val   | Loss:0.279 Acc:80.76%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.87it/s]\n",
      "train | Loss:0.329 Acc:78.72%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.49it/s]\n",
      "val   | Loss:0.282 Acc:80.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.88it/s]\n",
      "train | Loss:0.311 Acc:80.06%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.64it/s]\n",
      "val   | Loss:0.276 Acc:80.94%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.89it/s]\n",
      "train | Loss:0.326 Acc:78.95%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.279 Acc:81.49%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.60it/s]\n",
      "train | Loss:0.335 Acc:78.58%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.68it/s]\n",
      "val   | Loss:0.276 Acc:81.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.73it/s]\n",
      "train | Loss:0.333 Acc:79.14%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.66it/s]\n",
      "val   | Loss:0.271 Acc:81.13%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.19it/s]\n",
      "train | Loss:0.314 Acc:80.42%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.60it/s]\n",
      "val   | Loss:0.271 Acc:81.31%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.85it/s]\n",
      "train | Loss:0.322 Acc:79.23%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.61it/s]\n",
      "val   | Loss:0.270 Acc:82.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.52it/s]\n",
      "train | Loss:0.313 Acc:79.96%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.53it/s]\n",
      "val   | Loss:0.272 Acc:82.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.80it/s]\n",
      "train | Loss:0.302 Acc:80.10%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.65it/s]\n",
      "val   | Loss:0.268 Acc:81.13%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.81it/s]\n",
      "train | Loss:0.313 Acc:79.18%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.55it/s]\n",
      "val   | Loss:0.269 Acc:82.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.89it/s]\n",
      "train | Loss:0.299 Acc:80.70%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.67it/s]\n",
      "val   | Loss:0.265 Acc:81.49%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.85it/s]\n",
      "train | Loss:0.303 Acc:80.38%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.52it/s]\n",
      "val   | Loss:0.268 Acc:82.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.89it/s]\n",
      "train | Loss:0.297 Acc:81.16%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.65it/s]\n",
      "val   | Loss:0.262 Acc:82.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.97it/s]\n",
      "train | Loss:0.292 Acc:81.34%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.51it/s]\n",
      "val   | Loss:0.263 Acc:81.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.71it/s]\n",
      "train | Loss:0.289 Acc:81.66%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.67it/s]\n",
      "val   | Loss:0.263 Acc:82.21%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.93it/s]\n",
      "train | Loss:0.299 Acc:80.93%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.51it/s]\n",
      "val   | Loss:0.259 Acc:81.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.64it/s]\n",
      "train | Loss:0.298 Acc:81.02%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.61it/s]\n",
      "val   | Loss:0.257 Acc:82.58%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.73it/s]\n",
      "train | Loss:0.296 Acc:80.88%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.55it/s]\n",
      "val   | Loss:0.260 Acc:81.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.83it/s]\n",
      "train | Loss:0.292 Acc:81.11%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.67it/s]\n",
      "val   | Loss:0.258 Acc:81.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.71it/s]\n",
      "train | Loss:0.287 Acc:80.56%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.58it/s]\n",
      "val   | Loss:0.250 Acc:83.30%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.73it/s]\n",
      "train | Loss:0.281 Acc:81.39%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.67it/s]\n",
      "val   | Loss:0.251 Acc:82.94%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.89it/s]\n",
      "train | Loss:0.297 Acc:81.43%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.60it/s]\n",
      "val   | Loss:0.252 Acc:82.58%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.15it/s]\n",
      "train | Loss:0.285 Acc:81.99%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.55it/s]\n",
      "val   | Loss:0.252 Acc:82.58%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.72it/s]\n",
      "train | Loss:0.276 Acc:82.95%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.62it/s]\n",
      "val   | Loss:0.253 Acc:82.76%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.32it/s]\n",
      "train | Loss:0.275 Acc:81.71%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.62it/s]\n",
      "val   | Loss:0.249 Acc:82.76%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.73it/s]\n",
      "train | Loss:0.277 Acc:82.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.252 Acc:82.21%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.70it/s]\n",
      "train | Loss:0.272 Acc:82.35%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.57it/s]\n",
      "val   | Loss:0.248 Acc:83.12%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.78it/s]\n",
      "train | Loss:0.267 Acc:83.59%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.67it/s]\n",
      "val   | Loss:0.253 Acc:82.58%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.95it/s]\n",
      "train | Loss:0.275 Acc:82.44%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.53it/s]\n",
      "val   | Loss:0.244 Acc:82.58%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.93it/s]\n",
      "train | Loss:0.262 Acc:82.67%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.64it/s]\n",
      "val   | Loss:0.247 Acc:82.76%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.85it/s]\n",
      "train | Loss:0.267 Acc:83.69%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.54it/s]\n",
      "val   | Loss:0.245 Acc:82.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.89it/s]\n",
      "train | Loss:0.258 Acc:83.04%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.246 Acc:82.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.87it/s]\n",
      "train | Loss:0.260 Acc:82.95%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.50it/s]\n",
      "val   | Loss:0.247 Acc:82.94%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.86it/s]\n",
      "train | Loss:0.262 Acc:82.90%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.64it/s]\n",
      "val   | Loss:0.244 Acc:82.58%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.97it/s]\n",
      "train | Loss:0.254 Acc:84.15%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.52it/s]\n",
      "val   | Loss:0.246 Acc:82.21%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.84it/s]\n",
      "train | Loss:0.264 Acc:83.50%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.244 Acc:82.21%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.78it/s]\n",
      "train | Loss:0.252 Acc:83.96%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.56it/s]\n",
      "val   | Loss:0.245 Acc:82.58%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.74it/s]\n",
      "train | Loss:0.256 Acc:83.46%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.67it/s]\n",
      "val   | Loss:0.244 Acc:82.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.62it/s]\n",
      "train | Loss:0.257 Acc:84.51%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.54it/s]\n",
      "val   | Loss:0.242 Acc:82.21%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.47it/s]\n",
      "train | Loss:0.268 Acc:82.90%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.67it/s]\n",
      "val   | Loss:0.247 Acc:82.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.89it/s]\n",
      "train | Loss:0.257 Acc:83.55%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.66it/s]\n",
      "val   | Loss:0.244 Acc:82.76%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.42it/s]\n",
      "train | Loss:0.259 Acc:84.83%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.246 Acc:82.58%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.80it/s]\n",
      "train | Loss:0.246 Acc:82.72%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.63it/s]\n",
      "val   | Loss:0.241 Acc:82.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.95it/s]\n",
      "train | Loss:0.255 Acc:83.04%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.51it/s]\n",
      "val   | Loss:0.242 Acc:82.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.88it/s]\n",
      "train | Loss:0.253 Acc:83.09%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.248 Acc:82.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.90it/s]\n",
      "train | Loss:0.250 Acc:83.69%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.44it/s]\n",
      "val   | Loss:0.249 Acc:82.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.73it/s]\n",
      "train | Loss:0.259 Acc:83.50%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.61it/s]\n",
      "val   | Loss:0.243 Acc:81.31%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.95it/s]\n",
      "train | Loss:0.252 Acc:83.59%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.50it/s]\n",
      "val   | Loss:0.244 Acc:82.58%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.70it/s]\n",
      "train | Loss:0.257 Acc:83.36%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.60it/s]\n",
      "val   | Loss:0.246 Acc:81.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.95it/s]\n",
      "train | Loss:0.255 Acc:83.69%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.52it/s]\n",
      "val   | Loss:0.242 Acc:82.94%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.94it/s]\n",
      "train | Loss:0.243 Acc:84.01%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.64it/s]\n",
      "val   | Loss:0.239 Acc:82.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.94it/s]\n",
      "train | Loss:0.249 Acc:84.65%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.56it/s]\n",
      "val   | Loss:0.239 Acc:83.12%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.82it/s]\n",
      "train | Loss:0.249 Acc:84.42%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.67it/s]\n",
      "val   | Loss:0.240 Acc:82.21%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.86it/s]\n",
      "train | Loss:0.256 Acc:83.46%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.55it/s]\n",
      "val   | Loss:0.244 Acc:82.76%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.38it/s]\n",
      "train | Loss:0.257 Acc:83.92%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.63it/s]\n",
      "val   | Loss:0.239 Acc:82.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "ğŸ”¥ è¯„ä¼°å…¨å±€æœ€ä½³æ¨¡å‹ (æ¥è‡ª epoch 64ï¼ŒéªŒè¯é›†å‡†ç¡®ç‡ 83.3031%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test  | Loss:0.301 Acc:81.55%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:03<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "âœ… æ€»æ¨ç†æ—¶é—´ (Total Inference Time): 3.19 seconds for 683 images.\n",
      "âœ… æ¨ç†é€Ÿåº¦ (Inference Speed): 213.94 FPS\n",
      "Test Results - Loss: 0.3007 | Accuracy: 81.5520% | F1_weighted: 81.6732% | F1_macro: 80.7158% | Inference Speed: 213.94 FPS\n",
      "--------------------------------------------------\n",
      "\n",
      "Final Test Confusion Matrix:\n",
      "Class 0  |  111 |    0 |    1 |    5 |    2 |   18 |    2 |    1\n",
      "Class 1  |    0 |   62 |    0 |    0 |    0 |    2 |    0 |    0\n",
      "Class 2  |    0 |    0 |   75 |    0 |    0 |    0 |    7 |    0\n",
      "Class 3  |    0 |    0 |    3 |   60 |    7 |   10 |    0 |    1\n",
      "Class 4  |    0 |    0 |    2 |    8 |   38 |    5 |    1 |    0\n",
      "Class 5  |   12 |    1 |    0 |   15 |    6 |   76 |    3 |    0\n",
      "Class 6  |    1 |    0 |    5 |    6 |    0 |    1 |   30 |    0\n",
      "Class 7  |    0 |    0 |    0 |    0 |    0 |    0 |    1 |  105\n",
      "==================================================\n",
      "\n",
      "\n",
      "æ­£åœ¨ç”Ÿæˆè®­ç»ƒå†å²æ›²çº¿å›¾...\n",
      "Warning: æœªæ‰¾åˆ° train_metrics.xlsx æˆ– val_metrics.xlsxã€‚è·³è¿‡ç»˜å›¾ã€‚\n",
      "\n",
      "âœ… Fold 4 è®­ç»ƒå®Œæˆ!\n",
      "   æœ€ä½³epoch: 64\n",
      "   æœ€ä½³éªŒè¯å‡†ç¡®ç‡: 83.3031%\n",
      "   æµ‹è¯•å‡†ç¡®ç‡: 81.5520%\n",
      "   æµ‹è¯•F1 (macro): 80.7158%\n",
      "\n",
      "======================================================================\n",
      "ğŸ”¥ å¼€å§‹è®­ç»ƒ Fold 5/5\n",
      "======================================================================\n",
      "\n",
      "æ‰¾åˆ° 2204 ä¸ªè®­ç»ƒæ–‡ä»¶, 550 ä¸ªéªŒè¯æ–‡ä»¶, 683 ä¸ªæµ‹è¯•æ–‡ä»¶\n",
      "Calculating mean and std of training set for data normalization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2204/2204 [00:08<00:00, 269.04it/s]\n",
      "/tmp/ipykernel_19/1154223942.py:69: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=224, min_width=224, border_mode=0, value=134, p=1.0),\n",
      "/tmp/ipykernel_19/1154223942.py:75: UserWarning: Argument(s) 'alpha_affine' are not valid for transform ElasticTransform\n",
      "  A.ElasticTransform(p=0.5, alpha=20, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n",
      "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "/tmp/ipykernel_19/1154223942.py:88: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(5.0, 30.0), p=1.0),  # âœ… é™ä½å™ªå£°å¼ºåº¦: 10~50 -> 5~30\n",
      "/tmp/ipykernel_19/1154223942.py:91: UserWarning: Argument(s) 'max_holes, max_height, max_width, min_holes, fill_value' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(\n",
      "/tmp/ipykernel_19/1154223942.py:120: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=224, min_width=224, border_mode=0, value=134, p=1.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean (RGB): [0.4978357888341181, 0.5000665513018994, 0.5029518018322944]\n",
      "Std  (RGB): [0.16038189311425727, 0.16094733232781142, 0.16020318519174695]\n",
      "æ­£åœ¨è®¡ç®—ç±»åˆ«æƒé‡ä»¥å¤„ç†æ•°æ®ä¸å¹³è¡¡é—®é¢˜...\n",
      "è®¡ç®—å‡ºçš„ç±»åˆ«æƒé‡: [0.61358577 1.3309178  1.0357143  1.0555556  1.5653409  0.76104975\n",
      " 1.9401408  0.8079179 ]\n",
      "\n",
      "æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹: mobilenetv3_large_100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "âœ… æ¨¡å‹å‚æ•°é‡ (Parameters): 4.21 M\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "âœ… FLOPs: 0.22 G\n",
      "============================================================\n",
      "æ­£åœ¨ä½¿ç”¨ FocalLoss\n",
      "\n",
      "==================================================\n",
      "ğŸ”¥ é˜¶æ®µä¸€: å†»ç»“ä¸»å¹²ç½‘ç»œï¼Œåªè®­ç»ƒåˆ†ç±»å¤´\n",
      "==================================================\n",
      "æ¨¡å‹ä¸»å¹²å·²å†»ç»“ï¼Œåªè®­ç»ƒæœ€åçš„ 'classifier' å±‚ã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train | Loss:3.012 Acc:21.97%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.67it/s]\n",
      "val   | Loss:2.190 Acc:34.00%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.89it/s]\n",
      "train | Loss:2.007 Acc:36.99%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.76it/s]\n",
      "val   | Loss:1.566 Acc:45.64%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.84it/s]\n",
      "train | Loss:1.547 Acc:44.26%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:1.233 Acc:51.82%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.67it/s]\n",
      "train | Loss:1.265 Acc:49.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.75it/s]\n",
      "val   | Loss:1.040 Acc:55.45%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.91it/s]\n",
      "train | Loss:1.083 Acc:52.44%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.62it/s]\n",
      "val   | Loss:0.873 Acc:58.36%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.75it/s]\n",
      "train | Loss:0.872 Acc:56.34%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.72it/s]\n",
      "val   | Loss:0.758 Acc:62.18%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.48it/s]\n",
      "train | Loss:0.809 Acc:59.10%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.55it/s]\n",
      "val   | Loss:0.682 Acc:64.55%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.77it/s]\n",
      "train | Loss:0.687 Acc:61.90%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.63it/s]\n",
      "val   | Loss:0.608 Acc:66.00%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.79it/s]\n",
      "train | Loss:0.664 Acc:63.14%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.68it/s]\n",
      "val   | Loss:0.576 Acc:67.09%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.09it/s]\n",
      "train | Loss:0.587 Acc:65.81%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.71it/s]\n",
      "val   | Loss:0.524 Acc:68.18%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.87it/s]\n",
      "train | Loss:0.551 Acc:66.91%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.77it/s]\n",
      "val   | Loss:0.490 Acc:68.18%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.73it/s]\n",
      "train | Loss:0.491 Acc:70.82%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.70it/s]\n",
      "val   | Loss:0.466 Acc:71.27%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.89it/s]\n",
      "train | Loss:0.483 Acc:71.00%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.70it/s]\n",
      "val   | Loss:0.460 Acc:70.73%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.72it/s]\n",
      "train | Loss:0.464 Acc:72.38%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.430 Acc:72.91%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.00it/s]\n",
      "train | Loss:0.460 Acc:73.48%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.74it/s]\n",
      "val   | Loss:0.419 Acc:72.18%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.96it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”¥ é˜¶æ®µäºŒ: è§£å†»æ‰€æœ‰å±‚ï¼Œè¿›è¡Œå…¨å±€å¾®è°ƒ\n",
      "==================================================\n",
      "åŠ è½½é˜¶æ®µä¸€çš„æœ€ä½³æ¨¡å‹æƒé‡...\n",
      "æ‰€æœ‰å±‚å·²è§£å†»ã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train | Loss:0.438 Acc:74.13%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.49it/s]\n",
      "val   | Loss:0.428 Acc:71.82%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.91it/s]\n",
      "train | Loss:0.422 Acc:75.14%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.420 Acc:71.27%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.89it/s]\n",
      "train | Loss:0.427 Acc:74.91%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.53it/s]\n",
      "val   | Loss:0.413 Acc:72.73%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.88it/s]\n",
      "train | Loss:0.424 Acc:73.07%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.68it/s]\n",
      "val   | Loss:0.410 Acc:73.82%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.86it/s]\n",
      "train | Loss:0.416 Acc:75.00%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.61it/s]\n",
      "val   | Loss:0.404 Acc:74.00%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.84it/s]\n",
      "train | Loss:0.417 Acc:74.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.70it/s]\n",
      "val   | Loss:0.396 Acc:74.36%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.00it/s]\n",
      "train | Loss:0.394 Acc:75.28%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.68it/s]\n",
      "val   | Loss:0.397 Acc:73.64%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.39it/s]\n",
      "train | Loss:0.393 Acc:76.24%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.76it/s]\n",
      "val   | Loss:0.390 Acc:74.36%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.07it/s]\n",
      "train | Loss:0.387 Acc:77.30%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.68it/s]\n",
      "val   | Loss:0.389 Acc:74.55%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.59it/s]\n",
      "train | Loss:0.381 Acc:76.01%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.62it/s]\n",
      "val   | Loss:0.388 Acc:74.00%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.02it/s]\n",
      "train | Loss:0.384 Acc:76.01%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.66it/s]\n",
      "val   | Loss:0.388 Acc:74.36%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.95it/s]\n",
      "train | Loss:0.373 Acc:77.21%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.53it/s]\n",
      "val   | Loss:0.382 Acc:74.55%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.78it/s]\n",
      "train | Loss:0.372 Acc:76.93%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.57it/s]\n",
      "val   | Loss:0.376 Acc:75.09%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.66it/s]\n",
      "train | Loss:0.363 Acc:76.93%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.44it/s]\n",
      "val   | Loss:0.377 Acc:75.09%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.81it/s]\n",
      "train | Loss:0.369 Acc:76.79%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.63it/s]\n",
      "val   | Loss:0.371 Acc:75.27%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.78it/s]\n",
      "train | Loss:0.346 Acc:76.84%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.52it/s]\n",
      "val   | Loss:0.368 Acc:74.55%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.79it/s]\n",
      "train | Loss:0.369 Acc:77.07%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.64it/s]\n",
      "val   | Loss:0.369 Acc:75.45%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.80it/s]\n",
      "train | Loss:0.361 Acc:78.17%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.49it/s]\n",
      "val   | Loss:0.365 Acc:75.27%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.85it/s]\n",
      "train | Loss:0.361 Acc:77.02%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.61it/s]\n",
      "val   | Loss:0.361 Acc:75.27%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.90it/s]\n",
      "train | Loss:0.351 Acc:76.84%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.60it/s]\n",
      "val   | Loss:0.364 Acc:75.27%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.79it/s]\n",
      "train | Loss:0.340 Acc:79.55%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.61it/s]\n",
      "val   | Loss:0.360 Acc:74.91%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.75it/s]\n",
      "train | Loss:0.361 Acc:75.87%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.56it/s]\n",
      "val   | Loss:0.358 Acc:75.27%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.30it/s]\n",
      "train | Loss:0.342 Acc:78.58%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.61it/s]\n",
      "val   | Loss:0.357 Acc:76.00%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.97it/s]\n",
      "train | Loss:0.317 Acc:79.60%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.68it/s]\n",
      "val   | Loss:0.354 Acc:76.00%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.41it/s]\n",
      "train | Loss:0.335 Acc:78.54%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.51it/s]\n",
      "val   | Loss:0.352 Acc:75.64%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.84it/s]\n",
      "train | Loss:0.326 Acc:79.41%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.54it/s]\n",
      "val   | Loss:0.348 Acc:76.36%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.48it/s]\n",
      "train | Loss:0.318 Acc:79.14%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.47it/s]\n",
      "val   | Loss:0.349 Acc:76.36%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.93it/s]\n",
      "train | Loss:0.332 Acc:78.91%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.62it/s]\n",
      "val   | Loss:0.347 Acc:76.36%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.70it/s]\n",
      "train | Loss:0.322 Acc:78.95%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.52it/s]\n",
      "val   | Loss:0.350 Acc:76.55%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.79it/s]\n",
      "train | Loss:0.324 Acc:79.64%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.68it/s]\n",
      "val   | Loss:0.345 Acc:76.36%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.89it/s]\n",
      "train | Loss:0.318 Acc:79.64%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.45it/s]\n",
      "val   | Loss:0.343 Acc:76.18%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.71it/s]\n",
      "train | Loss:0.313 Acc:81.07%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.62it/s]\n",
      "val   | Loss:0.342 Acc:76.91%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.79it/s]\n",
      "train | Loss:0.321 Acc:80.06%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.45it/s]\n",
      "val   | Loss:0.340 Acc:76.36%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.75it/s]\n",
      "train | Loss:0.313 Acc:80.42%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.62it/s]\n",
      "val   | Loss:0.338 Acc:76.91%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.76it/s]\n",
      "train | Loss:0.310 Acc:79.46%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.45it/s]\n",
      "val   | Loss:0.337 Acc:76.91%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.74it/s]\n",
      "train | Loss:0.311 Acc:80.28%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.56it/s]\n",
      "val   | Loss:0.339 Acc:76.73%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.77it/s]\n",
      "train | Loss:0.302 Acc:80.38%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:14<00:00,  2.43it/s]\n",
      "val   | Loss:0.339 Acc:76.00%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.75it/s]\n",
      "train | Loss:0.317 Acc:80.06%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.61it/s]\n",
      "val   | Loss:0.334 Acc:76.18%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.91it/s]\n",
      "train | Loss:0.294 Acc:81.48%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.53it/s]\n",
      "val   | Loss:0.333 Acc:76.55%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.39it/s]\n",
      "train | Loss:0.301 Acc:81.16%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.58it/s]\n",
      "val   | Loss:0.328 Acc:77.27%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.81it/s]\n",
      "train | Loss:0.293 Acc:81.07%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.57it/s]\n",
      "val   | Loss:0.330 Acc:76.91%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.17it/s]\n",
      "train | Loss:0.283 Acc:80.79%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.61it/s]\n",
      "val   | Loss:0.328 Acc:76.73%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.92it/s]\n",
      "train | Loss:0.287 Acc:80.84%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.61it/s]\n",
      "val   | Loss:0.328 Acc:76.36%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.48it/s]\n",
      "train | Loss:0.290 Acc:80.28%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.52it/s]\n",
      "val   | Loss:0.328 Acc:76.36%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.88it/s]\n",
      "train | Loss:0.297 Acc:81.39%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.57it/s]\n",
      "val   | Loss:0.327 Acc:77.27%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.87it/s]\n",
      "train | Loss:0.281 Acc:81.99%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.49it/s]\n",
      "val   | Loss:0.327 Acc:77.09%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.79it/s]\n",
      "train | Loss:0.293 Acc:80.42%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.66it/s]\n",
      "val   | Loss:0.324 Acc:77.09%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.87it/s]\n",
      "train | Loss:0.286 Acc:81.11%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.51it/s]\n",
      "val   | Loss:0.325 Acc:76.91%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.80it/s]\n",
      "train | Loss:0.278 Acc:82.90%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.65it/s]\n",
      "val   | Loss:0.327 Acc:76.91%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.75it/s]\n",
      "train | Loss:0.272 Acc:81.71%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.53it/s]\n",
      "val   | Loss:0.324 Acc:76.55%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.91it/s]\n",
      "train | Loss:0.284 Acc:81.16%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.66it/s]\n",
      "val   | Loss:0.323 Acc:76.91%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.73it/s]\n",
      "train | Loss:0.265 Acc:81.76%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.51it/s]\n",
      "val   | Loss:0.322 Acc:77.64%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.79it/s]\n",
      "train | Loss:0.260 Acc:83.04%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.62it/s]\n",
      "val   | Loss:0.318 Acc:77.45%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.93it/s]\n",
      "train | Loss:0.261 Acc:82.72%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.324 Acc:77.45%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.51it/s]\n",
      "train | Loss:0.273 Acc:81.76%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.61it/s]\n",
      "val   | Loss:0.324 Acc:77.09%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.93it/s]\n",
      "train | Loss:0.266 Acc:82.35%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.63it/s]\n",
      "val   | Loss:0.319 Acc:77.82%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.39it/s]\n",
      "train | Loss:0.271 Acc:82.12%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.65it/s]\n",
      "val   | Loss:0.313 Acc:77.64%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.98it/s]\n",
      "train | Loss:0.271 Acc:82.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.69it/s]\n",
      "val   | Loss:0.317 Acc:77.64%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.79it/s]\n",
      "train | Loss:0.266 Acc:83.18%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.52it/s]\n",
      "val   | Loss:0.313 Acc:77.45%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.83it/s]\n",
      "train | Loss:0.271 Acc:82.95%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.69it/s]\n",
      "val   | Loss:0.312 Acc:77.82%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.00it/s]\n",
      "train | Loss:0.258 Acc:83.09%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.45it/s]\n",
      "val   | Loss:0.311 Acc:77.09%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.70it/s]\n",
      "train | Loss:0.264 Acc:82.58%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.57it/s]\n",
      "val   | Loss:0.312 Acc:77.82%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.81it/s]\n",
      "train | Loss:0.250 Acc:83.18%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.51it/s]\n",
      "val   | Loss:0.313 Acc:77.27%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.08it/s]\n",
      "train | Loss:0.244 Acc:83.41%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.65it/s]\n",
      "val   | Loss:0.311 Acc:77.45%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.89it/s]\n",
      "train | Loss:0.252 Acc:83.27%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.54it/s]\n",
      "val   | Loss:0.307 Acc:77.27%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.91it/s]\n",
      "train | Loss:0.251 Acc:83.23%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.65it/s]\n",
      "val   | Loss:0.306 Acc:77.45%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.91it/s]\n",
      "train | Loss:0.251 Acc:83.55%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.57it/s]\n",
      "val   | Loss:0.306 Acc:78.18%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.48it/s]\n",
      "train | Loss:0.248 Acc:84.01%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.75it/s]\n",
      "val   | Loss:0.307 Acc:77.64%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.81it/s]\n",
      "train | Loss:0.257 Acc:83.59%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.61it/s]\n",
      "val   | Loss:0.307 Acc:77.45%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.48it/s]\n",
      "train | Loss:0.251 Acc:83.69%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.307 Acc:77.45%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.89it/s]\n",
      "train | Loss:0.241 Acc:83.92%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.72it/s]\n",
      "val   | Loss:0.305 Acc:77.64%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.89it/s]\n",
      "train | Loss:0.238 Acc:84.38%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.53it/s]\n",
      "val   | Loss:0.307 Acc:77.64%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.77it/s]\n",
      "train | Loss:0.244 Acc:84.70%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.69it/s]\n",
      "val   | Loss:0.307 Acc:78.36%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.78it/s]\n",
      "train | Loss:0.253 Acc:83.55%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.52it/s]\n",
      "val   | Loss:0.304 Acc:78.55%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.88it/s]\n",
      "train | Loss:0.242 Acc:84.79%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.67it/s]\n",
      "val   | Loss:0.304 Acc:77.64%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.80it/s]\n",
      "train | Loss:0.238 Acc:84.38%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.51it/s]\n",
      "val   | Loss:0.301 Acc:79.09%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.97it/s]\n",
      "train | Loss:0.245 Acc:84.10%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.62it/s]\n",
      "val   | Loss:0.303 Acc:78.36%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.80it/s]\n",
      "train | Loss:0.239 Acc:84.42%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.53it/s]\n",
      "val   | Loss:0.300 Acc:78.55%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.56it/s]\n",
      "train | Loss:0.228 Acc:85.02%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.61it/s]\n",
      "val   | Loss:0.301 Acc:78.55%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.83it/s]\n",
      "train | Loss:0.245 Acc:84.24%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.64it/s]\n",
      "val   | Loss:0.302 Acc:78.73%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.28it/s]\n",
      "train | Loss:0.237 Acc:83.87%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.66it/s]\n",
      "val   | Loss:0.300 Acc:78.73%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.90it/s]\n",
      "train | Loss:0.243 Acc:84.01%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.65it/s]\n",
      "val   | Loss:0.298 Acc:78.73%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.96it/s]\n",
      "train | Loss:0.232 Acc:85.57%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.44it/s]\n",
      "val   | Loss:0.299 Acc:78.73%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.80it/s]\n",
      "train | Loss:0.231 Acc:84.24%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:14<00:00,  2.43it/s]\n",
      "val   | Loss:0.296 Acc:79.09%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.41it/s]\n",
      "train | Loss:0.225 Acc:84.60%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:15<00:00,  2.24it/s]\n",
      "val   | Loss:0.295 Acc:78.18%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.97it/s]\n",
      "train | Loss:0.241 Acc:84.33%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.60it/s]\n",
      "val   | Loss:0.294 Acc:79.27%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.69it/s]\n",
      "train | Loss:0.235 Acc:84.24%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.44it/s]\n",
      "val   | Loss:0.294 Acc:78.73%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.93it/s]\n",
      "train | Loss:0.215 Acc:86.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.67it/s]\n",
      "val   | Loss:0.294 Acc:78.55%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.86it/s]\n",
      "train | Loss:0.230 Acc:85.11%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.55it/s]\n",
      "val   | Loss:0.290 Acc:79.45%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.90it/s]\n",
      "train | Loss:0.231 Acc:84.05%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.65it/s]\n",
      "val   | Loss:0.294 Acc:79.09%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.97it/s]\n",
      "train | Loss:0.222 Acc:85.06%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.45it/s]\n",
      "val   | Loss:0.294 Acc:78.73%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.82it/s]\n",
      "train | Loss:0.214 Acc:86.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.63it/s]\n",
      "val   | Loss:0.292 Acc:78.91%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.92it/s]\n",
      "train | Loss:0.215 Acc:85.52%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.55it/s]\n",
      "val   | Loss:0.292 Acc:78.36%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.66it/s]\n",
      "train | Loss:0.218 Acc:85.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.61it/s]\n",
      "val   | Loss:0.291 Acc:79.09%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.90it/s]\n",
      "train | Loss:0.221 Acc:85.43%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.58it/s]\n",
      "val   | Loss:0.291 Acc:79.27%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.32it/s]\n",
      "train | Loss:0.214 Acc:85.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.56it/s]\n",
      "val   | Loss:0.289 Acc:78.91%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.81it/s]\n",
      "train | Loss:0.216 Acc:85.48%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.63it/s]\n",
      "val   | Loss:0.290 Acc:78.55%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.79it/s]\n",
      "train | Loss:0.218 Acc:86.26%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.48it/s]\n",
      "val   | Loss:0.291 Acc:79.45%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.86it/s]\n",
      "train | Loss:0.217 Acc:85.34%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.61it/s]\n",
      "val   | Loss:0.292 Acc:79.82%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.73it/s]\n",
      "train | Loss:0.215 Acc:86.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.45it/s]\n",
      "val   | Loss:0.288 Acc:79.45%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.86it/s]\n",
      "train | Loss:0.221 Acc:85.89%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.291 Acc:79.45%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.71it/s]\n",
      "train | Loss:0.233 Acc:85.02%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.47it/s]\n",
      "val   | Loss:0.289 Acc:79.27%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.92it/s]\n",
      "train | Loss:0.222 Acc:85.11%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.54it/s]\n",
      "val   | Loss:0.289 Acc:79.64%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.68it/s]\n",
      "train | Loss:0.232 Acc:85.52%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.46it/s]\n",
      "val   | Loss:0.290 Acc:79.27%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.69it/s]\n",
      "train | Loss:0.213 Acc:86.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.62it/s]\n",
      "val   | Loss:0.286 Acc:79.27%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.73it/s]\n",
      "train | Loss:0.214 Acc:84.93%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.50it/s]\n",
      "val   | Loss:0.290 Acc:79.27%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.70it/s]\n",
      "train | Loss:0.210 Acc:85.57%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.60it/s]\n",
      "val   | Loss:0.286 Acc:79.27%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.92it/s]\n",
      "train | Loss:0.210 Acc:86.35%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.60it/s]\n",
      "val   | Loss:0.288 Acc:79.64%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.25it/s]\n",
      "train | Loss:0.222 Acc:85.52%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.63it/s]\n",
      "val   | Loss:0.289 Acc:79.45%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.78it/s]\n",
      "train | Loss:0.212 Acc:86.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.65it/s]\n",
      "val   | Loss:0.286 Acc:80.00%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.42it/s]\n",
      "train | Loss:0.222 Acc:85.66%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.50it/s]\n",
      "val   | Loss:0.289 Acc:79.45%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.68it/s]\n",
      "train | Loss:0.216 Acc:87.32%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.286 Acc:79.64%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.68it/s]\n",
      "train | Loss:0.211 Acc:85.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:14<00:00,  2.42it/s]\n",
      "val   | Loss:0.286 Acc:78.91%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.76it/s]\n",
      "train | Loss:0.213 Acc:86.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.51it/s]\n",
      "val   | Loss:0.286 Acc:79.64%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.82it/s]\n",
      "train | Loss:0.219 Acc:86.08%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:14<00:00,  2.40it/s]\n",
      "val   | Loss:0.288 Acc:79.09%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.69it/s]\n",
      "train | Loss:0.216 Acc:84.70%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.52it/s]\n",
      "val   | Loss:0.286 Acc:80.00%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.69it/s]\n",
      "train | Loss:0.226 Acc:86.26%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:14<00:00,  2.30it/s]\n",
      "val   | Loss:0.285 Acc:79.27%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.69it/s]\n",
      "train | Loss:0.228 Acc:85.39%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.46it/s]\n",
      "val   | Loss:0.287 Acc:80.00%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.76it/s]\n",
      "train | Loss:0.211 Acc:86.81%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:14<00:00,  2.32it/s]\n",
      "val   | Loss:0.286 Acc:79.82%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.67it/s]\n",
      "train | Loss:0.221 Acc:85.39%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.51it/s]\n",
      "val   | Loss:0.288 Acc:79.45%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.72it/s]\n",
      "train | Loss:0.212 Acc:87.04%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:14<00:00,  2.37it/s]\n",
      "val   | Loss:0.286 Acc:80.00%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.67it/s]\n",
      "train | Loss:0.211 Acc:85.43%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.54it/s]\n",
      "val   | Loss:0.284 Acc:80.36%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.78it/s]\n",
      "train | Loss:0.206 Acc:86.76%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.44it/s]\n",
      "val   | Loss:0.284 Acc:80.00%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.85it/s]\n",
      "train | Loss:0.212 Acc:85.48%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.60it/s]\n",
      "val   | Loss:0.285 Acc:79.45%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.86it/s]\n",
      "train | Loss:0.210 Acc:86.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.50it/s]\n",
      "val   | Loss:0.286 Acc:80.36%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.44it/s]\n",
      "train | Loss:0.218 Acc:85.34%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.61it/s]\n",
      "val   | Loss:0.284 Acc:80.36%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.71it/s]\n",
      "train | Loss:0.221 Acc:85.94%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.62it/s]\n",
      "val   | Loss:0.284 Acc:80.73%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.09it/s]\n",
      "train | Loss:0.222 Acc:85.52%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.60it/s]\n",
      "val   | Loss:0.286 Acc:79.27%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.76it/s]\n",
      "train | Loss:0.214 Acc:86.03%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.60it/s]\n",
      "val   | Loss:0.284 Acc:80.55%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.56it/s]\n",
      "train | Loss:0.211 Acc:85.80%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.46it/s]\n",
      "val   | Loss:0.283 Acc:79.82%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.78it/s]\n",
      "train | Loss:0.205 Acc:85.98%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.56it/s]\n",
      "val   | Loss:0.285 Acc:79.82%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.76it/s]\n",
      "train | Loss:0.212 Acc:86.12%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:14<00:00,  2.38it/s]\n",
      "val   | Loss:0.283 Acc:80.36%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.67it/s]\n",
      "train | Loss:0.206 Acc:87.36%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.53it/s]\n",
      "val   | Loss:0.285 Acc:80.00%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.73it/s]\n",
      "train | Loss:0.210 Acc:85.71%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.43it/s]\n",
      "val   | Loss:0.286 Acc:79.64%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.79it/s]\n",
      "train | Loss:0.206 Acc:87.18%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.55it/s]\n",
      "val   | Loss:0.286 Acc:79.45%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.77it/s]\n",
      "train | Loss:0.202 Acc:86.53%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:14<00:00,  2.42it/s]\n",
      "val   | Loss:0.284 Acc:79.64%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.76it/s]\n",
      "train | Loss:0.209 Acc:86.31%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.52it/s]\n",
      "val   | Loss:0.284 Acc:79.82%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.79it/s]\n",
      "train | Loss:0.211 Acc:86.49%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.44it/s]\n",
      "val   | Loss:0.282 Acc:80.36%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.66it/s]\n",
      "train | Loss:0.210 Acc:86.67%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.55it/s]\n",
      "val   | Loss:0.283 Acc:80.18%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.60it/s]\n",
      "train | Loss:0.215 Acc:85.48%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:14<00:00,  2.42it/s]\n",
      "val   | Loss:0.286 Acc:80.55%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.37it/s]\n",
      "train | Loss:0.212 Acc:85.98%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.51it/s]\n",
      "val   | Loss:0.285 Acc:80.00%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.70it/s]\n",
      "train | Loss:0.201 Acc:86.76%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.51it/s]\n",
      "val   | Loss:0.282 Acc:80.00%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.14it/s]\n",
      "train | Loss:0.200 Acc:87.68%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.46it/s]\n",
      "val   | Loss:0.283 Acc:79.45%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.64it/s]\n",
      "train | Loss:0.208 Acc:86.35%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.49it/s]\n",
      "val   | Loss:0.284 Acc:80.18%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.05it/s]\n",
      "train | Loss:0.201 Acc:86.99%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:14<00:00,  2.41it/s]\n",
      "val   | Loss:0.286 Acc:79.82%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.63it/s]\n",
      "train | Loss:0.209 Acc:85.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.55it/s]\n",
      "val   | Loss:0.282 Acc:80.73%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.61it/s]\n",
      "train | Loss:0.210 Acc:85.94%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:14<00:00,  2.39it/s]\n",
      "val   | Loss:0.281 Acc:80.18%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.81it/s]\n",
      "train | Loss:0.205 Acc:86.90%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.57it/s]\n",
      "val   | Loss:0.282 Acc:79.64%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.91it/s]\n",
      "train | Loss:0.201 Acc:86.21%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:14<00:00,  2.38it/s]\n",
      "val   | Loss:0.282 Acc:80.36%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.45it/s]\n",
      "train | Loss:0.209 Acc:87.13%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.52it/s]\n",
      "val   | Loss:0.282 Acc:80.00%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.70it/s]\n",
      "train | Loss:0.206 Acc:86.86%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:14<00:00,  2.37it/s]\n",
      "val   | Loss:0.283 Acc:79.82%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.67it/s]\n",
      "train | Loss:0.209 Acc:86.26%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.57it/s]\n",
      "val   | Loss:0.285 Acc:79.82%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.84it/s]\n",
      "train | Loss:0.204 Acc:87.04%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.50it/s]\n",
      "val   | Loss:0.283 Acc:80.00%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.69it/s]\n",
      "train | Loss:0.204 Acc:87.04%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.60it/s]\n",
      "val   | Loss:0.282 Acc:79.82%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.66it/s]\n",
      "train | Loss:0.214 Acc:86.72%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.44it/s]\n",
      "val   | Loss:0.283 Acc:80.36%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.68it/s]\n",
      "train | Loss:0.215 Acc:85.85%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.55it/s]\n",
      "val   | Loss:0.283 Acc:80.00%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.70it/s]\n",
      "train | Loss:0.197 Acc:87.68%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.54it/s]\n",
      "val   | Loss:0.283 Acc:80.00%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.14it/s]\n",
      "train | Loss:0.199 Acc:86.72%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.64it/s]\n",
      "val   | Loss:0.284 Acc:79.64%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.80it/s]\n",
      "train | Loss:0.209 Acc:85.89%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.52it/s]\n",
      "val   | Loss:0.283 Acc:79.82%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.24it/s]\n",
      "train | Loss:0.207 Acc:86.53%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.49it/s]\n",
      "val   | Loss:0.282 Acc:80.55%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.79it/s]\n",
      "train | Loss:0.210 Acc:86.90%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.59it/s]\n",
      "val   | Loss:0.280 Acc:79.82%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.44it/s]\n",
      "train | Loss:0.215 Acc:85.94%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.44it/s]\n",
      "val   | Loss:0.282 Acc:80.18%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.89it/s]\n",
      "train | Loss:0.216 Acc:85.98%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.60it/s]\n",
      "val   | Loss:0.279 Acc:80.18%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.83it/s]\n",
      "train | Loss:0.197 Acc:86.72%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.44it/s]\n",
      "val   | Loss:0.280 Acc:80.00%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.73it/s]\n",
      "train | Loss:0.215 Acc:86.49%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.55it/s]\n",
      "val   | Loss:0.281 Acc:80.00%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.00it/s]\n",
      "train | Loss:0.211 Acc:86.31%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:14<00:00,  2.42it/s]\n",
      "val   | Loss:0.280 Acc:79.64%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.81it/s]\n",
      "train | Loss:0.210 Acc:85.98%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.55it/s]\n",
      "val   | Loss:0.282 Acc:79.82%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.60it/s]\n",
      "train | Loss:0.200 Acc:87.18%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:14<00:00,  2.30it/s]\n",
      "val   | Loss:0.281 Acc:79.45%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.35it/s]\n",
      "train | Loss:0.208 Acc:86.17%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:14<00:00,  2.40it/s]\n",
      "val   | Loss:0.281 Acc:80.36%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.60it/s]\n",
      "train | Loss:0.210 Acc:86.49%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:14<00:00,  2.30it/s]\n",
      "val   | Loss:0.280 Acc:79.64%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:03<00:00,  2.95it/s]\n",
      "train | Loss:0.207 Acc:86.31%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:14<00:00,  2.39it/s]\n",
      "val   | Loss:0.280 Acc:80.00%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.57it/s]\n",
      "train | Loss:0.216 Acc:86.31%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:15<00:00,  2.13it/s]\n",
      "val   | Loss:0.279 Acc:80.36%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.01it/s]\n",
      "train | Loss:0.205 Acc:86.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:14<00:00,  2.28it/s]\n",
      "val   | Loss:0.280 Acc:80.91%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.45it/s]\n",
      "train | Loss:0.214 Acc:86.40%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:15<00:00,  2.21it/s]\n",
      "val   | Loss:0.280 Acc:79.82%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.70it/s]\n",
      "train | Loss:0.204 Acc:86.44%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:14<00:00,  2.31it/s]\n",
      "val   | Loss:0.281 Acc:80.55%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.54it/s]\n",
      "train | Loss:0.210 Acc:85.80%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:14<00:00,  2.29it/s]\n",
      "val   | Loss:0.279 Acc:79.82%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.53it/s]\n",
      "train | Loss:0.211 Acc:86.72%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:14<00:00,  2.42it/s]\n",
      "val   | Loss:0.281 Acc:80.36%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.39it/s]\n",
      "train | Loss:0.203 Acc:86.63%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:14<00:00,  2.30it/s]\n",
      "val   | Loss:0.278 Acc:80.55%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:03<00:00,  2.78it/s]\n",
      "train | Loss:0.210 Acc:86.63%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:14<00:00,  2.39it/s]\n",
      "val   | Loss:0.279 Acc:80.55%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.52it/s]\n",
      "train | Loss:0.229 Acc:85.57%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:14<00:00,  2.27it/s]\n",
      "val   | Loss:0.281 Acc:80.55%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.73it/s]\n",
      "train | Loss:0.204 Acc:87.32%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.45it/s]\n",
      "val   | Loss:0.280 Acc:80.18%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.78it/s]\n",
      "train | Loss:0.206 Acc:86.63%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:14<00:00,  2.31it/s]\n",
      "val   | Loss:0.279 Acc:80.00%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.59it/s]\n",
      "train | Loss:0.207 Acc:86.63%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:14<00:00,  2.38it/s]\n",
      "val   | Loss:0.281 Acc:80.36%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.56it/s]\n",
      "train | Loss:0.208 Acc:85.29%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:14<00:00,  2.33it/s]\n",
      "val   | Loss:0.280 Acc:80.18%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.45it/s]\n",
      "train | Loss:0.200 Acc:87.04%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.52it/s]\n",
      "val   | Loss:0.280 Acc:79.82%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”¥ è¯„ä¼°å…¨å±€æœ€ä½³æ¨¡å‹ (æ¥è‡ª epoch 188ï¼ŒéªŒè¯é›†å‡†ç¡®ç‡ 80.9091%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test  | Loss:0.257 Acc:83.31%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:03<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "âœ… æ€»æ¨ç†æ—¶é—´ (Total Inference Time): 3.73 seconds for 683 images.\n",
      "âœ… æ¨ç†é€Ÿåº¦ (Inference Speed): 183.14 FPS\n",
      "Test Results - Loss: 0.2566 | Accuracy: 83.3089% | F1_weighted: 83.2338% | F1_macro: 82.5321% | Inference Speed: 183.14 FPS\n",
      "--------------------------------------------------\n",
      "\n",
      "Final Test Confusion Matrix:\n",
      "Class 0  |  119 |    0 |    0 |    3 |    0 |   16 |    1 |    1\n",
      "Class 1  |    0 |   63 |    0 |    1 |    0 |    0 |    0 |    0\n",
      "Class 2  |    0 |    0 |   80 |    0 |    0 |    0 |    2 |    0\n",
      "Class 3  |    1 |    0 |    1 |   59 |    4 |   12 |    4 |    0\n",
      "Class 4  |    0 |    0 |    2 |    4 |   42 |    4 |    1 |    1\n",
      "Class 5  |   13 |    3 |    1 |   16 |    3 |   73 |    4 |    0\n",
      "Class 6  |    3 |    0 |    3 |    6 |    1 |    1 |   29 |    0\n",
      "Class 7  |    0 |    0 |    0 |    0 |    1 |    0 |    1 |  104\n",
      "==================================================\n",
      "\n",
      "\n",
      "æ­£åœ¨ç”Ÿæˆè®­ç»ƒå†å²æ›²çº¿å›¾...\n",
      "Warning: æœªæ‰¾åˆ° train_metrics.xlsx æˆ– val_metrics.xlsxã€‚è·³è¿‡ç»˜å›¾ã€‚\n",
      "\n",
      "âœ… Fold 5 è®­ç»ƒå®Œæˆ!\n",
      "   æœ€ä½³epoch: 188\n",
      "   æœ€ä½³éªŒè¯å‡†ç¡®ç‡: 80.9091%\n",
      "   æµ‹è¯•å‡†ç¡®ç‡: 83.3089%\n",
      "   æµ‹è¯•F1 (macro): 82.5321%\n",
      "\n",
      "======================================================================\n",
      "ğŸ‰ æ‰€æœ‰ 5 æŠ˜è®­ç»ƒå®Œæˆ!\n",
      "======================================================================\n",
      "\n",
      "ğŸ“Š KæŠ˜äº¤å‰éªŒè¯æ±‡æ€»ç»“æœ:\n",
      "   éªŒè¯å‡†ç¡®ç‡: 82.9332% Â± 1.6439%\n",
      "   æµ‹è¯•å‡†ç¡®ç‡: 82.4597% Â± 1.1431%\n",
      "   æµ‹è¯•F1 (macro): 81.7967% Â± 1.3010%\n",
      "\n",
      "âœ… KæŠ˜æ±‡æ€»ç»“æœå·²ä¿å­˜è‡³: /kaggle/working/kfold_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# ğŸ†• KæŠ˜äº¤å‰éªŒè¯è®­ç»ƒè„šæœ¬ (æœ€å°æ”¹åŠ¨ç‰ˆ - å¤ç”¨mainå‡½æ•°)\n",
    "# =====================================================================\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def get_kfold_splits(file_names, n_folds=5, random_state=42):\n",
    "    \"\"\"åˆ›å»ºKæŠ˜äº¤å‰éªŒè¯çš„æ•°æ®åˆ†å‰²\"\"\"\n",
    "    labels = [CLASS_MAP[os.path.basename(os.path.dirname(p))] for p in file_names]\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n",
    "    fold_splits = []\n",
    "    for train_idx, val_idx in skf.split(file_names, labels):\n",
    "        fold_splits.append((train_idx, val_idx))\n",
    "    return fold_splits\n",
    "\n",
    "\n",
    "def generate_dataset(train_file_names, val_file_names, test_file_names, batch_size, val_batch_size, test_batch_size, train_transform, val_test_transform):\n",
    "    \"\"\"ç”Ÿæˆæ•°æ®åŠ è½½å™¨\"\"\"\n",
    "    train_dataset = DatasetImage(train_file_names, transform=train_transform)\n",
    "    valid_dataset = DatasetImage(val_file_names, transform=val_test_transform)\n",
    "    test_dataset = DatasetImage(test_file_names, transform=val_test_transform)\n",
    "    \n",
    "    args = KaggleConfig()\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        num_workers=2, \n",
    "        shuffle=True, \n",
    "        drop_last=True,\n",
    "        collate_fn=collate_fn if args.use_hybrid_mix else default_collate\n",
    "    )\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=val_batch_size, num_workers=2, shuffle=False, drop_last=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=test_batch_size, num_workers=2, shuffle=False, drop_last=False)\n",
    "    \n",
    "    return train_loader, valid_loader, test_loader\n",
    "\n",
    "\n",
    "def main(args, device, train_file_names, val_file_names, test_file_names):\n",
    "    \"\"\"ä¸»è®­ç»ƒå‡½æ•° (å·²ä¿®æ”¹ä¸ºæ¥æ”¶æ–‡ä»¶åˆ—è¡¨)\"\"\"\n",
    "    \n",
    "    print(f\"æ‰¾åˆ° {len(train_file_names)} ä¸ªè®­ç»ƒæ–‡ä»¶, {len(val_file_names)} ä¸ªéªŒè¯æ–‡ä»¶, {len(test_file_names)} ä¸ªæµ‹è¯•æ–‡ä»¶\")\n",
    "    \n",
    "    # --- è®¡ç®—å‡å€¼æ ‡å‡†å·®å’Œæ•°æ®å¢å¼º ---\n",
    "    train_mean, train_std = mean_and_std(train_file_names)\n",
    "    train_transform, val_test_transform = image_transform(mean=train_mean, std=train_std)\n",
    "    \n",
    "    train_loader, valid_loader, test_loader = generate_dataset(\n",
    "        train_file_names, val_file_names, test_file_names,\n",
    "        args.train_batch_size, args.val_batch_size, args.test_batch_size,\n",
    "        train_transform=train_transform,\n",
    "        val_test_transform=val_test_transform\n",
    "    )\n",
    "    \n",
    "    # --- è®¡ç®—ç±»åˆ«æƒé‡ ---\n",
    "    print(\"æ­£åœ¨è®¡ç®—ç±»åˆ«æƒé‡ä»¥å¤„ç†æ•°æ®ä¸å¹³è¡¡é—®é¢˜...\")\n",
    "    train_labels = [CLASS_MAP[os.path.basename(os.path.dirname(p))] for p in train_file_names]\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "    print(f\"è®¡ç®—å‡ºçš„ç±»åˆ«æƒé‡: {class_weights.cpu().numpy()}\")\n",
    "    \n",
    "    # --- åˆå§‹åŒ–æ¨¡å‹ ---\n",
    "    print(f\"\\næ­£åœ¨åˆå§‹åŒ–æ¨¡å‹: {args.encoder}\")\n",
    "    model = ClassificationModel(encoder=args.encoder, classnum=args.classnum, pretrained=True, drop_rate=args.dropout_rate).to(device)\n",
    "    \n",
    "    model_for_profiling = deepcopy(model)\n",
    "    model_for_profiling.eval()\n",
    "    num_params = count_parameters(model)\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"âœ… æ¨¡å‹å‚æ•°é‡ (Parameters): {num_params / 1e6:.2f} M\")\n",
    "    logging.info(\"==================== MODEL EFFICIENCY ====================\")\n",
    "    logging.info(f\"æ¨¡å‹å‚æ•°é‡ (Parameters): {num_params / 1e6:.2f} M\")\n",
    "    dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "    flops, params = profile(model_for_profiling, inputs=(dummy_input,))\n",
    "    print(f\"âœ… FLOPs: {flops / 1e9:.2f} G\")\n",
    "    print(\"=\" * 60)\n",
    "    logging.info(f\"FLOPs: {flops / 1e9:.2f} G\")\n",
    "    logging.info(\"==========================================================\")\n",
    "    del model_for_profiling\n",
    "    \n",
    "    # --- æŸå¤±å‡½æ•° ---\n",
    "    if args.use_hybrid_mix:\n",
    "        print(\"æ­£åœ¨ä½¿ç”¨ nn.CrossEntropyLoss (å› ä¸ºå¯ç”¨äº† CutMix/MixUp)\")\n",
    "        criterion = nn.CrossEntropyLoss(label_smoothing=args.label_smoothing, weight=class_weights)\n",
    "    else:\n",
    "        print(\"æ­£åœ¨ä½¿ç”¨ FocalLoss\")\n",
    "        criterion = FocalLoss(alpha=class_weights, gamma=args.focal_loss_gamma)\n",
    "    \n",
    "    writer = SummaryWriter(log_dir=args.save_path)\n",
    "    training_start_time = time.time()\n",
    "    \n",
    "    # =====================================================================================\n",
    "    # é˜¶æ®µä¸€: å†»ç»“ä¸»å¹²ç½‘ç»œï¼Œåªè®­ç»ƒåˆ†ç±»å¤´\n",
    "    # =====================================================================================\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ğŸ”¥ é˜¶æ®µä¸€: å†»ç»“ä¸»å¹²ç½‘ç»œï¼Œåªè®­ç»ƒåˆ†ç±»å¤´\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for param in model.clf_model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    if hasattr(model.clf_model, 'head'):\n",
    "        for param in model.clf_model.head.parameters():\n",
    "            param.requires_grad = True\n",
    "        print(\"æ¨¡å‹ä¸»å¹²å·²å†»ç»“ï¼Œåªè®­ç»ƒæœ€åçš„ 'head' å±‚ã€‚\")\n",
    "    elif hasattr(model.clf_model, 'classifier'):\n",
    "        for param in model.clf_model.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "        print(\"æ¨¡å‹ä¸»å¹²å·²å†»ç»“ï¼Œåªè®­ç»ƒæœ€åçš„ 'classifier' å±‚ã€‚\")\n",
    "    elif hasattr(model.clf_model, 'fc'):\n",
    "        for param in model.clf_model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "        print(\"æ¨¡å‹ä¸»å¹²å·²å†»ç»“ï¼Œåªè®­ç»ƒæœ€åçš„ 'fc' å±‚ã€‚\")\n",
    "    else:\n",
    "        raise AttributeError(\"æ— æ³•åœ¨æ¨¡å‹ä¸­æ‰¾åˆ° 'head', 'classifier' æˆ– 'fc' å±‚è¿›è¡Œè§£å†»ã€‚\")\n",
    "    \n",
    "    num_epochs_stage1 = 15\n",
    "    optimizer_stage1 = Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=args.LR_head, weight_decay=args.WE_dec)\n",
    "    scheduler_stage1 = build_scheduler(optimizer_stage1, phase=\"stage1\", args=args)\n",
    "    \n",
    "    best_acc_stage1 = 0\n",
    "    for epoch in range(1, num_epochs_stage1 + 1):\n",
    "        logging.info(f\"é˜¶æ®µä¸€ - Epoch {epoch}/{num_epochs_stage1}\")\n",
    "        run_epoch('train', model, train_loader, criterion, device, epoch, optimizer=optimizer_stage1, writer=writer, args=args)\n",
    "        val_metrics = run_epoch('val', model, valid_loader, criterion, device, epoch, writer=writer, args=args)\n",
    "        \n",
    "        if args.lr_scheduler == \"cosine\":\n",
    "            scheduler_stage1.step()\n",
    "        else:\n",
    "            scheduler_stage1.step(val_metrics['loss'])\n",
    "        \n",
    "        if val_metrics['accuracy'] >= best_acc_stage1:\n",
    "            best_acc_stage1 = val_metrics['accuracy']\n",
    "            logging.info(f\"é˜¶æ®µä¸€æ–°é«˜! éªŒè¯é›†å‡†ç¡®ç‡: {best_acc_stage1:.4%}. ä¿å­˜æ¨¡å‹...\")\n",
    "            torch.save(model.state_dict(), os.path.join(args.save_path, 'best_model_stage1.pth'))\n",
    "    \n",
    "    # =====================================================================================\n",
    "    # é˜¶æ®µäºŒ: è§£å†»æ‰€æœ‰å±‚ï¼Œè¿›è¡Œå…¨å±€å¾®è°ƒ\n",
    "    # =====================================================================================\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ğŸ”¥ é˜¶æ®µäºŒ: è§£å†»æ‰€æœ‰å±‚ï¼Œè¿›è¡Œå…¨å±€å¾®è°ƒ\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"åŠ è½½é˜¶æ®µä¸€çš„æœ€ä½³æ¨¡å‹æƒé‡...\")\n",
    "    model.load_state_dict(torch.load(os.path.join(args.save_path, 'best_model_stage1.pth')))\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "    print(\"æ‰€æœ‰å±‚å·²è§£å†»ã€‚\")\n",
    "    \n",
    "    optimizer_stage2 = Adam(model.parameters(), lr=args.LR_clf, weight_decay=args.WE_dec)\n",
    "    # ğŸ”¥ ä¿®å¤: ç»Ÿä¸€ä½¿ç”¨ build_schedulerï¼Œä¿æŒä¸¤é˜¶æ®µè°ƒåº¦ç­–ç•¥ä¸€è‡´\n",
    "    scheduler_stage2 = build_scheduler(optimizer_stage2, phase=\"stage2\", args=args, num_epochs_stage1=num_epochs_stage1)\n",
    "    \n",
    "    best_acc = 0\n",
    "    best_epoch = 0\n",
    "    early_stopping_patience = 35\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    for epoch in range(num_epochs_stage1 + 1, args.num_epochs + 1):\n",
    "        logging.info(f\"é˜¶æ®µäºŒ - Epoch {epoch}/{args.num_epochs}\")\n",
    "        \n",
    "        run_epoch('train', model, train_loader, criterion, device, epoch, optimizer=optimizer_stage2, writer=writer, args=args)\n",
    "        val_metrics = run_epoch('val', model, valid_loader, criterion, device, epoch, writer=writer, args=args)\n",
    "        \n",
    "        # ğŸ”¥ ä¿®å¤: æ ¹æ®é…ç½®çš„è°ƒåº¦å™¨ç±»å‹è°ƒç”¨ä¸åŒçš„ step æ–¹æ³•\n",
    "        if args.lr_scheduler == \"cosine\":\n",
    "            scheduler_stage2.step()\n",
    "        else:\n",
    "            scheduler_stage2.step(val_metrics['loss'])\n",
    "        \n",
    "        if val_metrics['accuracy'] >= best_acc:\n",
    "            best_acc = val_metrics['accuracy']\n",
    "            best_epoch = epoch\n",
    "            epochs_no_improve = 0\n",
    "            logging.info(f\"å…¨å±€æ–°é«˜! éªŒè¯é›†å‡†ç¡®ç‡: {best_acc:.4%}. ä¿å­˜æ¨¡å‹...\")\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "            }, os.path.join(args.save_path, 'best_model.pth'))\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            logging.info(f\"éªŒè¯é›†å‡†ç¡®ç‡æœªæå‡ï¼Œå½“å‰æ— æ”¹å–„è½®æ•°: {epochs_no_improve}/{early_stopping_patience}\")\n",
    "        \n",
    "        if epochs_no_improve >= early_stopping_patience:\n",
    "            print(f'\\n')\n",
    "            logging.info(f\"è§¦å‘æå‰åœæ­¢ï¼è¿ç»­ {early_stopping_patience} ä¸ª epochs éªŒè¯é›†å‡†ç¡®ç‡æœªæå‡ã€‚\")\n",
    "            logging.info(f\"æœ€ä½³epoch: {best_epoch}, æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_acc:.4%}\")\n",
    "            break\n",
    "    \n",
    "    training_end_time = time.time()\n",
    "    total_training_time = training_end_time - training_start_time\n",
    "    logging.info(f\"æ€»è®­ç»ƒæ—¶é—´ (Total Training Time): {total_training_time/3600:.2f} hours\")\n",
    "    \n",
    "    # --- æœ€ç»ˆæµ‹è¯•è¯„ä¼° ---\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"ğŸ”¥ è¯„ä¼°å…¨å±€æœ€ä½³æ¨¡å‹ (æ¥è‡ª epoch {best_epoch}ï¼ŒéªŒè¯é›†å‡†ç¡®ç‡ {best_acc:.4%})\")\n",
    "    \n",
    "    best_model_path = os.path.join(args.save_path, 'best_model.pth')\n",
    "    test_metrics = None\n",
    "    if os.path.exists(best_model_path):\n",
    "        final_test_model = ClassificationModel(encoder=args.encoder, classnum=args.classnum, pretrained=False).to(device)\n",
    "        checkpoint = torch.load(best_model_path)\n",
    "        final_test_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        test_metrics = run_epoch('test', final_test_model, test_loader, criterion, device,\n",
    "                                 epoch=checkpoint['epoch'], writer=writer, compute_cm=True, args=args)\n",
    "        \n",
    "        if test_metrics.get('confusion_matrix') is not None:\n",
    "            cm = test_metrics['confusion_matrix']\n",
    "            print(\"\\nFinal Test Confusion Matrix:\")\n",
    "            for i in range(cm.shape[0]):\n",
    "                row_str = \" | \".join([f\"{count:4d}\" for count in cm[i]])\n",
    "                print(f\"Class {i:<2} | {row_str}\")\n",
    "    \n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    torch.save(model.state_dict(), os.path.join(args.save_path, 'final_model.pth'))\n",
    "    \n",
    "    # --- ç»˜åˆ¶å†å²æ›²çº¿ ---\n",
    "    print(\"\\næ­£åœ¨ç”Ÿæˆè®­ç»ƒå†å²æ›²çº¿å›¾...\")\n",
    "    try:\n",
    "        train_metrics_df = pd.read_excel(os.path.join(args.save_path, 'train_metrics.xlsx'))\n",
    "        val_metrics_df = pd.read_excel(os.path.join(args.save_path, 'val_metrics.xlsx'))\n",
    "        history = {\n",
    "            'train_loss': train_metrics_df['Loss'].tolist(),\n",
    "            'train_acc': train_metrics_df['Accuracy'].tolist(),\n",
    "            'val_loss': val_metrics_df['Loss'].tolist(),\n",
    "            'val_acc': val_metrics_df['Accuracy'].tolist()\n",
    "        }\n",
    "        plot_history_curves(history, args.save_path)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Warning: æœªæ‰¾åˆ° train_metrics.xlsx æˆ– val_metrics.xlsxã€‚è·³è¿‡ç»˜å›¾ã€‚\")\n",
    "    except Exception as e:\n",
    "        print(f\"ç»˜å›¾æ—¶å‘ç”Ÿé”™è¯¯: {e}\")\n",
    "    \n",
    "    return {\n",
    "        'best_epoch': best_epoch,\n",
    "        'best_val_acc': best_acc,\n",
    "        'test_metrics': test_metrics\n",
    "    }\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# ä¸»è®­ç»ƒå¾ªç¯ - KæŠ˜äº¤å‰éªŒè¯\n",
    "# =====================================================================\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # --- å…¨å±€è®¾ç½® ---\n",
    "    args = KaggleConfig()\n",
    "    set_seed(42)\n",
    "    device = torch.device(f'cuda:{args.cuda_no}' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    os.makedirs(args.save_path, exist_ok=True)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ğŸ”¥ å¼€å§‹ {args.n_folds} æŠ˜äº¤å‰éªŒè¯è®­ç»ƒ\")\n",
    "    print(f\"æ¨¡å‹: {args.encoder} | å­¦ä¹ ç‡: {args.LR_clf}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # --- è·å–æ‰€æœ‰è®­ç»ƒ+éªŒè¯æ–‡ä»¶ï¼ˆåˆå¹¶ç”¨äºKæŠ˜åˆ†å‰²ï¼‰---\n",
    "    train_files = glob.glob(os.path.join(args.train_path, '*', '*.[jp][pn]g'))\n",
    "    val_files = glob.glob(os.path.join(args.val_path, '*', '*.[jp][pn]g'))\n",
    "    all_train_val_files = train_files + val_files\n",
    "    test_file_names = glob.glob(os.path.join(args.test_path, '*', '*.[jp][pn]g'))\n",
    "    \n",
    "    print(f\"æ€»è®­ç»ƒ+éªŒè¯æ–‡ä»¶æ•°: {len(all_train_val_files)}\")\n",
    "    print(f\"æµ‹è¯•æ–‡ä»¶æ•°: {len(test_file_names)}\")\n",
    "    \n",
    "    # --- åˆ›å»ºKæŠ˜åˆ†å‰² ---\n",
    "    fold_splits = get_kfold_splits(all_train_val_files, n_folds=args.n_folds, random_state=42)\n",
    "    \n",
    "    # --- å­˜å‚¨æ‰€æœ‰foldçš„ç»“æœ ---\n",
    "    all_fold_results = []\n",
    "    \n",
    "    # --- è®­ç»ƒæ¯ä¸ªfold ---\n",
    "    for fold_idx, (train_indices, val_indices) in enumerate(fold_splits):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"ğŸ”¥ å¼€å§‹è®­ç»ƒ Fold {fold_idx + 1}/{args.n_folds}\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        # æ ¹æ®ç´¢å¼•è·å–æ–‡ä»¶å\n",
    "        fold_train_files = [all_train_val_files[i] for i in train_indices]\n",
    "        fold_val_files = [all_train_val_files[i] for i in val_indices]\n",
    "        \n",
    "        # ğŸ”¥ è®¾ç½®å½“å‰foldçš„ä¿å­˜è·¯å¾„å’Œrun_id\n",
    "        fold_save_path = os.path.join(args.save_path, f'fold_{fold_idx}')\n",
    "        os.makedirs(fold_save_path, exist_ok=True)\n",
    "        original_save_path = args.save_path\n",
    "        args.save_path = fold_save_path\n",
    "        args.current_fold = fold_idx\n",
    "        args.run_id = f\"{args.encoder}_lr_{args.LR_clf}_fold{fold_idx}\"\n",
    "        \n",
    "        # è®­ç»ƒå½“å‰fold\n",
    "        fold_result = main(args, device, fold_train_files, fold_val_files, test_file_names)\n",
    "        fold_result['fold'] = fold_idx\n",
    "        all_fold_results.append(fold_result)\n",
    "        \n",
    "        # æ¢å¤åŸå§‹ä¿å­˜è·¯å¾„\n",
    "        args.save_path = original_save_path\n",
    "        \n",
    "        print(f\"\\nâœ… Fold {fold_idx + 1} è®­ç»ƒå®Œæˆ!\")\n",
    "        print(f\"   æœ€ä½³epoch: {fold_result['best_epoch']}\")\n",
    "        print(f\"   æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {fold_result['best_val_acc']:.4%}\")\n",
    "        if fold_result['test_metrics']:\n",
    "            print(f\"   æµ‹è¯•å‡†ç¡®ç‡: {fold_result['test_metrics']['accuracy']:.4%}\")\n",
    "            print(f\"   æµ‹è¯•F1 (macro): {fold_result['test_metrics']['f1_macro']:.4%}\")\n",
    "    \n",
    "    # --- æ±‡æ€»æ‰€æœ‰foldçš„ç»“æœ ---\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ğŸ‰ æ‰€æœ‰ {args.n_folds} æŠ˜è®­ç»ƒå®Œæˆ!\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    avg_val_acc = np.mean([r['best_val_acc'] for r in all_fold_results])\n",
    "    std_val_acc = np.std([r['best_val_acc'] for r in all_fold_results])\n",
    "    \n",
    "    avg_test_acc = np.mean([r['test_metrics']['accuracy'] for r in all_fold_results if r['test_metrics']])\n",
    "    std_test_acc = np.std([r['test_metrics']['accuracy'] for r in all_fold_results if r['test_metrics']])\n",
    "    \n",
    "    avg_test_f1 = np.mean([r['test_metrics']['f1_macro'] for r in all_fold_results if r['test_metrics']])\n",
    "    std_test_f1 = np.std([r['test_metrics']['f1_macro'] for r in all_fold_results if r['test_metrics']])\n",
    "    \n",
    "    print(\"ğŸ“Š KæŠ˜äº¤å‰éªŒè¯æ±‡æ€»ç»“æœ:\")\n",
    "    print(f\"   éªŒè¯å‡†ç¡®ç‡: {avg_val_acc:.4%} Â± {std_val_acc:.4%}\")\n",
    "    print(f\"   æµ‹è¯•å‡†ç¡®ç‡: {avg_test_acc:.4%} Â± {std_test_acc:.4%}\")\n",
    "    print(f\"   æµ‹è¯•F1 (macro): {avg_test_f1:.4%} Â± {std_test_f1:.4%}\")\n",
    "    \n",
    "    # --- ä¿å­˜æ±‡æ€»ç»“æœ ---\n",
    "    summary_df = pd.DataFrame(all_fold_results)\n",
    "    summary_path = os.path.join(args.save_path, 'kfold_summary.csv')\n",
    "    summary_df.to_csv(summary_path, index=False)\n",
    "    print(f\"\\nâœ… KæŠ˜æ±‡æ€»ç»“æœå·²ä¿å­˜è‡³: {summary_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c01ff1",
   "metadata": {
    "papermill": {
     "duration": 2.861835,
     "end_time": "2025-10-29T05:36:32.418364",
     "exception": false,
     "start_time": "2025-10-29T05:36:29.556529",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# path: 8-crop-new.ipynb\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "# å­¦ä¹ ç‡è°ƒåº¦å™¨ä¸é˜¶æ®µå‚æ•°è¯´æ˜ï¼ˆCosine vs Plateauï¼‰\n",
    "\n",
    "æœ¬è¯´æ˜å›ç­”ä¸¤ä¸ªå¸¸è§é—®é¢˜ï¼Œå¹¶ç»™å‡ºæœ€å°æ”¹åŠ¨çš„æœ€ä½³å®è·µã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## é—®é¢˜ä¸€ï¼šä¸ºä»€ä¹ˆæ„é€ è°ƒåº¦å™¨æ—¶è¦ä¼ å…¥ `optimizer`ï¼Ÿ\n",
    "\n",
    "- PyTorch çš„æ‰€æœ‰å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼ˆå¦‚ `CosineAnnealingLR`ã€`ReduceLROnPlateau`ï¼‰éƒ½éœ€è¦ç»‘å®šä¸€ä¸ªä¼˜åŒ–å™¨å®ä¾‹ã€‚\n",
    "- åŸå› ï¼šè°ƒåº¦å™¨çš„èŒè´£æ˜¯æŒ‰ç­–ç•¥æ›´æ–°è¯¥ä¼˜åŒ–å™¨çš„å„å‚æ•°ç»„çš„å­¦ä¹ ç‡ï¼ˆ`optimizer.param_groups[i]['lr']`ï¼‰ã€‚\n",
    "- å› æ­¤ï¼Œå¿…é¡»åœ¨åˆå§‹åŒ–è°ƒåº¦å™¨æ—¶ä¼ å…¥å¯¹åº”çš„ `optimizer`ï¼Œè°ƒåº¦å™¨æ‰èƒ½â€œçŸ¥é“è¦è°ƒè°â€çš„å­¦ä¹ ç‡ã€‚\n",
    "\n",
    "ç¤ºä¾‹ï¼ˆé˜¶æ®µä¸€åªè®­ç»ƒåˆ†ç±»å¤´ï¼‰ï¼š\n",
    "```python\n",
    "optimizer_stage1 = AdamW(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                         lr=args.LR_head, weight_decay=args.WE_dec)\n",
    "scheduler_stage1 = build_scheduler(optimizer_stage1, phase=\"stage1\", args=args)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7972960,
     "sourceId": 12619589,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8054472,
     "sourceId": 12741834,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8141773,
     "sourceId": 12870923,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8152888,
     "sourceId": 12886293,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8195394,
     "sourceId": 12950064,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8213083,
     "sourceId": 12976249,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8239355,
     "sourceId": 13014199,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8505203,
     "sourceId": 13402229,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8533297,
     "sourceId": 13443710,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8559815,
     "sourceId": 13482583,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8562393,
     "sourceId": 13486374,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11012.973007,
   "end_time": "2025-10-29T05:36:38.855998",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-29T02:33:05.882991",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1ca30aebf4584cd2847c36f681150901": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2cfc06ca5692432b9542e9a3775c0f1c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3da0749944cb4c0d8c4c588f015540b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "600fffe41c004b3da3df07ea3a1c74cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bbc8a77016994d9bb349f8cfd54b1bac",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_c2c666f2126f4229873fab761082698e",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors:â€‡100%"
      }
     },
     "adac39c2443c4f5088c086f921c0a2bd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_600fffe41c004b3da3df07ea3a1c74cf",
        "IPY_MODEL_da42592a9f51404da4f695bdf2fed99a",
        "IPY_MODEL_e3483fe76f564e3c91abd89a660d619e"
       ],
       "layout": "IPY_MODEL_c0c409e39a3e405ab5a362ba9caa60cb",
       "tabbable": null,
       "tooltip": null
      }
     },
     "b8c9943fb0264fc880656e4ed6dabf47": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bbc8a77016994d9bb349f8cfd54b1bac": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c0c409e39a3e405ab5a362ba9caa60cb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c2c666f2126f4229873fab761082698e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "da42592a9f51404da4f695bdf2fed99a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b8c9943fb0264fc880656e4ed6dabf47",
       "max": 22058321.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2cfc06ca5692432b9542e9a3775c0f1c",
       "tabbable": null,
       "tooltip": null,
       "value": 22058321.0
      }
     },
     "e3483fe76f564e3c91abd89a660d619e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1ca30aebf4584cd2847c36f681150901",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_3da0749944cb4c0d8c4c588f015540b3",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡22.1M/22.1Mâ€‡[00:00&lt;00:00,â€‡29.3MB/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
